[
  {
    "objectID": "webexercises.html",
    "href": "webexercises.html",
    "title": "Webexercises",
    "section": "",
    "text": "This is a Web Exercise template created by the psychology teaching team at the University of Glasgow, based on ideas from Software Carpentry. This template shows how instructors can easily create interactive web documents that students can use in self-guided learning.\nThe {webexercises} package provides a number of functions that you use in inline R code or through code chunk options to create HTML widgets (text boxes, pull down menus, buttons that reveal hidden content). Examples are given below. Render this file to HTML to see how it works.\nNOTE: To use the widgets in the compiled HTML file, you need to have a JavaScript-enabled browser."
  },
  {
    "objectID": "webexercises.html#example-questions",
    "href": "webexercises.html#example-questions",
    "title": "Webexercises",
    "section": "Example Questions",
    "text": "Example Questions\n\nFill-In-The-Blanks (fitb())\nCreate fill-in-the-blank questions using fitb(), providing the answer as the first argument.\n\n2 + 2 is \n\nYou can also create these questions dynamically, using variables from your R session.\n\nThe square root of 9 is: \n\nThe blanks are case-sensitive; if you don’t care about case, use the argument ignore_case = TRUE.\n\nWhat is the letter after D? \n\nIf you want to ignore differences in whitespace use, use the argument ignore_ws = TRUE (which is the default) and include spaces in your answer anywhere they could be acceptable.\n\nHow do you load the tidyverse package? \n\nYou can set more than one possible correct answer by setting the answers as a vector.\n\nType a vowel: \n\nYou can use regular expressions to test answers against more complex rules.\n\nType any 3 letters: \n\n\n\nMultiple Choice (mcq())\n\n“Never gonna give you up, never gonna: let you goturn you downrun awaylet you down”\n“I bless the rainsguess it rainssense the rain down in Africa” -Toto\n\n\n\nTrue or False (torf())\n\nTrue or False? You can permute values in a vector using sample(). TRUEFALSE\n\n\n\nLonger MCQs (longmcq())\nWhen your answers are very long, sometimes a drop-down select box gets formatted oddly. You can use longmcq() to deal with this. Since the answers are long, It’s probably best to set up the options inside an R chunk with echo=FALSE.\nWhat is a p-value?\n\n the probability that the null hypothesis is true the probability of the observed, or more extreme, data, under the assumption that the null-hypothesis is true the probability of making an error in your conclusion\n\nWhat is true about a 95% confidence interval of the mean?\n\n if you repeated the process many times, 95% of intervals calculated in this way contain the true mean there is a 95% probability that the true mean lies within this range 95% of the data fall within this range"
  },
  {
    "objectID": "webexercises.html#checked-sections",
    "href": "webexercises.html#checked-sections",
    "title": "Webexercises",
    "section": "Checked sections",
    "text": "Checked sections\nCreate sections with the class webex-check to add a button that hides feedback until it is pressed. Add the class webex-box to draw a box around the section (or use your own styles).\n\nI am going to learn a lot: TRUEFALSE\nWhat is a p-value?\n\n the probability that the null hypothesis is true the probability of the observed, or more extreme, data, under the assumption that the null-hypothesis is true the probability of making an error in your conclusion"
  },
  {
    "objectID": "webexercises.html#hidden-solutions-and-hints",
    "href": "webexercises.html#hidden-solutions-and-hints",
    "title": "Webexercises",
    "section": "Hidden solutions and hints",
    "text": "Hidden solutions and hints\nYou can fence off a solution area that will be hidden behind a button using hide() before the solution and unhide() after, each as inline R code. Pass the text you want to appear on the button to the hide() function.\nIf the solution is a code chunk, instead of using hide() and unhide(), simply set the webex.hide chunk option to TRUE, or set it to the string you wish to display on the button.\nRecreate the scatterplot below, using the built-in cars dataset.\n\n\n\n\n\n\n\nI need a hint\n\nSee the documentation for plot() (?plot)\n\n\n\n\n\nClick here to see the solution\n\nplot(cars$speed, cars$dist)"
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "Week 2 Tasks",
    "section": "",
    "text": "An airline industry measure of a passenger airline’s capacity is the available seat miles, which is equal to the number of seats available multiplied by the number of miles or kilometers flown. So for example say an airline had 2 flights using a plane with 10 seats that flew 500 miles and 3 flights using a plane with 20 seats that flew 1000 miles, the available seat miles would be 2 \\(\\times\\) 10 \\(\\times\\) 500 \\(+\\) 3 \\(\\times\\) 20 \\(\\times\\) 1000 = 70,000 seat miles.\nUsing the data sets included in the nycflights13 package, compute the available seat miles for each airline sorted in descending order. After completing all the necessary data wrangling steps, the resulting data frame should have 16 rows (one for each airline) and 2 columns (airline name and available seat miles). Here are some hints:\n\nTake a close look at all the data sets using the View, head or glimpse functions: flights, weather, planes, airports, and airlines to identify which variables are necessary to compute available seat miles.\nThis diagram (from the Joining section) will also be useful.\n\n\n\n\nConsider the data wrangling verbs in the table above as your toolbox!\n\nIf you want to work through it step by step, here are some hints:\nStep 1: To compute the available seat miles for a given flight, we need the distance variable from the flights data frame and the seats variable from the planes data frame, necessitating a join by the key variable tailnum. To keep the resulting data frame easy to view, we’ll select only these two variables and carrier.\nStep 2: Now for each flight we can compute the available seat miles ASM by multiplying the number of seats by the distance via a mutate.\nStep 3: Next we want to sum the ASM for each carrier. We achieve this by first grouping by carrier and then summarising using the sum function.\nStep 4: However, if it was the case that some carriers had certain flights with missing NA values, the resulting table above would also return NA’s (NB: this is not the case for this data). We can eliminate these by adding the na.rm = TRUE argument to sum, telling R that we want to remove the NA’s in the sum.\nStep 5: Finally, arrange the data in descending order of ASM."
  },
  {
    "objectID": "about.html#further-task-1",
    "href": "about.html#further-task-1",
    "title": "Week 2 Tasks",
    "section": "Further Task 1",
    "text": "Further Task 1\nIn this task we will work with the data set analysed and reported in the 2016 article from FiveThirtyEight.com entitled Some People Are Too Superstitious To Have A Baby On Friday The 13th. The data set is called US_births_2000_2014 and is within the fivethirtyeight package.\n\nCreate an object called US_births_2013 which focuses only on data corresponding to 2013 births.\nBy only choosing birth data for the years 2010, 2011, 2012, and 2014 create a new data frame called US_births_small and check that this resulting data frame has 1461 rows. Note that there are many different ways to do this, but try and come up with three different ways using:\n\n\nthe “or” operator |\nthe %in% operator\nthe “not” operator !\n\nor combinations of them.\n\nSuppose we are interested in choosing rows for only weekdays (not Saturdays or Sundays) for day_of_week in year 2013. Write the code to do so and give the name US_births_weekdays_2013 to the resulting data frame. Note that you may want to run US_births_2000_2014 |&gt; distinct(day_of_week) to identify the specific values of day_of_week.\nUsing what you covered in Week 1, produce an appropriate plot looking at the pattern of births on all weekdays in 2013 coloured by the particular day of the week.\nThe plot in the previous task has shown there are some outliers in the data for US births on weekdays in 2013. We can use the summarize function to get an idea for how these outliers may affect the shape of the births variable in US_births_weekdays_2013. Write some code to calculate the mean and median values for all weekday birth totals in 2013. Store this aggregated data in the data frame birth_summ. What do these values suggest about the effects of the outliers?\nInstead of looking at the overall mean and median across all of 2013 weekdays, calculate the mean and median for each of the five different weekdays throughout 2013. Using the same names for the columns as in the birth_summ data frame in the previous exercise, create a new data frame called birth_day_summ.\nUsing the aggregated data in the birth_day_summ data frame, produce this barplot."
  },
  {
    "objectID": "about.html#further-task-2",
    "href": "about.html#further-task-2",
    "title": "Week 2 Tasks",
    "section": "Further Task 2",
    "text": "Further Task 2\nIn this task we will work with the data set analysed and reported in the 2014 article from FiveThirtyEight.com entitled 41 Percent Of Fliers Think You’re Rude If You Recline Your Seat. The data set is called flying and is within the fivethirtyeight package.\n\nWrite code to determine the proportion of respondents in the survey that responded with Very when asked if a passenger reclining their seat was rude. You should determine this proportion across the different levels of age and gender resulting in a data frame of size 8 x 3. Assign the name prop_very to this calculated proportion in this aggregated data frame.\n\n\n\n\n\n\n\nHint 1\n\n\n\nWe can obtain proportions using the mean function applied to logical values. For example suppose we want to count the proportion of “heads” in five tosses of a fair coin. If the results of the five tosses are stored in\ntosses &lt;- c(\"heads\", \"tails\", \"tails\", \"heads\", \"heads\")\nthen we can use mean(tosses == \"heads\") to get the resulting answer of 0.6.\n\n\n\n\n\n\n\n\nHint 2\n\n\n\nIncluding the function na.omit(TRUE) in the ‘pipe’ (|&gt;) removes all entries that are not complete whereas including the argument na.rm=TRUE in the mean function removes just those entries where the relevant variable value is missing.\n\n\n\nUsing the aggregated data you’ve created, produce two bar plots (one stacked, the other side-by-side) to show the differences between the sexes of the proportion of people who believe reclining your seat is ‘very’ rude, within each age group. Also, consider\n\nWhat stands out to you as you review these proportions?\nWhat gender and age-range pairings have the highest and lowest proportions thinking reclining airline seats is very rude in this survey?"
  },
  {
    "objectID": "shorty/example.html",
    "href": "shorty/example.html",
    "title": "Shorty Example",
    "section": "",
    "text": "Hello from Shorty!"
  },
  {
    "objectID": "shorty/example.html#heading",
    "href": "shorty/example.html#heading",
    "title": "Shorty Example",
    "section": "",
    "text": "Hello from Shorty!"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Week 2: Tidying and Wrangling data using R",
    "section": "",
    "text": "This week we will demonstrate various techniques for tidying and wrangling data in R. From the ‘Introduction to R Programming’ course we are familiar with a data frame in R: a rectangular spreadsheet-like representation of data in R where the rows correspond to observations and the columns correspond to variables describing each observation. In Week 1 of Data Analysis, we started exploring the data frame flights included in the nycflights13 package by creating visualisations of the data contained within said data frame.\nHere we will discover a type of data formatting called tidy data. You will see that having data stored in the tidy format is about more than what the colloquial definition of the term tidy might suggest of having your data “neatly organised” in a spreadsheet. Instead, we define the term tidy in a more rigorous fashion, outlining a set of rules by which data can be stored and the implications of these rules on analyses.\n\n\n\n\n\n\nNote\n\n\n\nThis session is based on Chapters 4 and 5 of the open-source book An Introduction to Statistical and Data Science via R which can be consulted at any point.\n\n\nFirst, start by opening RStudio by going to Desktop -&gt; Maths-Stats -&gt; RStudio. Once RStudio has opened create a new R script by going to File -&gt; New File -&gt; R Script. Next go to File -&gt; Save As... and save the script into your personal drive, either M: or K: (do not save it to the H: drive). We shall now load into R all of the libraries we will need for this session. This can be done by typing the following into your R script:\n\nCodelibrary(tidyverse)\nlibrary(nycflights13)\nlibrary(fivethirtyeight)\n\n\nThe tidyverse library is actually a collection of different R packages for transforming and visualising data. The final two libraries (nycflights13 and fivethirtyeight) contain interesting data sets that we shall examine in this session. Notice that when loading the tidyverse package you get a message that tells you about conflicting functions of certain packages. This means that there is at least one or more functions with the same name loaded from different packages (and thus one the function will mask the other). You can use the function tidyverse_conflicts() for getting a list of the conflicted packages:\n\nCodetidyverse_conflicts()\n\n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter() masks stats::filter()\n✖ dplyr::lag()    masks stats::lag()\nℹ Use the conflicted package (&lt;http://conflicted.r-lib.org/&gt;) to force all conflicts to become errors\n\n\nIn here, we can see for example that the filter function from the dplyr package has a conflict with the filter function in base R stats library. A way of sorting that out is to load the dplyr library after base R so that R will only consider the version of the function that was last loaded. We can be more rigorous about this and load the conflicted library. This will prohibit us to us any functions that have some conflict with previously defined functions.\n\nCodelibrary(conflicted)\n\n\nBy doing this, we would need to be more specific about the source package from which the desired function should be loaded. There are two ways of doing this:\n\nUsing :: after calling the package name every time we use the function from that package. E.g., dplyr::filter(…) will tell R to explicitly use the function filter from the dplyr library.\nUsing the conflicts_prefer(\"function\",\"package\") function to explicitly declare which version of the function you want to use in the remaining R session (i.e. after conflicts_prefer() is called, e.g., conflict_prefer(\"filter\",\"dplyr\") .\n\n\n\n\n\n\n\n Question\n\n\n\nWhat do you think is the advantage of using the conflicts_prefer as opposed to the first approach?"
  },
  {
    "objectID": "index.html#method-1-from-the-console",
    "href": "index.html#method-1-from-the-console",
    "title": "Week 2: Tidying and Wrangling data using R",
    "section": "\n5.1 Method 1: From the console",
    "text": "5.1 Method 1: From the console\nFirst, let’s download a Comma Separated Values (CSV) file of ratings of the level of democracy in different countries spanning 1952 to 1992: https://moderndive.com/data/dem_score.csv. We use the read_csv() function from the readr package to read it off the web:\n\nCodedem_score &lt;- read_csv(\"https://moderndive.com/data/dem_score.csv\")\n\n# A tibble: 96 × 10\n   country    `1952` `1957` `1962` `1967` `1972` `1977` `1982` `1987` `1992`\n   &lt;chr&gt;       &lt;dbl&gt;  &lt;dbl&gt;  &lt;dbl&gt;  &lt;dbl&gt;  &lt;dbl&gt;  &lt;dbl&gt;  &lt;dbl&gt;  &lt;dbl&gt;  &lt;dbl&gt;\n 1 Albania        -9     -9     -9     -9     -9     -9     -9     -9      5\n 2 Argentina      -9     -1     -1     -9     -9     -9     -8      8      7\n 3 Armenia        -9     -7     -7     -7     -7     -7     -7     -7      7\n 4 Australia      10     10     10     10     10     10     10     10     10\n 5 Austria        10     10     10     10     10     10     10     10     10\n 6 Azerbaijan     -9     -7     -7     -7     -7     -7     -7     -7      1\n 7 Belarus        -9     -7     -7     -7     -7     -7     -7     -7      7\n 8 Belgium        10     10     10     10     10     10     10     10     10\n 9 Bhutan        -10    -10    -10    -10    -10    -10    -10    -10    -10\n10 Bolivia        -4     -3     -3     -4     -7     -7      8      9      9\n# ℹ 86 more rows\n\n\nIn this dem_score data frame, the minimum value of -10 corresponds to a highly autocratic nation whereas a value of 10 corresponds to a highly democratic nation."
  },
  {
    "objectID": "index.html#method-2-using-rstudios-interface",
    "href": "index.html#method-2-using-rstudios-interface",
    "title": "Week 2: Tidying and Wrangling data using R",
    "section": "\n5.2 Method 2: Using RStudio’s interface",
    "text": "5.2 Method 2: Using RStudio’s interface\nLet’s read in the same data saved in Excel format this time at https://moderndive.com/data/dem_score.xlsx, but using RStudio’s graphical interface instead of via the R console. First download the Excel file, then go to the Files -&gt; Import Dataset -&gt; From Excel... and navigate to the directory where your downloaded dem_score.xlsx using Browse.... You should see something similar to the image below:\n\n\n\n\n\nAfter clicking on the Import button on the bottom-right save this spreadsheet’s data in a data frame called dem_score and display its contents in the spreadsheet viewer (View()). Furthermore you’ll see the code that read in your data in the console; you can copy and paste this code to reload your data again later instead of repeating the above manual process.\n\n\n\n\n\n\nCaution\n\n\n\nNote that if you use the xlsx package to import .xlsx files is important to have the latest version of java installed in your local PC. The xlsx package depends on the rJava package which requires the Java Runtime Environment 1.2 or above. Download and install the latest version of the Java Runtime Environment from Oracle.\n\n\n\n\n\n\n\n\nTask\n\n\n\nRead in the life expectancy data stored at https://moderndive.com/data/le_mess.csv, either using the R console or RStudio’s interface."
  },
  {
    "objectID": "index.html#piping",
    "href": "index.html#piping",
    "title": "Week 2: Tidying and Wrangling data using R",
    "section": "\n7.1 The pipe |>",
    "text": "7.1 The pipe |&gt;\nBefore we dig into data wrangling, let’s first introduce the pipe operator (|&gt;). Just as the + sign was used to add layers to a plot created using ggplot, the pipe operator allows us to chain together data wrangling functions. The pipe operator can be read as then. The |&gt; operator allows us to go from one step in to the next easily so we can, for example:\n\n\nfilter our data frame to only focus on a few rows then\n\n\ngroup_by another variable to create groups then\n\n\nsummarize this grouped data to calculate the mean for each level of the group.\n\nThe piping syntax will be our major focus throughout the rest of this course and you’ll find that you’ll quickly be addicted to the chaining with some practice."
  },
  {
    "objectID": "index.html#verbs",
    "href": "index.html#verbs",
    "title": "Week 2: Tidying and Wrangling data using R",
    "section": "\n7.2 Data wrangling verbs",
    "text": "7.2 Data wrangling verbs\nThe d in dplyr stands for data frames, so the functions in dplyr are built for working with objects of the data frame type. For now, we focus on the most commonly used functions that help wrangle and summarise data. A description of these verbs follows, with each subsequent section devoted to an example of that verb, or a combination of a few verbs, in action.\n\n\nfilter: Pick rows based on conditions about their values\n\nsummarize: Compute summary measures known as “summary statistics” of variables\n\ngroup_by: Group rows of observations together\n\nmutate: Create a new variable in the data frame by mutating existing ones\n\narrange: Arrange/sort the rows based on one or more variables\n\njoin: Join/merge two data frames by matching along a “key” variable. There are many different joins available. Here, we will focus on the inner_join function.\n\nAll of the verbs are used similarly where you: take a data frame, pipe it using the %&gt;% syntax into one of the verbs above followed by other arguments specifying which criteria you would like the verb to work with in parentheses."
  },
  {
    "objectID": "index.html#grouping-by-more-than-one-variable",
    "href": "index.html#grouping-by-more-than-one-variable",
    "title": "Week 2: Tidying and Wrangling data using R",
    "section": "\n10.1 Grouping by more than one variable",
    "text": "10.1 Grouping by more than one variable\nYou are not limited to grouping by one variable. Say you wanted to know the number of flights leaving each of the three New York City airports for each month, we can also group by a second variable month:\n\nCodeby_origin_monthly &lt;- flights |&gt; \n  summarize(count = n(), \n            .by = c(origin, month))\nby_origin_monthly\n\n# A tibble: 36 × 3\n   origin month count\n   &lt;chr&gt;  &lt;int&gt; &lt;int&gt;\n 1 EWR        1  9893\n 2 LGA        1  7950\n 3 JFK        1  9161\n 4 EWR       10 10104\n 5 JFK       10  9143\n 6 LGA       10  9642\n 7 JFK       11  8710\n 8 EWR       11  9707\n 9 LGA       11  8851\n10 JFK       12  9146\n# ℹ 26 more rows\n\n\nWe see there are 36 rows for by_origin_monthly because there are 12 months times 3 airports (EWR, JFK, and LGA). Let’s now pose a question.\n\nFirst, what if we reverse the order of the grouping, i.e. .by = c(month, origin)?\n\n\nCodeby_monthly_origin &lt;- flights |&gt; \n  summarize(count = n(), \n            .by = c(month,origin))\nby_monthly_origin\n\n# A tibble: 36 × 3\n   month origin count\n   &lt;int&gt; &lt;chr&gt;  &lt;int&gt;\n 1     1 EWR     9893\n 2     1 LGA     7950\n 3     1 JFK     9161\n 4    10 EWR    10104\n 5    10 JFK     9143\n 6    10 LGA     9642\n 7    11 JFK     8710\n 8    11 EWR     9707\n 9    11 LGA     8851\n10    12 JFK     9146\n# ℹ 26 more rows\n\n\nIn by_monthly_origin the month column is now first and the rows are sorted by month instead of origin. If you compare the values of count in by_origin_monthly and by_monthly_origin using the View function, you’ll see that the values are actually the same, just presented in a different order.\n\n\n\n\n\n\n Question\n\n\n\nRecall from Week 1 when we looked at plots of temperatures by months in NYC. What does the standard deviation column in the summary_monthly_temp data frame tell us about temperatures in New York City throughout the year?\n\nTemperature are lower in the winter Temperature variability increases during winterSpring is the season with more outliers \n\n\n\n\n\n\n\n\n\nTask\n\n\n\nWrite code to produce the mean and standard deviation temperature for each day in 2013 for NYC\n\n\nTake a hint\n\nSee the documentation for plot() (?plot)\n\n\n\n\nClick here to see the solution\n\nCode weather |&gt; \n  summarize(mean = mean(temp, na.rm = TRUE), \n            std_dev = sd(temp, na.rm = TRUE),\n            .by = day)\n\n# A tibble: 31 × 3\n     day  mean std_dev\n   &lt;int&gt; &lt;dbl&gt;   &lt;dbl&gt;\n 1     1  57.6    17.4\n 2     2  55.7    20.2\n 3     3  53.8    18.9\n 4     4  54.0    18.8\n 5     5  55.6    16.2\n 6     6  55.7    15.6\n 7     7  55.6    17.4\n 8     8  55.0    17.6\n 9     9  56.6    17.4\n10    10  56.9    17.8\n# ℹ 21 more rows\n\n\n\n\n\n\n\n\n\n\n\nTask\n\n\n\nHow could we identify how many flights left each of the three airports for each carrier? Can you create a bar plot showing these results?\n\n\nTake a hint\n\nYou can count how many flights left each of the three airports by summarising the data using the n() function while grouping by the origin and carrier. Then, you can pass the resulting data frame to ggplot using the pipeline command |&gt; and use a geom_col layer as we saw in the previous week.\n\n\n\n\nClick here to see the solution\n\nCodeflights |&gt; \n  summarise(count = n(), \n            .by = c(origin,carrier)) |&gt;\n  ggplot(aes(x = carrier, y = count, fill = origin)) + geom_col()"
  },
  {
    "objectID": "index.html#joining-by-key-variables",
    "href": "index.html#joining-by-key-variables",
    "title": "Week 2: Tidying and Wrangling data using R",
    "section": "\n13.1 Joining by “key” variables",
    "text": "13.1 Joining by “key” variables\nIn both flights and airlines, the key variable we want to join/merge/match the two data frames with has the same name in both data sets: carriers. We make use of the inner_join function to join by the variable carrier.\n\nCodeflights_joined &lt;- flights |&gt; \n  inner_join(airlines, \n             by = join_by(carrier))\n             \nflights\n\n# A tibble: 336,776 × 22\n    year month   day dep_time sched_dep_time dep_delay arr_time sched_arr_time\n   &lt;int&gt; &lt;int&gt; &lt;int&gt;    &lt;int&gt;          &lt;int&gt;     &lt;dbl&gt;    &lt;int&gt;          &lt;int&gt;\n 1  2013     1     1      517            515         2      830            819\n 2  2013     1     1      533            529         4      850            830\n 3  2013     1     1      542            540         2      923            850\n 4  2013     1     1      544            545        -1     1004           1022\n 5  2013     1     1      554            600        -6      812            837\n 6  2013     1     1      554            558        -4      740            728\n 7  2013     1     1      555            600        -5      913            854\n 8  2013     1     1      557            600        -3      709            723\n 9  2013     1     1      557            600        -3      838            846\n10  2013     1     1      558            600        -2      753            745\n# ℹ 336,766 more rows\n# ℹ 14 more variables: arr_delay &lt;dbl&gt;, carrier &lt;chr&gt;, flight &lt;int&gt;,\n#   tailnum &lt;chr&gt;, origin &lt;chr&gt;, dest &lt;chr&gt;, air_time &lt;dbl&gt;, distance &lt;dbl&gt;,\n#   hour &lt;dbl&gt;, minute &lt;dbl&gt;, time_hour &lt;dttm&gt;, gain &lt;dbl&gt;, hours &lt;dbl&gt;,\n#   gain_per_hour &lt;dbl&gt;\n\nCodeflights_joined\n\n# A tibble: 336,776 × 23\n    year month   day dep_time sched_dep_time dep_delay arr_time sched_arr_time\n   &lt;int&gt; &lt;int&gt; &lt;int&gt;    &lt;int&gt;          &lt;int&gt;     &lt;dbl&gt;    &lt;int&gt;          &lt;int&gt;\n 1  2013     1     1      517            515         2      830            819\n 2  2013     1     1      533            529         4      850            830\n 3  2013     1     1      542            540         2      923            850\n 4  2013     1     1      544            545        -1     1004           1022\n 5  2013     1     1      554            600        -6      812            837\n 6  2013     1     1      554            558        -4      740            728\n 7  2013     1     1      555            600        -5      913            854\n 8  2013     1     1      557            600        -3      709            723\n 9  2013     1     1      557            600        -3      838            846\n10  2013     1     1      558            600        -2      753            745\n# ℹ 336,766 more rows\n# ℹ 15 more variables: arr_delay &lt;dbl&gt;, carrier &lt;chr&gt;, flight &lt;int&gt;,\n#   tailnum &lt;chr&gt;, origin &lt;chr&gt;, dest &lt;chr&gt;, air_time &lt;dbl&gt;, distance &lt;dbl&gt;,\n#   hour &lt;dbl&gt;, minute &lt;dbl&gt;, time_hour &lt;dttm&gt;, gain &lt;dbl&gt;, hours &lt;dbl&gt;,\n#   gain_per_hour &lt;dbl&gt;, name &lt;chr&gt;\n\n\nWe observe that the flights and flights_joined are identical except that flights_joined has an additional variable name whose values were drawn from airlines.\nA visual representation of the inner_join is given below:\n\n\n\n\nDiagram of inner join from R for Data Science.\n\n\n\nThere are more complex joins available, but the inner_join will solve nearly all of the problems you will face here."
  },
  {
    "objectID": "index.html#joining-by-key-variables-with-different-names",
    "href": "index.html#joining-by-key-variables-with-different-names",
    "title": "Week 2: Tidying and Wrangling data using R",
    "section": "\n13.2 Joining by “key” variables with different names",
    "text": "13.2 Joining by “key” variables with different names\nSay instead, you are interested in all the destinations of flights from NYC in 2013 and ask yourself:\n\n“What cities are these airports in?”\n“Is ORD Orlando?”\n“Where is FLL?”\n\nThe airports data frame contains airport codes:\n\nCodeairports\n\n# A tibble: 1,458 × 8\n   faa   name                             lat    lon   alt    tz dst   tzone    \n   &lt;chr&gt; &lt;chr&gt;                          &lt;dbl&gt;  &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;chr&gt; &lt;chr&gt;    \n 1 04G   Lansdowne Airport               41.1  -80.6  1044    -5 A     America/…\n 2 06A   Moton Field Municipal Airport   32.5  -85.7   264    -6 A     America/…\n 3 06C   Schaumburg Regional             42.0  -88.1   801    -6 A     America/…\n 4 06N   Randall Airport                 41.4  -74.4   523    -5 A     America/…\n 5 09J   Jekyll Island Airport           31.1  -81.4    11    -5 A     America/…\n 6 0A9   Elizabethton Municipal Airport  36.4  -82.2  1593    -5 A     America/…\n 7 0G6   Williams County Airport         41.5  -84.5   730    -5 A     America/…\n 8 0G7   Finger Lakes Regional Airport   42.9  -76.8   492    -5 A     America/…\n 9 0P2   Shoestring Aviation Airfield    39.8  -76.6  1000    -5 U     America/…\n10 0S9   Jefferson County Intl           48.1 -123.    108    -8 A     America/…\n# ℹ 1,448 more rows\n\n\nHowever, looking at both the airports and flights and the visual representation of the relations between the data frames in the figure above, we see that in:\n\n\nairports the airport code is in the variable faa\n\n\nflights the airport code is in the variable origin\n\n\nSo to join these two data sets, our inner_join operation involves a logical operator == argument that accounts for the different names.\n\nCodeflights |&gt; \n  inner_join(airports,\n             by = join_by(dest == faa))\n\n\nWe can read the code out loud as:\nLet’s construct the sequence of commands that computes the number of flights from NYC to each destination, but also includes information about each destination airport:\n\nCodenamed_dests &lt;- flights|&gt;\n  summarize(num_flights = n(),\n            .by = dest) |&gt;\n  arrange(desc(num_flights)) |&gt;\n  inner_join(airports, by = join_by(dest == faa)) %&gt;%\n  rename(airport_name = name)\n\n# A tibble: 101 × 9\n   dest  num_flights airport_name             lat    lon   alt    tz dst   tzone\n   &lt;chr&gt;       &lt;int&gt; &lt;chr&gt;                  &lt;dbl&gt;  &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;chr&gt; &lt;chr&gt;\n 1 ORD         17283 Chicago Ohare Intl      42.0  -87.9   668    -6 A     Amer…\n 2 ATL         17215 Hartsfield Jackson At…  33.6  -84.4  1026    -5 A     Amer…\n 3 LAX         16174 Los Angeles Intl        33.9 -118.    126    -8 A     Amer…\n 4 BOS         15508 General Edward Lawren…  42.4  -71.0    19    -5 A     Amer…\n 5 MCO         14082 Orlando Intl            28.4  -81.3    96    -5 A     Amer…\n 6 CLT         14064 Charlotte Douglas Intl  35.2  -80.9   748    -5 A     Amer…\n 7 SFO         13331 San Francisco Intl      37.6 -122.     13    -8 A     Amer…\n 8 FLL         12055 Fort Lauderdale Holly…  26.1  -80.2     9    -5 A     Amer…\n 9 MIA         11728 Miami Intl              25.8  -80.3     8    -5 A     Amer…\n10 DCA          9705 Ronald Reagan Washing…  38.9  -77.0    15    -5 A     Amer…\n# ℹ 91 more rows\n\n\nIn case you didn’t know, ORD is the airport code of Chicago O’Hare airport and FLL is the main airport in Fort Lauderdale, Florida, which we can now see in our named_dests data frame."
  },
  {
    "objectID": "index.html#joining-by-multiple-key-variables",
    "href": "index.html#joining-by-multiple-key-variables",
    "title": "Week 2: Tidying and Wrangling data using R",
    "section": "\n13.3 Joining by multiple “key” variables",
    "text": "13.3 Joining by multiple “key” variables\nSay instead we are in a situation where we need to join by multiple variables. For example, in the first figure in this section we see that in order to join the flights and weather data frames, we need more than one key variable: year, month, day, hour, and origin. This is because the combination of these 5 variables act to uniquely identify each observational unit in the weather data frame: hourly weather recordings at each of the 3 NYC airports.\nWe achieve this by specifying a vector of key variables to join by.\n\nCodeflights_weather_joined &lt;- flights |&gt;\n  inner_join(weather, \n             by = join_by(year,month,day,hour,origin))\n\n# A tibble: 335,220 × 32\n    year month   day dep_time sched_dep_time dep_delay arr_time sched_arr_time\n   &lt;int&gt; &lt;int&gt; &lt;int&gt;    &lt;int&gt;          &lt;int&gt;     &lt;dbl&gt;    &lt;int&gt;          &lt;int&gt;\n 1  2013     1     1      517            515         2      830            819\n 2  2013     1     1      533            529         4      850            830\n 3  2013     1     1      542            540         2      923            850\n 4  2013     1     1      544            545        -1     1004           1022\n 5  2013     1     1      554            600        -6      812            837\n 6  2013     1     1      554            558        -4      740            728\n 7  2013     1     1      555            600        -5      913            854\n 8  2013     1     1      557            600        -3      709            723\n 9  2013     1     1      557            600        -3      838            846\n10  2013     1     1      558            600        -2      753            745\n# ℹ 335,210 more rows\n# ℹ 24 more variables: arr_delay &lt;dbl&gt;, carrier &lt;chr&gt;, flight &lt;int&gt;,\n#   tailnum &lt;chr&gt;, origin &lt;chr&gt;, dest &lt;chr&gt;, air_time &lt;dbl&gt;, distance &lt;dbl&gt;,\n#   hour &lt;dbl&gt;, minute &lt;dbl&gt;, time_hour.x &lt;dttm&gt;, gain &lt;dbl&gt;, hours &lt;dbl&gt;,\n#   gain_per_hour &lt;dbl&gt;, temp &lt;dbl&gt;, dewp &lt;dbl&gt;, humid &lt;dbl&gt;, wind_dir &lt;dbl&gt;,\n#   wind_speed &lt;dbl&gt;, wind_gust &lt;dbl&gt;, precip &lt;dbl&gt;, pressure &lt;dbl&gt;,\n#   visib &lt;dbl&gt;, time_hour.y &lt;dttm&gt;\n\n\n\n\n\n\n\n\n Question\n\n\n\nLooking at the first figure in this section, when joining flights and weather (or, in other words, matching the hourly weather values with each flight), why do we need to join by all of year, month, day, hour, and origin, and not just hour?\n\n\nAnswer\n\nyear,month,day,hour,origin are the key variables that allow us to uniquely identify the observational units."
  },
  {
    "objectID": "index.html#select",
    "href": "index.html#select",
    "title": "Week 2: Tidying and Wrangling data using R",
    "section": "\n14.1 Select variables using select",
    "text": "14.1 Select variables using select\n\n\n\n\nSelect diagram from Data Wrangling with dplyr and tidyr cheatsheet.\n\n\n\nWe’ve seen that the flights data frame in the nycflights13 package contains many different variables. The names function gives a listing of all the columns in a data frame; in our case you would run names(flights). You can also identify these variables by running the glimpse function in the dplyr package:\n\nCodeglimpse(flights)\n\nRows: 336,776\nColumns: 22\n$ year           &lt;int&gt; 2013, 2013, 2013, 2013, 2013, 2013, 2013, 2013, 2013, 2…\n$ month          &lt;int&gt; 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1…\n$ day            &lt;int&gt; 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1…\n$ dep_time       &lt;int&gt; 517, 533, 542, 544, 554, 554, 555, 557, 557, 558, 558, …\n$ sched_dep_time &lt;int&gt; 515, 529, 540, 545, 600, 558, 600, 600, 600, 600, 600, …\n$ dep_delay      &lt;dbl&gt; 2, 4, 2, -1, -6, -4, -5, -3, -3, -2, -2, -2, -2, -2, -1…\n$ arr_time       &lt;int&gt; 830, 850, 923, 1004, 812, 740, 913, 709, 838, 753, 849,…\n$ sched_arr_time &lt;int&gt; 819, 830, 850, 1022, 837, 728, 854, 723, 846, 745, 851,…\n$ arr_delay      &lt;dbl&gt; 11, 20, 33, -18, -25, 12, 19, -14, -8, 8, -2, -3, 7, -1…\n$ carrier        &lt;chr&gt; \"UA\", \"UA\", \"AA\", \"B6\", \"DL\", \"UA\", \"B6\", \"EV\", \"B6\", \"…\n$ flight         &lt;int&gt; 1545, 1714, 1141, 725, 461, 1696, 507, 5708, 79, 301, 4…\n$ tailnum        &lt;chr&gt; \"N14228\", \"N24211\", \"N619AA\", \"N804JB\", \"N668DN\", \"N394…\n$ origin         &lt;chr&gt; \"EWR\", \"LGA\", \"JFK\", \"JFK\", \"LGA\", \"EWR\", \"EWR\", \"LGA\",…\n$ dest           &lt;chr&gt; \"IAH\", \"IAH\", \"MIA\", \"BQN\", \"ATL\", \"ORD\", \"FLL\", \"IAD\",…\n$ air_time       &lt;dbl&gt; 227, 227, 160, 183, 116, 150, 158, 53, 140, 138, 149, 1…\n$ distance       &lt;dbl&gt; 1400, 1416, 1089, 1576, 762, 719, 1065, 229, 944, 733, …\n$ hour           &lt;dbl&gt; 5, 5, 5, 5, 6, 5, 6, 6, 6, 6, 6, 6, 6, 6, 6, 5, 6, 6, 6…\n$ minute         &lt;dbl&gt; 15, 29, 40, 45, 0, 58, 0, 0, 0, 0, 0, 0, 0, 0, 0, 59, 0…\n$ time_hour      &lt;dttm&gt; 2013-01-01 05:00:00, 2013-01-01 05:00:00, 2013-01-01 0…\n$ gain           &lt;dbl&gt; -9, -16, -31, 17, 19, -16, -24, 11, 5, -10, 0, 1, -9, 1…\n$ hours          &lt;dbl&gt; 3.7833333, 3.7833333, 2.6666667, 3.0500000, 1.9333333, …\n$ gain_per_hour  &lt;dbl&gt; -2.3788546, -4.2290749, -11.6250000, 5.5737705, 9.82758…\n\n\nHowever, say you only want to consider two of these variables, say carrier and flight. You can select these:\n\nCodeflights |&gt; \n  select(carrier, flight)\n\n# A tibble: 336,776 × 2\n   carrier flight\n   &lt;chr&gt;    &lt;int&gt;\n 1 UA        1545\n 2 UA        1714\n 3 AA        1141\n 4 B6         725\n 5 DL         461\n 6 UA        1696\n 7 B6         507\n 8 EV        5708\n 9 B6          79\n10 AA         301\n# ℹ 336,766 more rows\n\n\nThis function makes navigating data sets with a very large number of variables easier for humans by restricting consideration to only those of interest, like carrier and flight above. So for example, this might make viewing the data set using the View spreadsheet viewer more digestible. However, as far as the computer is concerned it does not care how many additional variables are in the data set in question, so long as carrier and flight are included.\nAnother example involves the variable year. If you remember the original description of the flights data frame (or by running ?flights), you will remember that this data corresponds to flights in 2013 departing New York City. The year variable isn’t really a variable here in that it doesn’t vary, the flights data set actually comes from a larger data set that covers many years. We may want to remove the year variable from our data set since it won’t be helpful for analysis in this case. We can deselect year by using the - sign:\n\nCodeflights_no_year &lt;- flights |&gt; \n  select(-year)\n\n\nOr we could specify a ranges of columns:\n\nCodeflight_arr_times &lt;- flights |&gt; \n  select(month:dep_time, arr_time:sched_arr_time)\n\n# A tibble: 336,776 × 5\n   month   day dep_time arr_time sched_arr_time\n   &lt;int&gt; &lt;int&gt;    &lt;int&gt;    &lt;int&gt;          &lt;int&gt;\n 1     1     1      517      830            819\n 2     1     1      533      850            830\n 3     1     1      542      923            850\n 4     1     1      544     1004           1022\n 5     1     1      554      812            837\n 6     1     1      554      740            728\n 7     1     1      555      913            854\n 8     1     1      557      709            723\n 9     1     1      557      838            846\n10     1     1      558      753            745\n# ℹ 336,766 more rows\n\n\nThe select function can also be used to reorder columns in combination with the everything helper function. Let’s suppose we would like the hour, minute, and time_hour variables, which appear at the end of the flights data set, to actually appear immediately after the day variable:\n\nCodeflights_reorder &lt;- flights |&gt; \n  select(month:day, hour:time_hour, everything())\n\n [1] \"month\"          \"day\"            \"hour\"           \"minute\"        \n [5] \"time_hour\"      \"year\"           \"dep_time\"       \"sched_dep_time\"\n [9] \"dep_delay\"      \"arr_time\"       \"sched_arr_time\" \"arr_delay\"     \n[13] \"carrier\"        \"flight\"         \"tailnum\"        \"origin\"        \n[17] \"dest\"           \"air_time\"       \"distance\"       \"gain\"          \n[21] \"hours\"          \"gain_per_hour\" \n\n\nin this case everything() picks up all remaining variables. Lastly, the helper functions starts_with, ends_with, and contains can be used to choose variables / column names that match those conditions:\n\nCodeflights_begin_a &lt;- flights |&gt; \n  select(starts_with(\"a\"))\n\n# A tibble: 336,776 × 3\n   arr_time arr_delay air_time\n      &lt;int&gt;     &lt;dbl&gt;    &lt;dbl&gt;\n 1      830        11      227\n 2      850        20      227\n 3      923        33      160\n 4     1004       -18      183\n 5      812       -25      116\n 6      740        12      150\n 7      913        19      158\n 8      709       -14       53\n 9      838        -8      140\n10      753         8      138\n# ℹ 336,766 more rows\n\n\n\nCodeflights_delays &lt;- flights |&gt; \n  select(ends_with(\"delay\"))\n\n# A tibble: 336,776 × 2\n   dep_delay arr_delay\n       &lt;dbl&gt;     &lt;dbl&gt;\n 1         2        11\n 2         4        20\n 3         2        33\n 4        -1       -18\n 5        -6       -25\n 6        -4        12\n 7        -5        19\n 8        -3       -14\n 9        -3        -8\n10        -2         8\n# ℹ 336,766 more rows\n\n\n\nCodeflights_time &lt;- flights |&gt; \n  select(contains(\"time\"))\n\n# A tibble: 336,776 × 6\n   dep_time sched_dep_time arr_time sched_arr_time air_time time_hour          \n      &lt;int&gt;          &lt;int&gt;    &lt;int&gt;          &lt;int&gt;    &lt;dbl&gt; &lt;dttm&gt;             \n 1      517            515      830            819      227 2013-01-01 05:00:00\n 2      533            529      850            830      227 2013-01-01 05:00:00\n 3      542            540      923            850      160 2013-01-01 05:00:00\n 4      544            545     1004           1022      183 2013-01-01 05:00:00\n 5      554            600      812            837      116 2013-01-01 06:00:00\n 6      554            558      740            728      150 2013-01-01 05:00:00\n 7      555            600      913            854      158 2013-01-01 06:00:00\n 8      557            600      709            723       53 2013-01-01 06:00:00\n 9      557            600      838            846      140 2013-01-01 06:00:00\n10      558            600      753            745      138 2013-01-01 06:00:00\n# ℹ 336,766 more rows"
  },
  {
    "objectID": "index.html#rename",
    "href": "index.html#rename",
    "title": "Week 2: Tidying and Wrangling data using R",
    "section": "\n14.2 Rename variables using rename",
    "text": "14.2 Rename variables using rename\nAnother useful function is rename, which as you may suspect renames one column to another name. Suppose we wanted dep_time and arr_time to be departure_time and arrival_time instead in the flights_time data frame:\n\nCodeflights_time &lt;- flights |&gt; \n  select(contains(\"time\")) |&gt; \n  rename(departure_time = dep_time,\n         arrival_time = arr_time)\n\n[1] \"departure_time\" \"sched_dep_time\" \"arrival_time\"   \"sched_arr_time\"\n[5] \"air_time\"       \"time_hour\"     \n\n\nNote that in this case we used a single = sign with rename. eg. departure_time = dep_time. This is because we are not testing for equality like we would using ==, but instead we want to assign a new variable departure_time to have the same values as dep_time and then delete the variable dep_time."
  },
  {
    "objectID": "index.html#find-the-top-number-of-values-using-slice",
    "href": "index.html#find-the-top-number-of-values-using-slice",
    "title": "Week 2: Tidying and Wrangling data using R",
    "section": "\n14.3 Find the top number of values using slice",
    "text": "14.3 Find the top number of values using slice\nWe can also use the slice_max() function which automatically tells us the most frequent num_flights. We specify the top 10 airports here:\n\nCodenamed_dests |&gt; \n  slice_max(num_flights, n = 10)\n\n# A tibble: 10 × 9\n   dest  num_flights airport_name             lat    lon   alt    tz dst   tzone\n   &lt;chr&gt;       &lt;int&gt; &lt;chr&gt;                  &lt;dbl&gt;  &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;chr&gt; &lt;chr&gt;\n 1 ORD         17283 Chicago Ohare Intl      42.0  -87.9   668    -6 A     Amer…\n 2 ATL         17215 Hartsfield Jackson At…  33.6  -84.4  1026    -5 A     Amer…\n 3 LAX         16174 Los Angeles Intl        33.9 -118.    126    -8 A     Amer…\n 4 BOS         15508 General Edward Lawren…  42.4  -71.0    19    -5 A     Amer…\n 5 MCO         14082 Orlando Intl            28.4  -81.3    96    -5 A     Amer…\n 6 CLT         14064 Charlotte Douglas Intl  35.2  -80.9   748    -5 A     Amer…\n 7 SFO         13331 San Francisco Intl      37.6 -122.     13    -8 A     Amer…\n 8 FLL         12055 Fort Lauderdale Holly…  26.1  -80.2     9    -5 A     Amer…\n 9 MIA         11728 Miami Intl              25.8  -80.3     8    -5 A     Amer…\n10 DCA          9705 Ronald Reagan Washing…  38.9  -77.0    15    -5 A     Amer…\n\n\nWe can find the most frequent flights in a single pipeline as follows:\n\nCodeten_freq_dests &lt;- flights |&gt;\n  summarize(num_flights = n(),\n            .by = dest) |&gt;\n  slice_max(num_flights, n = 10) \n\n# A tibble: 10 × 2\n   dest  num_flights\n   &lt;chr&gt;       &lt;int&gt;\n 1 ORD         17283\n 2 ATL         17215\n 3 LAX         16174\n 4 BOS         15508\n 5 MCO         14082\n 6 CLT         14064\n 7 SFO         13331\n 8 FLL         12055\n 9 MIA         11728\n10 DCA          9705\n\n\n\n\n\n\n\n\nTask\n\n\n\nHow could one use starts_with, ends_with, and contains to select columns from the flights data frame? Provide three different examples in total: one for starts_with, one for ends_with, and one for contains.\n\n\n\nClick here to see the solution\n\nCode# Select arrival time and arrival delay columns\nflights |&gt;\n  select(starts_with(\"arr\"))\n\n# A tibble: 336,776 × 2\n   arr_time arr_delay\n      &lt;int&gt;     &lt;dbl&gt;\n 1      830        11\n 2      850        20\n 3      923        33\n 4     1004       -18\n 5      812       -25\n 6      740        12\n 7      913        19\n 8      709       -14\n 9      838        -8\n10      753         8\n# ℹ 336,766 more rows\n\nCode# Select departure and arrival delay columns\nflights |&gt;\n  select(ends_with(\"delay\"))\n\n# A tibble: 336,776 × 2\n   dep_delay arr_delay\n       &lt;dbl&gt;     &lt;dbl&gt;\n 1         2        11\n 2         4        20\n 3         2        33\n 4        -1       -18\n 5        -6       -25\n 6        -4        12\n 7        -5        19\n 8        -3       -14\n 9        -3        -8\n10        -2         8\n# ℹ 336,766 more rows\n\nCode# Select departure times, schedule  departure and departure delay columns\nflights |&gt;\n  select(contains(\"dep\"))\n\n# A tibble: 336,776 × 3\n   dep_time sched_dep_time dep_delay\n      &lt;int&gt;          &lt;int&gt;     &lt;dbl&gt;\n 1      517            515         2\n 2      533            529         4\n 3      542            540         2\n 4      544            545        -1\n 5      554            600        -6\n 6      554            558        -4\n 7      555            600        -5\n 8      557            600        -3\n 9      557            600        -3\n10      558            600        -2\n# ℹ 336,766 more rows\n\n\n\n\n\n\n\n\n\n\n\nTask\n\n\n\nCreate a new data frame that shows the top 5 airports with the largest average arrival delays from NYC in 2013.\n\n\nTake a hint\n\nCompute the mean arrival delay from each destination. You can then join the resulting data set with the airports data which contains the airports names and search for the top 5 entries.\n\n\n\n\nClick here to see the solution\n\nCode  flights|&gt;\n  summarize(mean_arr_delay = mean(arr_delay,na.rm=T),\n            .by = dest) |&gt;\n  inner_join(airports, by = join_by(dest == faa)) |&gt;\n  rename(airport_name = name) |&gt;\n    slice_max(mean_arr_delay,n=5)"
  },
  {
    "objectID": "index.html#vectorised-if-else-thru-case_when",
    "href": "index.html#vectorised-if-else-thru-case_when",
    "title": "Week 2: Tidying and Wrangling data using R",
    "section": "\n14.4 Vectorised if-else thru case_when\n",
    "text": "14.4 Vectorised if-else thru case_when\n\ncase_when serves as a method to streamline multiple if-else statements by vectorizing them. It allows us to assess a condition expression and make decisions accordingly. For instance, consider a scenario where we need to categorize weather conditions according to the meteorological data contained in the weather data set.\nLet suppose that we want to categorize the temperature variable into three categories:\n\nlow for temperatures \\(&lt;39.9\\)\nmedium for temperature values \\(\\geq 39.9\\) and \\(\\leq 70\\)\nhigh for temperature values \\(&gt; 70\\)\n\nWe can achieve this with the following code:\n\nCodeweather |&gt;\n  mutate(\n    temp_cat = case_when(\n      is.na(temp) ~ NA,\n      temp &lt; 39.9 ~ \"low\",\n      between(temp,39.9 ,70)~ \"medium\",\n      .default = \"large\"\n    )\n  ) |&gt;\n  relocate(temp,temp_cat)\n\n# A tibble: 26,115 × 16\n    temp temp_cat origin  year month   day  hour  dewp humid wind_dir wind_speed\n   &lt;dbl&gt; &lt;chr&gt;    &lt;chr&gt;  &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;dbl&gt; &lt;dbl&gt;    &lt;dbl&gt;      &lt;dbl&gt;\n 1  39.0 low      EWR     2013     1     1     1  26.1  59.4      270      10.4 \n 2  39.0 low      EWR     2013     1     1     2  27.0  61.6      250       8.06\n 3  39.0 low      EWR     2013     1     1     3  28.0  64.4      240      11.5 \n 4  39.9 medium   EWR     2013     1     1     4  28.0  62.2      250      12.7 \n 5  39.0 low      EWR     2013     1     1     5  28.0  64.4      260      12.7 \n 6  37.9 low      EWR     2013     1     1     6  28.0  67.2      240      11.5 \n 7  39.0 low      EWR     2013     1     1     7  28.0  64.4      240      15.0 \n 8  39.9 medium   EWR     2013     1     1     8  28.0  62.2      250      10.4 \n 9  39.9 medium   EWR     2013     1     1     9  28.0  62.2      260      15.0 \n10  41   medium   EWR     2013     1     1    10  28.0  59.6      260      13.8 \n# ℹ 26,105 more rows\n# ℹ 5 more variables: wind_gust &lt;dbl&gt;, precip &lt;dbl&gt;, pressure &lt;dbl&gt;,\n#   visib &lt;dbl&gt;, time_hour &lt;dttm&gt;\n\n\nHere we use the mutate command to create new variable named temp_cat. The case_when will then set to NA those values in the original temp variable that are missing. Then if the values of temp are \\(&lt; 30.9\\) it will assign them the label of low. If they lie between \\(39.9\\) and \\(70\\) it will assign them the label of medium and finally set to large any of the values that do not meet any of the aforementioned conditions. We can also use the function relocate to change the columns position so that the temp and temp_cat appears first on the data frame.\n\n\n\n\n\n\nTask\n\n\n\nCreate a new variable called extreme_weather that takes the value of extreme if the wind speed exceeds 64 mph and the temperature is less than 40 °F and not extreme otherwise. Then, relocate this new variable along with the variables used to create it at the first columns of the data frame, and sort them out based on wind_speed.\n\n\nTake a hint\n\nUse the conditional operators | and & to add multiple conditions.\n\n\n\n\nClick here to see the solution\n\nCodeweather |&gt;\n  mutate(\n    extreme_weather  = case_when(\n      is.na(temp)|is.na(wind_speed) ~ NA,\n      temp &lt; 40 & wind_speed  &gt; 64~ \"extreme\",\n      .default = \"not extreme\"\n    )\n  ) |&gt;\n  relocate(extreme_weather,temp,wind_speed) |&gt;\n  arrange(desc(wind_speed))\n\n# A tibble: 26,115 × 16\n   extreme_weather  temp wind_speed origin  year month   day  hour  dewp humid\n   &lt;chr&gt;           &lt;dbl&gt;      &lt;dbl&gt; &lt;chr&gt;  &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;dbl&gt; &lt;dbl&gt;\n 1 extreme          39.0     1048.  EWR     2013     2    12     3 27.0   61.6\n 2 not extreme      57.2       42.6 EWR     2013     1    31     6 53.6   87.7\n 3 not extreme      53.6       42.6 JFK     2013     1    31     4 53.1  100  \n 4 not extreme      60.8       40.3 EWR     2013     1    31     4 59     93.8\n 5 not extreme      59         40.3 LGA     2013     1    31     4 55.4   93.7\n 6 not extreme      46.0       39.1 EWR     2013     1    31     8 30.0   53.3\n 7 not extreme      41         38.0 JFK     2013     3     6    14 28.9   61.9\n 8 not extreme      53.1       36.8 JFK     2013     1    31     3 52.0  100  \n 9 not extreme      51.8       36.8 JFK     2013     1    31     7 46.4   81.7\n10 not extreme      28.0       36.8 JFK     2013    11    24    10 -0.04  29.2\n# ℹ 26,105 more rows\n# ℹ 6 more variables: wind_dir &lt;dbl&gt;, wind_gust &lt;dbl&gt;, precip &lt;dbl&gt;,\n#   pressure &lt;dbl&gt;, visib &lt;dbl&gt;, time_hour &lt;dttm&gt;"
  },
  {
    "objectID": "Week3Solutions.html",
    "href": "Week3Solutions.html",
    "title": "Week 2 Tasks Solutions",
    "section": "",
    "text": "library(tidyverse)\nlibrary(ggplot2)\nlibrary(nycflights13)\nlibrary(readr)\nlibrary(knitr)\nlibrary(fivethirtyeight)\n\nFurther Task 1\nIn this task we will work with the dataset analysed and reported in the 2016 article from FiveThirtyEight.com entitled “Some People Are Too Superstitious To Have A Baby On Friday The 13th” here.\nThe data set is called US_births_2000_2014 and is in the fivethirtyeight package.\n\nCreate an object called US_births_2013 which focuses only on data corresponding to 2013 births.\n\n\n#Further Task 1.1 Solution\nUS_births_2013 &lt;- US_births_2000_2014 |&gt; filter(year == 2013)\n\n\nBy only choosing births data for the years 2010, 2011, 2012, and 2014 create a new dataframe called US_births_small and check that this resulting data frame has 1461 rows. Note that there are many different ways to do this, but try and come up with three different ways using:\n\n\nthe “or” operator |\nthe %in% operator\nthe “not” operator ! or combinations of them.\n\n\n#Further Task 1.2 Solution\nUS_births_small &lt;- US_births_2000_2014 |&gt; \n  filter(year %in% c(2010, 2011, 2012, 2014))\n\nUS_births_small &lt;- US_births_2000_2014 |&gt; \n  filter(!(year %in% c(2000:2009, 2013, 2015)))\n\nUS_births_small &lt;- US_births_2000_2014 |&gt; \n  filter(year == 2010 | year == 2011 | year == 2012 | year == 2014)\n\n\nSuppose we are interested in choosing rows for only weekdays (not Saturdays or Sundays) for day_of_week in year 2013. Write the code to do so and give the name US_births_weekdays_2013 to the resulting data frame. (Note that you may want to run US_births_2000_2014 |&gt; distinct(day_of_week) to identify the specific values of day_of_week.)\n\n\n#Further Task 1.3 Solution\nUS_births_weekdays_2013 &lt;- US_births_2000_2014 |&gt; \n  filter(!(day_of_week %in% c('Sat','Sun')), year==2013)\n# You could also use & instead of the last comma, i.e. \nUS_births_weekdays_2013 &lt;- US_births_2000_2014 |&gt; \n  filter(!(day_of_week %in% c('Sat','Sun')) & year==2013)\n\n. Using what you covered in Week 1: Visualization, produce an appropriate plot looking at the pattern of births on all weekdays in 2013 coloured by the particular day of the week. (Remember to load the package ggplot2).\n\n#Further Task 1.4 Solution\nggplot(US_births_weekdays_2013, aes(x=date,y=births, color=day_of_week))+\n  geom_line()+ \n  labs(x='Date', y='Number of births', \n       title='Number US births on week days in 2013')\n\n\n\n\n\nThe plot in the previous task has shown there are some outliers in the data for US births on weekdays in 2013. We can use the summarize function to get an idea for how these outliers may affect the shape of the births variable in US_births_weekdays_2013. Write some code to calculate the mean and median values for all weekday birth totals in 2013. Store this aggregated data in the data frame birth_summ. What do these values suggest about the effects of the outliers?\n\n\n#Further Task 1.5 Solution\nbirth_summ &lt;- US_births_weekdays_2013 |&gt; \n  summarize(mean_births =  mean(births),\n            median_births = median(births))\nbirth_summ\n\n# A tibble: 1 × 2\n  mean_births median_births\n        &lt;dbl&gt;         &lt;int&gt;\n1      12145.         12192\n\n#Comparing the mean and the median values we see they are not very different, \n#showing that the potential outliers are not distorting the shape of \n\n\nInstead of looking at the overall mean and median across all of 2013 weekdays, calculate the mean and median for each of the five different weekdays throughout 2013. Using the same names for the columns as in the birth_summ data frame in the previous exercise, create a new data frame called birth_day_summ.\n\n\n#Further Task 1.6 Solution\nbirth_day_summ &lt;- US_births_weekdays_2013 |&gt;\n  summarize( mean_births =  mean(births),\n             median_births = median(births),.by = c(day_of_week))\nbirth_day_summ\n\n# A tibble: 5 × 3\n  day_of_week mean_births median_births\n  &lt;ord&gt;             &lt;dbl&gt;         &lt;dbl&gt;\n1 Tues             12469.        12519 \n2 Wed              12190.        12194 \n3 Thurs            12194.        12270 \n4 Fri              12133.        12126.\n5 Mon              11732.        11838.\n\n\n\nUsing the aggregated data in the birth_day_summ data frame, produce this barplot.\n\n\n\n\n\n\n\n#Further Task 1.7 Solution\nggplot(birth_day_summ, aes(x=day_of_week,y=mean_births, fill=day_of_week))+ \n  geom_col(show.legend = FALSE)+ \n  labs(x='Day of Week', y='Average number of births', \n       title='Average US births by weekday, 2013')\n\n\n\n\n\nFurther Task 2\nIn this task we will work with the dataset analysed and reported in the 2014 article from FiveThirtyEight.com entitled “41 Percent Of Fliers Think You’re Rude If You Recline Your Seat” here.\nThe data set is called flying and is in the fivethirtyeight package.\n\nWrite code to determine the proportion of respondents in the survey that responded with “Very” when asked if a passenger reclining their seat was rude. You should determine this proportion across the different levels of age and gender resulting in a data frame of size 8 x 3. Assign the name prop_very to this calculated proportion in this aggregated data frame.\n\n\n\n\n\n\n\nTip\n\n\n\nWe can obtain proportions using the mean() function applied to logical values. For example suppose we want to count the proportion of “heads” in five tosses of a fair coin. If the results of the five tosses are stored in\ntosses &lt;- c(\"heads\", \"tails\", \"tails\", \"heads\", \"heads\")\nthen we can use mean(tosses == \"heads\") to get the resulting answer of 0.6.\n\n\n\n\n\n\n\n\nTip\n\n\n\nIncluding the function na.omit(TRUE) in the ‘pipe’ (|&gt;) removes all entries that are not complete whereas including the argument na.rm=TRUE in the mean() function removes just those entries where the relevant variable value is missing.\n\n\n\n#Further Task 2.1 Solution\ntwo_group_prop_1 &lt;- flying |&gt; \n  summarize(prop_very = mean(recline_rude=='Very', na.rm=TRUE),\n            .by=c(gender,age))\n#OR\ntwo_group_prop_2 &lt;- flying |&gt; \n  na.omit(TRUE) |&gt; \n  summarize(prop_very = mean(recline_rude=='Very'),\n            .by = c(gender,age))\n\n\n\n#Compare the two summaries...\ntwo_group_prop_1\n\n# A tibble: 9 × 3\n  gender age   prop_very\n  &lt;chr&gt;  &lt;ord&gt;     &lt;dbl&gt;\n1 &lt;NA&gt;   &lt;NA&gt;     0.0909\n2 Male   30-44    0.0811\n3 Male   18-29    0.152 \n4 Male   45-60    0.0804\n5 Male   &gt; 60     0.0606\n6 Female &gt; 60     0.129 \n7 Female 30-44    0.0541\n8 Female 45-60    0.0410\n9 Female 18-29    0.0860\n\ntwo_group_prop_2\n\n# A tibble: 8 × 3\n  gender age   prop_very\n  &lt;chr&gt;  &lt;ord&gt;     &lt;dbl&gt;\n1 Male   30-44    0.075 \n2 Male   18-29    0.140 \n3 Male   45-60    0.0658\n4 Male   &gt; 60     0.0455\n5 Female &gt; 60     0.135 \n6 Female 30-44    0.0548\n7 Female 45-60    0.0353\n8 Female 18-29    0.113 \n\n\n\nUsing the aggregated data you’ve created, produce two bar plots (one stacked, the other side-by-side) to show the differences between the sexes of the proportion of people who believe reclining your seat is ‘very’ rude, within each age group.\n\nWhat gender and age-range pairings have the highest and lowest proportions of thinking reclining airline seats are very rude in this survey?\nWhat stands out to you as you review these proportions?\n\n#Further Task 2.2 Solution\nggplot(two_group_prop_2, aes(x=age,y=prop_very,fill=gender))+geom_col()\n\n\n\nggplot(two_group_prop_2, aes(x=age,y=prop_very,fill=gender))+geom_col(position = \"dodge\")"
  }
]