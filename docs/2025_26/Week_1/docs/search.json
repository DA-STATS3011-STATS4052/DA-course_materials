[
  {
    "objectID": "slides/slides.html#the-course-structure",
    "href": "slides/slides.html#the-course-structure",
    "title": "Data analysis",
    "section": "The Course Structure",
    "text": "The Course Structure\n\n\n\n\n\n\n\n\n\n\nWeek\nTopic\nAssessment\nWeights (%)\n\n\n\n\n1\nVisualising and data tidying using R\n\n\n\n\n2\nIntroduction to Quarto\n\n\n\n\n3\nRegression Modelling\n\n\n\n\n4\nModel assessment\nMoodle Quiz 1 online\n15\n\n\n5\nClass test üñ•Ô∏è\nClass test - in person\n25\n\n\n6\nGeneralised linear Models part 1\n\n\n\n\n7\nGeneralised linear Models part 2\nPeer review (submission phase)\n20\n\n\n8\nIntroduction to version control\nMoodle Quiz 2 online\n15\n\n\n9\nCollaborative coding\nPeer review (evaluation phase)\n\n\n\n10\nDrop-in session (Group projects)\n\n\n\n\n11\n\nGroup projects\n25"
  },
  {
    "objectID": "slides/slides.html#assessment-calendar",
    "href": "slides/slides.html#assessment-calendar",
    "title": "Data analysis",
    "section": "Assessment calendar",
    "text": "Assessment calendar\nPlease refer to Moodle for the detailed assessment calendar\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nRelease_week\nTopics\nType_of_assessment\nWeights\nDue_Date\n\n\n\n\nWeek 3 (Jan 30)\nWeeks: 1-3\nMoodle Quiz 1\n15\nWeek 4 (Feb 06) 11:00 am BST\n\n\nWeek 5 (Feb 13)\nWeeks: 1-4\nClass test\n25\nWeek 5 (Feb 13) 11:00 am BST\n\n\nWeek 2 (Jan 23)\nInformation during Week 2\nPeer assessment\n20\nWeek 7 (Feb 27) 11:00 am BST (End of Submission Stage)\nWeek 9 (Mar 13) 11:00 am BST (End of Evaluation Stage)\n\n\nWeek 8 (Mar 06)\nWeeks:6-7\nMoodle Quiz 2\n15\nWeek 8 (Mar 06) 11:00 am BST\n\n\nWeek 6 (Feb 20)\nWeeks: 1-10\nGroups project\n25\nWeek 11 (Mar 27) 11:00 am BST"
  },
  {
    "objectID": "slides/slides.html#lab-structure",
    "href": "slides/slides.html#lab-structure",
    "title": "Data analysis",
    "section": "Lab structure",
    "text": "Lab structure\nHow to Approach Each Lab\n\nOverview\n\nBrief introduction/ recap at the beginning of each lab\nUnderstand what concepts and tools you‚Äôll practice\n\nWork Through Exercises - Work on your own pace through the self-contained notes - Attempt all the tasks (Focus on understanding, not just finishing)\nCheck Against Solutions\n\nCompare your approach to the provided solutions\nDon‚Äôt just copy - try to understand why it works\n\nAsk for Help üôã‚Äç‚ôÇÔ∏è - If you‚Äôre stuck more than ~5 minutes, ask for help"
  },
  {
    "objectID": "slides/slides.html#overview",
    "href": "slides/slides.html#overview",
    "title": "Data analysis",
    "section": "Overview",
    "text": "Overview\nWe‚Äôll revisit key concepts from your previous¬†R programming¬†course and build on them with more advanced methods for data manipulation and plotting.\nILO‚Äôs for today:\n\n\nUse tools from the tidyverse and ggplot2 packages to manipulate and visualise data in R, including categorical variables.\nUnderstand the concept of tidy data and apply tidyverse tools to structure datasets and join datasets accordingly.\nPerform data wrangling tasks using tidyverse functions to prepare data for analysis and visualisation."
  },
  {
    "objectID": "slides/slides.html#load-libraries-data",
    "href": "slides/slides.html#load-libraries-data",
    "title": "Data analysis",
    "section": "Load libraries & data",
    "text": "Load libraries & data\nWe shall now load into R all of the libraries we will need for this session. This can be done by typing the following into your R script:\n\n\nThe first library ggplot2 allows us to use functions within that package in order to create nicer data visualisations.\nThe second library tidyverse is a collection of package for data manipulation.\nThe final two libraries (nycflights13¬†and¬†fivethirtyeight) contain interesting data sets that we shall examine in this session."
  },
  {
    "objectID": "slides/slides.html#tidy-data",
    "href": "slides/slides.html#tidy-data",
    "title": "Data analysis",
    "section": "Tidy Data",
    "text": "Tidy Data\nTidy data is about structuring your data so that:\n\nEach variable has its own column\nEach observation has its own row\nEach type of observation forms a table."
  },
  {
    "objectID": "slides/slides.html#tidy-data-1",
    "href": "slides/slides.html#tidy-data-1",
    "title": "Data analysis",
    "section": "Tidy Data",
    "text": "Tidy Data\nTidy data is about structuring your data so that:\n\nEach variable has its own column\nEach observation has its own row\nEach type of observation forms a table.\n\nYou will learn how to convert your data to tidy data format"
  },
  {
    "objectID": "slides/slides.html#data-visualization-using-ggplot",
    "href": "slides/slides.html#data-visualization-using-ggplot",
    "title": "Data analysis",
    "section": "Data Visualization using ggplot",
    "text": "Data Visualization using ggplot\nUse ggplot to produce scatter plots, boxplots, histograms, barplots, line plots, etc.\n\nStart by specifying the tidy data you‚Äôre plotting from"
  },
  {
    "objectID": "slides/slides.html#data-visualization-using-ggplot-1",
    "href": "slides/slides.html#data-visualization-using-ggplot-1",
    "title": "Data analysis",
    "section": "Data Visualization using ggplot",
    "text": "Data Visualization using ggplot\nUse ggplot to produce scatter plots, boxplots, histograms, barplots,line plots, etc.\n\nStart by specifying the tidy data you‚Äôre plotting from\nUse the aesthetic mapping to define which variables go on the axes, colors, size, etc"
  },
  {
    "objectID": "slides/slides.html#data-visualization-using-ggplot-2",
    "href": "slides/slides.html#data-visualization-using-ggplot-2",
    "title": "Data analysis",
    "section": "Data Visualization using ggplot",
    "text": "Data Visualization using ggplot\nUse ggplot to produce scatter plots, boxplots, histograms, barplots,line plots, etc.\n\nStart by specifying the tidy data you‚Äôre plotting from\nUse the aesthetic mapping to define which variables go on the axes, colors, size, etc\nAdd a geom layer (e.g., geom_point(), geom_bar(), geom_line())"
  },
  {
    "objectID": "slides/slides.html#data-visualization-using-ggplot-3",
    "href": "slides/slides.html#data-visualization-using-ggplot-3",
    "title": "Data analysis",
    "section": "Data Visualization using ggplot",
    "text": "Data Visualization using ggplot\nUse ggplot to produce scatter plots, boxplots, histograms, barplots,line plots, etc.\n\nStart by specifying the tidy data you‚Äôre plotting from\nUse the aesthetic mapping to define which variables go on the axes, colors, size, etc\nAdd a geom layer (e.g., geom_point(), geom_bar(), `geom_line()\nAdd labels for axes or a title to make your plot more readable."
  },
  {
    "objectID": "slides/slides.html#data-wrangling",
    "href": "slides/slides.html#data-wrangling",
    "title": "Data analysis",
    "section": "Data wrangling",
    "text": "Data wrangling\nUse tools from the dplyr package (included in tidyverse) to perform data wrangling which includes transforming, mapping and summarising variables using the pipeline command %&gt;%"
  },
  {
    "objectID": "slides/slides.html#data-wrangling-1",
    "href": "slides/slides.html#data-wrangling-1",
    "title": "Data analysis",
    "section": "Data wrangling",
    "text": "Data wrangling\n\n\n\n\n\n\nSelect Columns"
  },
  {
    "objectID": "slides/slides.html#data-wrangling-2",
    "href": "slides/slides.html#data-wrangling-2",
    "title": "Data analysis",
    "section": "Data wrangling",
    "text": "Data wrangling\n\n\n\n\n\n\nFilter observations"
  },
  {
    "objectID": "slides/slides.html#data-wrangling-3",
    "href": "slides/slides.html#data-wrangling-3",
    "title": "Data analysis",
    "section": "Data wrangling",
    "text": "Data wrangling\n\n\n\n\n\n\nCreate/modify variables"
  },
  {
    "objectID": "slides/slides.html#data-wrangling-4",
    "href": "slides/slides.html#data-wrangling-4",
    "title": "Data analysis",
    "section": "Data wrangling",
    "text": "Data wrangling\n\n\n\n\n\n\nSummarise variables"
  },
  {
    "objectID": "slides/slides.html#data-wrangling-5",
    "href": "slides/slides.html#data-wrangling-5",
    "title": "Data analysis",
    "section": "Data wrangling",
    "text": "Data wrangling\n\n\n\n\n\n\nGrouping structure"
  },
  {
    "objectID": "slides/slides.html#data-wrangling-6",
    "href": "slides/slides.html#data-wrangling-6",
    "title": "Data analysis",
    "section": "Data wrangling",
    "text": "Data wrangling\n\n\n\n\n\n\nJoining data frames"
  },
  {
    "objectID": "slides/slides.html#a-last-thing",
    "href": "slides/slides.html#a-last-thing",
    "title": "Data analysis",
    "section": "A last thing‚Ä¶",
    "text": "A last thing‚Ä¶\n\n\n\n\n\n\nNote\n\n\nTo further enhance your skills in Data analysis, check out the additional material provided on handling date-time data.\n\n\n\n\n\nüïí Work at your own pace or in groups ‚Äî the notes and exercises are designed for flexible, self-guided learning.\nüí¨ Ask for help whenever you need it ‚Äî we‚Äôre here to support you.\nüß† Focus on understanding the concepts, not just completing tasks.\nüè† Didn‚Äôt finish? No problem! You‚Äôre encouraged to take the exercises home and revisit them later."
  },
  {
    "objectID": "tutorial.html",
    "href": "tutorial.html",
    "title": "Extra material",
    "section": "",
    "text": "Working with date-time data in R can be challenging due to the unintuitive and inconsistent commands across different date-time objects. Additionally, managing things like time zones, leap days, and daylight saving time can be tricky since R doesn‚Äôt always handle these well. The lubridate and hms packages (loaded as part of tideverse) simplify date-time operations in R, making it easier to perform common tasks and enabling functionalities that R‚Äôs base capabilities do not support. Unfortunately, we don‚Äôt have enough time to cover all the details in this session. Instead, we will only give short introduction on how to work and manipulate date and time variables in R using the lubridate and hms packages. But if you want to learn more please have a look at the R for Data Science ebook.\nFirst, what do we mean by Date/Time data? well, when we speak of Date/Time data we are mainly referring to three data types:\n\nDate - a variable containing only the date when an observation was made (e.g.¬†2024-07-12). More formally, it is a day stored as the number of days since 1970-01-01\nTime - a variable containing only the time when an observation was made (e.g.¬†18:15:00). Formally , the number of seconds since 00:00:00\nDate & Time - combination of both the date and time (e.g.¬†2024-07-12 18:15:00). Formally, is a point on the timeline, stored as the number of seconds since 1970-01-01 00:00:00 UTC\n\nThere are several ways in which Date-time variables can be created. Here are some examples:\n\n# Example 1: string input with date Y/M/D format\nymd(\"2017-01-31\")\n\n[1] \"2017-01-31\"\n\n# Example 2: string input with date M/D/Y format\nmdy(\"January 31st, 2017\")\n\n[1] \"2017-01-31\"\n\n# Example 3: string input with date D/M/Y format\ndmy(\"31-Jan-2017\")\n\n[1] \"2017-01-31\"\n\n# Example 4: numeric input with date M/D/Y format\nmdy(07082016)\n\n[1] \"2016-07-08\"\n\n# Examples 5: string input with time H:M formate\nhm(\"20:11\")\n\n[1] \"20H 11M 0S\"\n\n# Example 6:  string input with date-time D/M/Y H:M:S\nymd_hms(\"2017-01-31 20:11:59\")\n\n[1] \"2017-01-31 20:11:59 UTC\"\n\n\nIn this session, instead of creating data-time variables by ourselves, we will focus on already existing Date/Time Data. Let‚Äôs look at some of the date-time variables in the flights data set, namely the scheduled departure dates and times:\n\n\nOutput\nR-Code\n\n\n\n\n\n# A tibble: 336,776 √ó 5\n    year month   day  hour minute\n   &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;dbl&gt;  &lt;dbl&gt;\n 1  2013     1     1     5     15\n 2  2013     1     1     5     29\n 3  2013     1     1     5     40\n 4  2013     1     1     5     45\n 5  2013     1     1     6      0\n 6  2013     1     1     5     58\n 7  2013     1     1     6      0\n 8  2013     1     1     6      0\n 9  2013     1     1     6      0\n10  2013     1     1     6      0\n# ‚Ñπ 336,766 more rows\n\n\n\n\n\nflights_dep &lt;- flights %&gt;%\n  select(year, month, day, hour, minute)\nflights_dep\n\n\n\n\nInstead of having separate date-time variables spread across different columns, we can use the make_date() or make_datetime()functions to create new date and date-time variables respectively:\n\nflights_dep &lt;- flights_dep %&gt;%\n    mutate(departure_time = make_datetime(year, month, day, hour, minute),\n           departure_date = make_date(year, month, day))\nflights_dep\n\n# A tibble: 336,776 √ó 7\n    year month   day  hour minute departure_time      departure_date\n   &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;dbl&gt;  &lt;dbl&gt; &lt;dttm&gt;              &lt;date&gt;        \n 1  2013     1     1     5     15 2013-01-01 05:15:00 2013-01-01    \n 2  2013     1     1     5     29 2013-01-01 05:29:00 2013-01-01    \n 3  2013     1     1     5     40 2013-01-01 05:40:00 2013-01-01    \n 4  2013     1     1     5     45 2013-01-01 05:45:00 2013-01-01    \n 5  2013     1     1     6      0 2013-01-01 06:00:00 2013-01-01    \n 6  2013     1     1     5     58 2013-01-01 05:58:00 2013-01-01    \n 7  2013     1     1     6      0 2013-01-01 06:00:00 2013-01-01    \n 8  2013     1     1     6      0 2013-01-01 06:00:00 2013-01-01    \n 9  2013     1     1     6      0 2013-01-01 06:00:00 2013-01-01    \n10  2013     1     1     6      0 2013-01-01 06:00:00 2013-01-01    \n# ‚Ñπ 336,766 more rows\n\n\nWe then can visualize the distribution of the scheduled departure times across the year with ggplot by adding a geom_freqpoly() layer (which is similar to an histogram where the counts are displayed with lines instead of bars). Note that when you use date-times in a numeric context (like in a histogram), a binwidth of 1 is equivalent to 1 second, so a binwidth of 86400 is equivalent to one day.\n\nCodeflights_dep %&gt;%\n  ggplot(aes(x = departure_time)) +\n  geom_freqpoly(binwidth = 86400) # 86400 seconds = 1 day\n\n\n\n\n\n\n\nLikewise, if were interested in the distribution of the scheduled departures for a given day:\n\nCodeflights_dep %&gt;%\n  filter(departure_date == ymd(20130102)) %&gt;%\n  ggplot(aes(x = departure_time)) +\n  geom_freqpoly(binwidth = 600) # 600 s = 10 minutes\n\n\n\n\n\n\n\nIn here, binwidth = 600 means we are clumping all flights within each 10 minutes (600 s) together into one single data point in our frequency polygon.\nNow, notice that in the original flights data set, the hour and minute of the actual departure (dep_time) and arrival times (arr_time) are encoded together into a single integer. Let make a function that sets the actual times in a sensible format:\n\nCodemake_datetime_flights &lt;- function(year, month, day, time) {\n  hour &lt;- case_when(\n      nchar(time)== 1 ~ time  %/%1,\n      nchar(time)== 2 ~ time  %/%10,\n      .default =  time  %/%100\n    )\n\n  min &lt;- case_when(\n      nchar(time)== 1 ~ time  %%1,\n      nchar(time)== 2 ~ time  %%10,\n      .default =  time  %%100\n    )\n  make_datetime(year, month, day, hour, min)\n}\n\n\nThe new make_datetime_flights() function we just created separates the hour and minute of a given HM input and pass it on to make_datetime function. This is achieved by using a vectorized case_when argument based on the number of characters in the integer that uses the %/% or%% operator to find (or discards accordingly) the remainder of an integer division to obtain the hour and minute components (e.g.¬†951 %/% 100 and 951 %% 100 splits the entry 951 into 9 and 51 (9:15 am once converted to time-date data) while 15 %/% 10 and 15 %% 10 and gives 1 and 5 (equivalent to 1:05 am in date-time format) .\n\nCodeflights_dt &lt;- flights %&gt;%\n  filter(!is.na(dep_time), !is.na(arr_time)) %&gt;%\n  mutate(\n    dep_time = make_datetime_flights(year, month, day, dep_time),\n    arr_time = make_datetime_flights(year, month, day, arr_time),\n    sched_dep_time = make_datetime_flights(year, month, day, sched_dep_time),\n    sched_arr_time = make_datetime_flights(year, month, day, sched_arr_time)\n  )\n\nflights_dt %&gt;%\n  select(dep_time,arr_time,sched_dep_time,sched_arr_time) %&gt;%\n  slice(1:3)\n\n# A tibble: 3 √ó 4\n  dep_time            arr_time            sched_dep_time     \n  &lt;dttm&gt;              &lt;dttm&gt;              &lt;dttm&gt;             \n1 2013-01-01 05:17:00 2013-01-01 08:30:00 2013-01-01 05:15:00\n2 2013-01-01 05:33:00 2013-01-01 08:50:00 2013-01-01 05:29:00\n3 2013-01-01 05:42:00 2013-01-01 09:23:00 2013-01-01 05:40:00\n# ‚Ñπ 1 more variable: sched_arr_time &lt;dttm&gt;\n\n\n\nThe lubridate package also provide us with different tools for extracting specific components from date-time objects (e.g.¬†year, month, hours, minutes, etc). Suppose we are interested in finding out which day of the week each flight took place. The wday() functions allow us to extract the numeric entry of the day of the week, by including the argument label =TRUE, we can also print the name of the weekday as the output\n\nCodeflights_dt %&gt;%\n   select(dep_time,arr_time,sched_dep_time,sched_arr_time) %&gt;%\n  mutate(weekday = wday(dep_time,label=TRUE)) %&gt;%\n  slice_sample(n=5)\n\n# A tibble: 5 √ó 5\n  dep_time            arr_time            sched_dep_time     \n  &lt;dttm&gt;              &lt;dttm&gt;              &lt;dttm&gt;             \n1 2013-10-14 08:10:00 2013-10-14 09:59:00 2013-10-14 08:00:00\n2 2013-06-29 07:27:00 2013-06-29 11:08:00 2013-06-29 07:30:00\n3 2013-02-05 23:55:00 2013-02-05 04:30:00 2013-02-05 23:59:00\n4 2013-08-23 11:44:00 2013-08-23 13:40:00 2013-08-23 11:55:00\n5 2013-10-26 15:02:00 2013-10-26 17:39:00 2013-10-26 15:00:00\n# ‚Ñπ 2 more variables: sched_arr_time &lt;dttm&gt;, weekday &lt;ord&gt;\n\n\nHere are some more few examples of helper functions that allow you to extract individual date-time components:\n\nCodedatetime &lt;- ymd_hms(\"2026-07-08 12:34:56\")\n\nyear(datetime)\n\n[1] 2026\n\nCodemonth(datetime,label = TRUE)\n\n[1] Jul\n12 Levels: Jan &lt; Feb &lt; Mar &lt; Apr &lt; May &lt; Jun &lt; Jul &lt; Aug &lt; Sep &lt; ... &lt; Dec\n\nCodeday(datetime)\n\n[1] 8\n\nCodehour(datetime)\n\n[1] 12\n\nCodeminute(datetime)\n\n[1] 34\n\n\n\n\n\n\n\n\nTask\n\n\n\nCan you make a plot showing how does the distribution of flight times within a day change over the course of the year? i.e., how many flights have taken off by each hour. Comment on the patterns\n\n\nTake a hint\n\nWithin a day, we want to observe how the flight times differ. This means we should look at how flight times differ by the hour (i.e how many flights are taking off at every hour of the day). You can use the hour() function to extract the hours for every departure time and then count (using summarize()) how many flights have taken off by each hour. You can visualize the trend using geom_line in ggplot.\n\n\n\n\nClick here to see the solution\n\nCodeflights_dt %&gt;%\n  mutate(hour = hour(dep_time)) %&gt;%\n  summarize(numflights_per_hour = n(),.by= hour)%&gt;%\n  ggplot(aes(x = hour, y = numflights_per_hour)) +\n    geom_line() +\n  labs(y=\"number of flights per hour\",x = \"hour\")\n\n\n\n\n\n\n\n\nWe can see there is a peak of flights around 8am, a dip in flights from 10am-12pm, and then a drop off in number of flights past 7pm.\n\n\n\n\n\n\n\n\nTask\n\n\n\nFind out on what day of the week should you leave if you want to minimise the chance of a delay?\n\n\nTake a hint\n\nTo find the days of the week that have the lowest average delay, first you need to assign a day to each observation using wday(). You can then use summarize() and group by the the day of the week to find the average delay time for each day of the week.\n\n\n\n\nClick here to see the solution\n\nCodeflights_dt %&gt;%\n  mutate(wday = wday(sched_dep_time, label = TRUE)) %&gt;%\n  group_by(wday) %&gt;%\n  summarize ( avg_dep_delay_week = mean(dep_delay, na.rm = TRUE),\n              avg_arr_delay_week = mean(arr_delay, na.rm = TRUE)) %&gt;%\n  slice_min(avg_dep_delay_week,n=1)\n\n# A tibble: 1 √ó 3\n  wday  avg_dep_delay_week avg_arr_delay_week\n  &lt;ord&gt;              &lt;dbl&gt;              &lt;dbl&gt;\n1 Sat                 7.62              -1.45\n\nCode# Saturday has the lowest average delay at 7.61, and on average the flights even arrive earlier than expected!\n\n\n\nWe can see there is a peak of flights around 8am, a dip in flights from 10am-12pm, and then a drop off in number of flights past 7pm.\n\n\n\nNow that we have seen a few examples of R‚Äôs date-time data structures, lets look into some of the time span classes.\n\nDuration: exact number of seconds.\nPeriods: human units like weeks and months.\nIntervals: a time span defined by a start and end point.\n\nDuration is simply defined by the exact amount of time between two time events. It does not consider what these two events are in terms of,e.g.¬†calendar years or time zone (so things like leap years would be ignored), and the output is shown in seconds. For example, say we want to manually compute the departure delays in the flights data set (we will use the flights_dt data frame we created previously which has the dep_time and sched_dep_times in the correct date-time format).\n\nCode flights_dt %&gt;%\n  mutate(\n    dep_delay_manual =  dep_time - sched_dep_time) %&gt;%\n    select(dep_time,sched_dep_time,dep_delay_manual,dep_delay)  %&gt;%\n  slice(1:5)\n\n# A tibble: 5 √ó 4\n  dep_time            sched_dep_time      dep_delay_manual dep_delay\n  &lt;dttm&gt;              &lt;dttm&gt;              &lt;drtn&gt;               &lt;dbl&gt;\n1 2013-01-01 05:17:00 2013-01-01 05:15:00  120 secs                2\n2 2013-01-01 05:33:00 2013-01-01 05:29:00  240 secs                4\n3 2013-01-01 05:42:00 2013-01-01 05:40:00  120 secs                2\n4 2013-01-01 05:44:00 2013-01-01 05:45:00  -60 secs               -1\n5 2013-01-01 05:54:00 2013-01-01 06:00:00 -360 secs               -6\n\n\nAt first glance, we can see that the manually computed departure delays dep_delay_manual and the original delays dep_delay are not on the same format. By default, when you subtract two dates (e.g.¬†dep_time - sched_dep_time), you get a difftime object which records a time span of seconds, minutes, hours, days, or weeks. This variability can make difftime objects difficult to work with. To address this, we can use convert a difftime object to a duration class using the as.duration() function. Additionally, the original delays dep_delay, which are measured in minutes but have no default date-time format, can also be transformed into a duration class using the duration(units =\"\") function.\n\nCode flights_dt %&gt;%\n  mutate(\n      dep_delay = duration(minute  = dep_delay),\n      dep_delay_manual =  as.duration(dep_time - sched_dep_time))%&gt;%\n  select(dep_time,sched_dep_time,dep_delay_manual,dep_delay)  %&gt;%\n  slice(1:5)\n\n# A tibble: 5 √ó 4\n  dep_time            sched_dep_time      dep_delay_manual   \n  &lt;dttm&gt;              &lt;dttm&gt;              &lt;Duration&gt;         \n1 2013-01-01 05:17:00 2013-01-01 05:15:00 120s (~2 minutes)  \n2 2013-01-01 05:33:00 2013-01-01 05:29:00 240s (~4 minutes)  \n3 2013-01-01 05:42:00 2013-01-01 05:40:00 120s (~2 minutes)  \n4 2013-01-01 05:44:00 2013-01-01 05:45:00 -60s (~-1 minutes) \n5 2013-01-01 05:54:00 2013-01-01 06:00:00 -360s (~-6 minutes)\n# ‚Ñπ 1 more variable: dep_delay &lt;Duration&gt;\n\n\nDurations always record the time span in seconds. Instead, periods represent time spans without a fixed length in seconds; they work with ‚Äúhuman‚Äù times, such as days and months. This allows them to operate in a more intuitive manner. periods can be created with different functions, here are some examples:\n\nCodehours(c(12, 24))\n\n[1] \"12H 0M 0S\" \"24H 0M 0S\"\n\nCodedays(7)\n\n[1] \"7d 0H 0M 0S\"\n\nCodemonths(1:3)\n\n[1] \"1m 0d 0H 0M 0S\" \"2m 0d 0H 0M 0S\" \"3m 0d 0H 0M 0S\"\n\n\nLets see how the output changes when we use periods instead of durations:\n\nCodeflights_dt %&gt;%\n  mutate(\n      dep_delay = period(minute  = dep_delay),\n      dep_delay_manual =  as.period(dep_time - sched_dep_time))%&gt;%\n  select(dep_time,sched_dep_time,dep_delay_manual,dep_delay)  %&gt;%\n  slice(1:5)\n\n# A tibble: 5 √ó 4\n  dep_time            sched_dep_time      dep_delay_manual dep_delay\n  &lt;dttm&gt;              &lt;dttm&gt;              &lt;Period&gt;         &lt;Period&gt; \n1 2013-01-01 05:17:00 2013-01-01 05:15:00 2M 0S            2M 0S    \n2 2013-01-01 05:33:00 2013-01-01 05:29:00 4M 0S            4M 0S    \n3 2013-01-01 05:42:00 2013-01-01 05:40:00 2M 0S            2M 0S    \n4 2013-01-01 05:44:00 2013-01-01 05:45:00 -1M 0S           -1M 0S   \n5 2013-01-01 05:54:00 2013-01-01 06:00:00 -6M 0S           -6M 0S   \n\n\nThe last type of time-span defined in lubridate are intervals. As with durations, intervals are expressed in physical time spans defined by a start and end points that are real date-times, i.e.¬†intervals are durations defined by a calendar time. Lets suppose we are only given the scheduled departure times and the departure delay. We can create an interval time-span to compute the actual departure time as follows:\n\nCodeflights_dt %&gt;%\n  select(sched_dep_time,dep_delay) %&gt;%\n  mutate(\n      dep_delay_duration = duration(minute  = dep_delay),\n      dep_delay_interval= as.interval(x = dep_delay_duration, start= sched_dep_time))%&gt;%\n  slice(1:5)\n\n# A tibble: 5 √ó 4\n  sched_dep_time      dep_delay dep_delay_duration \n  &lt;dttm&gt;                  &lt;dbl&gt; &lt;Duration&gt;         \n1 2013-01-01 05:15:00         2 120s (~2 minutes)  \n2 2013-01-01 05:29:00         4 240s (~4 minutes)  \n3 2013-01-01 05:40:00         2 120s (~2 minutes)  \n4 2013-01-01 05:45:00        -1 -60s (~-1 minutes) \n5 2013-01-01 06:00:00        -6 -360s (~-6 minutes)\n# ‚Ñπ 1 more variable: dep_delay_interval &lt;Interval&gt;"
  },
  {
    "objectID": "tutorial.html#extracting-individual-date-time-components",
    "href": "tutorial.html#extracting-individual-date-time-components",
    "title": "Extra material",
    "section": "",
    "text": "The lubridate package also provide us with different tools for extracting specific components from date-time objects (e.g.¬†year, month, hours, minutes, etc). Suppose we are interested in finding out which day of the week each flight took place. The wday() functions allow us to extract the numeric entry of the day of the week, by including the argument label =TRUE, we can also print the name of the weekday as the output\n\nCodeflights_dt %&gt;%\n   select(dep_time,arr_time,sched_dep_time,sched_arr_time) %&gt;%\n  mutate(weekday = wday(dep_time,label=TRUE)) %&gt;%\n  slice_sample(n=5)\n\n# A tibble: 5 √ó 5\n  dep_time            arr_time            sched_dep_time     \n  &lt;dttm&gt;              &lt;dttm&gt;              &lt;dttm&gt;             \n1 2013-10-14 08:10:00 2013-10-14 09:59:00 2013-10-14 08:00:00\n2 2013-06-29 07:27:00 2013-06-29 11:08:00 2013-06-29 07:30:00\n3 2013-02-05 23:55:00 2013-02-05 04:30:00 2013-02-05 23:59:00\n4 2013-08-23 11:44:00 2013-08-23 13:40:00 2013-08-23 11:55:00\n5 2013-10-26 15:02:00 2013-10-26 17:39:00 2013-10-26 15:00:00\n# ‚Ñπ 2 more variables: sched_arr_time &lt;dttm&gt;, weekday &lt;ord&gt;\n\n\nHere are some more few examples of helper functions that allow you to extract individual date-time components:\n\nCodedatetime &lt;- ymd_hms(\"2026-07-08 12:34:56\")\n\nyear(datetime)\n\n[1] 2026\n\nCodemonth(datetime,label = TRUE)\n\n[1] Jul\n12 Levels: Jan &lt; Feb &lt; Mar &lt; Apr &lt; May &lt; Jun &lt; Jul &lt; Aug &lt; Sep &lt; ... &lt; Dec\n\nCodeday(datetime)\n\n[1] 8\n\nCodehour(datetime)\n\n[1] 12\n\nCodeminute(datetime)\n\n[1] 34\n\n\n\n\n\n\n\n\nTask\n\n\n\nCan you make a plot showing how does the distribution of flight times within a day change over the course of the year? i.e., how many flights have taken off by each hour. Comment on the patterns\n\n\nTake a hint\n\nWithin a day, we want to observe how the flight times differ. This means we should look at how flight times differ by the hour (i.e how many flights are taking off at every hour of the day). You can use the hour() function to extract the hours for every departure time and then count (using summarize()) how many flights have taken off by each hour. You can visualize the trend using geom_line in ggplot.\n\n\n\n\nClick here to see the solution\n\nCodeflights_dt %&gt;%\n  mutate(hour = hour(dep_time)) %&gt;%\n  summarize(numflights_per_hour = n(),.by= hour)%&gt;%\n  ggplot(aes(x = hour, y = numflights_per_hour)) +\n    geom_line() +\n  labs(y=\"number of flights per hour\",x = \"hour\")\n\n\n\n\n\n\n\n\nWe can see there is a peak of flights around 8am, a dip in flights from 10am-12pm, and then a drop off in number of flights past 7pm.\n\n\n\n\n\n\n\n\nTask\n\n\n\nFind out on what day of the week should you leave if you want to minimise the chance of a delay?\n\n\nTake a hint\n\nTo find the days of the week that have the lowest average delay, first you need to assign a day to each observation using wday(). You can then use summarize() and group by the the day of the week to find the average delay time for each day of the week.\n\n\n\n\nClick here to see the solution\n\nCodeflights_dt %&gt;%\n  mutate(wday = wday(sched_dep_time, label = TRUE)) %&gt;%\n  group_by(wday) %&gt;%\n  summarize ( avg_dep_delay_week = mean(dep_delay, na.rm = TRUE),\n              avg_arr_delay_week = mean(arr_delay, na.rm = TRUE)) %&gt;%\n  slice_min(avg_dep_delay_week,n=1)\n\n# A tibble: 1 √ó 3\n  wday  avg_dep_delay_week avg_arr_delay_week\n  &lt;ord&gt;              &lt;dbl&gt;              &lt;dbl&gt;\n1 Sat                 7.62              -1.45\n\nCode# Saturday has the lowest average delay at 7.61, and on average the flights even arrive earlier than expected!\n\n\n\nWe can see there is a peak of flights around 8am, a dip in flights from 10am-12pm, and then a drop off in number of flights past 7pm."
  },
  {
    "objectID": "tutorial.html#time-intervals-durations-and-periods",
    "href": "tutorial.html#time-intervals-durations-and-periods",
    "title": "Extra material",
    "section": "",
    "text": "Now that we have seen a few examples of R‚Äôs date-time data structures, lets look into some of the time span classes.\n\nDuration: exact number of seconds.\nPeriods: human units like weeks and months.\nIntervals: a time span defined by a start and end point.\n\nDuration is simply defined by the exact amount of time between two time events. It does not consider what these two events are in terms of,e.g.¬†calendar years or time zone (so things like leap years would be ignored), and the output is shown in seconds. For example, say we want to manually compute the departure delays in the flights data set (we will use the flights_dt data frame we created previously which has the dep_time and sched_dep_times in the correct date-time format).\n\nCode flights_dt %&gt;%\n  mutate(\n    dep_delay_manual =  dep_time - sched_dep_time) %&gt;%\n    select(dep_time,sched_dep_time,dep_delay_manual,dep_delay)  %&gt;%\n  slice(1:5)\n\n# A tibble: 5 √ó 4\n  dep_time            sched_dep_time      dep_delay_manual dep_delay\n  &lt;dttm&gt;              &lt;dttm&gt;              &lt;drtn&gt;               &lt;dbl&gt;\n1 2013-01-01 05:17:00 2013-01-01 05:15:00  120 secs                2\n2 2013-01-01 05:33:00 2013-01-01 05:29:00  240 secs                4\n3 2013-01-01 05:42:00 2013-01-01 05:40:00  120 secs                2\n4 2013-01-01 05:44:00 2013-01-01 05:45:00  -60 secs               -1\n5 2013-01-01 05:54:00 2013-01-01 06:00:00 -360 secs               -6\n\n\nAt first glance, we can see that the manually computed departure delays dep_delay_manual and the original delays dep_delay are not on the same format. By default, when you subtract two dates (e.g.¬†dep_time - sched_dep_time), you get a difftime object which records a time span of seconds, minutes, hours, days, or weeks. This variability can make difftime objects difficult to work with. To address this, we can use convert a difftime object to a duration class using the as.duration() function. Additionally, the original delays dep_delay, which are measured in minutes but have no default date-time format, can also be transformed into a duration class using the duration(units =\"\") function.\n\nCode flights_dt %&gt;%\n  mutate(\n      dep_delay = duration(minute  = dep_delay),\n      dep_delay_manual =  as.duration(dep_time - sched_dep_time))%&gt;%\n  select(dep_time,sched_dep_time,dep_delay_manual,dep_delay)  %&gt;%\n  slice(1:5)\n\n# A tibble: 5 √ó 4\n  dep_time            sched_dep_time      dep_delay_manual   \n  &lt;dttm&gt;              &lt;dttm&gt;              &lt;Duration&gt;         \n1 2013-01-01 05:17:00 2013-01-01 05:15:00 120s (~2 minutes)  \n2 2013-01-01 05:33:00 2013-01-01 05:29:00 240s (~4 minutes)  \n3 2013-01-01 05:42:00 2013-01-01 05:40:00 120s (~2 minutes)  \n4 2013-01-01 05:44:00 2013-01-01 05:45:00 -60s (~-1 minutes) \n5 2013-01-01 05:54:00 2013-01-01 06:00:00 -360s (~-6 minutes)\n# ‚Ñπ 1 more variable: dep_delay &lt;Duration&gt;\n\n\nDurations always record the time span in seconds. Instead, periods represent time spans without a fixed length in seconds; they work with ‚Äúhuman‚Äù times, such as days and months. This allows them to operate in a more intuitive manner. periods can be created with different functions, here are some examples:\n\nCodehours(c(12, 24))\n\n[1] \"12H 0M 0S\" \"24H 0M 0S\"\n\nCodedays(7)\n\n[1] \"7d 0H 0M 0S\"\n\nCodemonths(1:3)\n\n[1] \"1m 0d 0H 0M 0S\" \"2m 0d 0H 0M 0S\" \"3m 0d 0H 0M 0S\"\n\n\nLets see how the output changes when we use periods instead of durations:\n\nCodeflights_dt %&gt;%\n  mutate(\n      dep_delay = period(minute  = dep_delay),\n      dep_delay_manual =  as.period(dep_time - sched_dep_time))%&gt;%\n  select(dep_time,sched_dep_time,dep_delay_manual,dep_delay)  %&gt;%\n  slice(1:5)\n\n# A tibble: 5 √ó 4\n  dep_time            sched_dep_time      dep_delay_manual dep_delay\n  &lt;dttm&gt;              &lt;dttm&gt;              &lt;Period&gt;         &lt;Period&gt; \n1 2013-01-01 05:17:00 2013-01-01 05:15:00 2M 0S            2M 0S    \n2 2013-01-01 05:33:00 2013-01-01 05:29:00 4M 0S            4M 0S    \n3 2013-01-01 05:42:00 2013-01-01 05:40:00 2M 0S            2M 0S    \n4 2013-01-01 05:44:00 2013-01-01 05:45:00 -1M 0S           -1M 0S   \n5 2013-01-01 05:54:00 2013-01-01 06:00:00 -6M 0S           -6M 0S   \n\n\nThe last type of time-span defined in lubridate are intervals. As with durations, intervals are expressed in physical time spans defined by a start and end points that are real date-times, i.e.¬†intervals are durations defined by a calendar time. Lets suppose we are only given the scheduled departure times and the departure delay. We can create an interval time-span to compute the actual departure time as follows:\n\nCodeflights_dt %&gt;%\n  select(sched_dep_time,dep_delay) %&gt;%\n  mutate(\n      dep_delay_duration = duration(minute  = dep_delay),\n      dep_delay_interval= as.interval(x = dep_delay_duration, start= sched_dep_time))%&gt;%\n  slice(1:5)\n\n# A tibble: 5 √ó 4\n  sched_dep_time      dep_delay dep_delay_duration \n  &lt;dttm&gt;                  &lt;dbl&gt; &lt;Duration&gt;         \n1 2013-01-01 05:15:00         2 120s (~2 minutes)  \n2 2013-01-01 05:29:00         4 240s (~4 minutes)  \n3 2013-01-01 05:40:00         2 120s (~2 minutes)  \n4 2013-01-01 05:45:00        -1 -60s (~-1 minutes) \n5 2013-01-01 06:00:00        -6 -360s (~-6 minutes)\n# ‚Ñπ 1 more variable: dep_delay_interval &lt;Interval&gt;"
  },
  {
    "objectID": "notes.html",
    "href": "notes.html",
    "title": "Week 1: Visualising and data tidying using R",
    "section": "",
    "text": "This week we will review various techniques for data tidying, wrangling and visualization in R. We‚Äôll revisit key concepts from your previous R programming course and build on them with more advanced methods for data manipulation and plotting.\n\n\n\n\n\n\nNote\n\n\n\nA lot of the content within this course is based on the open-source book Statistical Inference via Data Science and thus is a useful source for additional examples and questions.\n\n\nFirst, start by opening RStudio by going to Desktop -&gt; Maths-Stats -&gt; RStudio. Once RStudio has opened create a new R script by going to File -&gt; New File -&gt; R Script. Next go to File -&gt; Save As... and save the script into your personal drive. Alternatively, you can download today‚Äôs session R script and open it on RStudio (remember to save any edits or comments you make on this file) :\n Download Week 1 R script \nWe shall now load into R all of the libraries we will need for this session. This can be done by typing the following into your R script:\n\nCodelibrary(ggplot2)\nlibrary(tidyverse)\nlibrary(nycflights13)\nlibrary(fivethirtyeight)\n\n\nThe libraries can be loaded into R by highlighting them in your script and then clicking on the Run button located in the top right of the script window. The first library ggplot2 allows us to use functions within that package in order to create nice data visualisations. The tidyverse library is actually a collection of different R packages for manipulating data. The final two libraries (nycflights13 and fivethirtyeight) contain interesting data sets that we shall examine in this session.\nNotice that when loading the tidyverse package you get a message that tells you about conflicting functions of certain packages. This means that there is at least one or more functions with the same name loaded from different packages (and thus one the function will mask the other).\n\nUsing :: after calling the package name every time we use the function from that package. E.g., dplyr::filter(‚Ä¶) will tell R to explicitly use the function filter from the dplyr library.\nLoad the conflicted library and use the conflicts_prefer(\"function\",\"package\") function to explicitly declare which version of the function you want to use in the remaining R session (i.e.¬†after conflicts_prefer() is called, e.g., conflict_prefer(\"filter\",\"dplyr\") .\n\n\n\n\n\n\n\n Question\n\n\n\nWhat do you think is the advantage of using the conflicts_prefer as opposed to the first approach?"
  },
  {
    "objectID": "notes.html#piping",
    "href": "notes.html#piping",
    "title": "Week 1: Visualising and data tidying using R",
    "section": "\n6.1 The pipe %>%",
    "text": "6.1 The pipe %&gt;%\nBefore we dig into data wrangling, let‚Äôs first introduce the pipe operator (%&gt;%). Just as the + sign was used to add layers to a plot created using ggplot, the pipe operator allows us to chain together data wrangling functions. The pipe operator can be read as then.\nThe piping syntax will be our major focus throughout the rest of this course and you‚Äôll find that you‚Äôll quickly be addicted to the chaining with some practice."
  },
  {
    "objectID": "notes.html#verbs",
    "href": "notes.html#verbs",
    "title": "Week 1: Visualising and data tidying using R",
    "section": "\n6.2 Data wrangling verbs",
    "text": "6.2 Data wrangling verbs\nThe d in dplyr stands for data frames, so the functions in dplyr are built for working with objects of the data frame type. In your previous R programming course you have already covered some of the most commonly used functions/verbs for wrangling and summarising data (i.e.¬†filter, summarise and group_by). Thus, on this session we won‚Äôt review these deeply (for more details of how these verbs work please refer back to your R programming course) but rather we will introduce new verbs that you might not have seen before. Here is a description of some of these verbs:\n\nselect: Select variables in a data frame\nfilter: Pick rows based on conditions about their values\nsummarize: Compute summary measures known as ‚Äúsummary statistics‚Äù of variables\ngroup_by: Group rows of observations together\nmutate: Create a new variable in the data frame by mutating existing ones\njoin: Join/merge two data frames by matching along a ‚Äúkey‚Äù variable. There are many different join available. Here, we will focus on the inner_join function.\n\nAll of the verbs are used similarly where you: take a data frame, pipe it using the %&gt;% syntax into one of the verbs above followed by other arguments specifying which criteria you would like the verb to work with in parentheses."
  },
  {
    "objectID": "notes.html#select-and-rename-columns",
    "href": "notes.html#select-and-rename-columns",
    "title": "Week 1: Visualising and data tidying using R",
    "section": "\n6.3 Select and rename columns",
    "text": "6.3 Select and rename columns\n\n\n\n\nSelect diagram from Data Wrangling with dplyr and tidyr cheatsheet.\n\n\n\nWe‚Äôve seen that the flights data frame in the nycflights13 package contains many different variables. The names function gives a listing of all the columns in a data frame; in our case you would run names(flights). However, say you only want to consider two of these variables, carrier and flight. You can select these as follows:\n\nCodeflights %&gt;%\n  select(carrier, flight)\n\n\n\n\n\n\ncarrier\nflight\n\n\n\nUA\n1545\n\n\nUA\n1714\n\n\nAA\n1141\n\n\nB6\n725\n\n\nDL\n461\n\n\n\n\n\nThe select function allows a subset of columns to be extracted, making navigation data sets with a very large number of variables easier.\nReversely, one can exclude specific columns via negative selection (using -). For instance, in the flights data set, the year variable isn‚Äôt really a variable here in that it doesn‚Äôt vary (the flights data set actually comes from a larger data set that covers many years). Thus, we may want to remove the year variable from our data set since it won‚Äôt be helpful for analysis in this case. We can deselect year by using the - sign:\n\nCodeflights_no_year &lt;- flights  %&gt;% select(-year)\n\n\nThe select function can also be used to reorder columns in combination with the everything helper function. Let‚Äôs suppose we would like the hour, minute, and time_hour variables, which appear at the end of the flights data set, to actually appear immediately after the day variable:\n\nCodeflights_reorder &lt;- flights %&gt;%\n  select(month:day, hour:time_hour, everything())\nnames(flights_reorder)\n\n [1] \"month\"          \"day\"            \"hour\"           \"minute\"        \n [5] \"time_hour\"      \"year\"           \"dep_time\"       \"sched_dep_time\"\n [9] \"dep_delay\"      \"arr_time\"       \"sched_arr_time\" \"arr_delay\"     \n[13] \"carrier\"        \"flight\"         \"tailnum\"        \"origin\"        \n[17] \"dest\"           \"air_time\"       \"distance\"      \n\n\nin this case everything() picks up all remaining variables.\n\n\n\n\n\n\nNote\n\n\n\nAlternatively we could use the relocate() verb to change column positions, using the same syntax as select() to make it easy to move blocks of columns at once. We will see an example of this in the next section.\n\n\nLastly, the helper functions starts_with, ends_with, and contains can be used to choose variables / column names that match those conditions.\n\n\n\n\n\n\n Task\n\n\n\n\nUse starts_with helper function to select the arrival time and arrival delay columns from the flights data frame.\nUse ends_with to select departure and arrival delay columns from the flights data frame.\nUse contains to select columns to select departure times, schedule departure and departure delay columns from the flights data frame.\n\n\n\nTake hint\n\nIn the flights data frame arrival time and arrival delay columns all begin with the arr character, while departure and arrival delay columns end with the delay character. Lastly, departure times, schedule departure and departure delay columns all contain the dep characters\n\n\n\n\nClick here to see the solution\n\nCode# Select arrival time and arrival delay columns\nflights %&gt;%\n  select(starts_with(\"arr\")) %&gt;%\n  slice(1:3)\n\n# A tibble: 3 √ó 2\n  arr_time arr_delay\n     &lt;int&gt;     &lt;dbl&gt;\n1      830        11\n2      850        20\n3      923        33\n\nCode# Select departure and arrival delay columns\nflights %&gt;%\n  select(ends_with(\"delay\")) %&gt;%\n  slice(1:3)\n\n# A tibble: 3 √ó 2\n  dep_delay arr_delay\n      &lt;dbl&gt;     &lt;dbl&gt;\n1         2        11\n2         4        20\n3         2        33\n\nCode# Select departure times, schedule departure and departure delay columns\nflights %&gt;%\n  select(contains(\"dep\"))%&gt;%\n  slice(1:3)\n\n# A tibble: 3 √ó 3\n  dep_time sched_dep_time dep_delay\n     &lt;int&gt;          &lt;int&gt;     &lt;dbl&gt;\n1      517            515         2\n2      533            529         4\n3      542            540         2\n\n\n\n\n\nFinally, if we want to rename a column while preserving the other columns we can use the rename function. Suppose we wanted dep_time and arr_time to be departure_time and arrival_time instead in the flights_time data frame:\n\nCodeflights_time &lt;- flights %&gt;%\n  select(contains(\"time\")) %&gt;%\n  rename(departure_time = dep_time, arrival_time = arr_time)\nnames(flights_time)\n\n[1] \"departure_time\" \"sched_dep_time\" \"arrival_time\"   \"sched_arr_time\"\n[5] \"air_time\"       \"time_hour\"     \n\n\nNote that in this case we used a single = sign with rename. e.g,. departure_time = dep_time. This is because we are not testing for equality like we would using ==, but instead we want to assign a new variable departure_time to have the same values as dep_time and then delete the variable dep_time."
  },
  {
    "objectID": "notes.html#filter",
    "href": "notes.html#filter",
    "title": "Week 1: Visualising and data tidying using R",
    "section": "\n6.4 Filter observations using filter",
    "text": "6.4 Filter observations using filter\n\n\n\n\n\n\n\n\nThe filter function allows you to specify criteria about values of a variable in your data set and then chooses only those rows that match that criteria.\n\n\n\n\n\n\nImportant\n\n\n\nRecall that the base R has already a filter function defined. So make sure to avoid any conflicts either by calling dplyr::filter() every time you use the function (specially if you have loaded the conflicts library) or alternatively run theconflict_prefer() function to let R know that it should use dplyr‚Äôs filter function as default.\n\nCodeconflict_prefer(\"filter\", \"dplyr\")\n\n[conflicted] Will prefer dplyr::filter over any other package.\n\n\n\n\nSince you have already covered this in your R programming course, let‚Äôs begin straight away by focusing only at Alaska Airlines flights leaving from New York City in 2013. We can combine the data wrangling output with ggplot plotting techniques. Run the following code and look at the resulting scatterplot.\n\nCodeflights %&gt;%\n  filter(carrier ==  \"AS\") %&gt;%\n  ggplot(aes(x = dep_delay, y = arr_delay)) +\n  geom_point()+\n   labs(x = \"Departure delay (minutes)\", y = \"Arrival delay (minutes)\",\n       title = \"Alaska Airlines flights leaving NYC in 2013\")\n\n\n\n\n\n\n\nHere is an explanation of what we‚Äôve just did:\n\nTake the data frame flights then\n\n\nfilter the data frame so that only those where the carrier equals AS are included. (recall that the double equals sign == tests equality, and not a single equals sign =).\npass the filtered data to the ggplot function and add a point layer and then modify axis labels.\n\nYou can combine multiple criteria together using operators that make comparisons:\n\n\n| corresponds to or\n\n\n& corresponds to and\n\n\nWe can often skip the use of & and just separate our conditions with a comma. You‚Äôll see this in the example below.\n\n\n\n\n\n\nNote\n\n\n\nIn addition, you can use other mathematical checks (similar to ==):\n\n&gt; corresponds to greater than\n&lt; corresponds to less than\n&gt;= corresponds to greater than or equal to\n&lt;= corresponds to less than or equal to\n!= corresponds to not equal to\n\n\n\nTo see many of these in action, let‚Äôs select all flights that left JFK airport heading to Burlington, Vermont (BTV) or Seattle, Washington (SEA) in the months of October, November, or December. Run the following:\n\nCodebtv_sea_flights_fall &lt;- flights %&gt;%\n  filter(origin == \"JFK\", (dest == \"BTV\" | dest == \"SEA\"), month &gt;= 10) %&gt;%\n  relocate(dest,.before = dep_time )\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nyear\nmonth\nday\ndest\ndep_time\nsched_dep_time\ndep_delay\narr_time\nsched_arr_time\narr_delay\ncarrier\nflight\ntailnum\norigin\nair_time\ndistance\nhour\nminute\ntime_hour\n\n\n\n2013\n10\n1\nSEA\n729\n735\n-6\n1049\n1040\n9\nDL\n183\nN721TW\nJFK\n352\n2422\n7\n35\n2013-10-01 07:00:00\n\n\n2013\n10\n1\nSEA\n853\n900\n-7\n1217\n1157\n20\nB6\n63\nN807JB\nJFK\n362\n2422\n9\n0\n2013-10-01 09:00:00\n\n\n2013\n10\n1\nBTV\n916\n925\n-9\n1016\n1033\n-17\nB6\n1634\nN192JB\nJFK\n48\n266\n9\n25\n2013-10-01 09:00:00\n\n\n\n\n\n\n\n\n\n\n\nNote\n\n\n\nEven though colloquially speaking one might say ‚Äúall flights leaving Burlington, Vermont and Seattle, Washington,‚Äù in terms of computer logical operations, we really mean ‚Äúall flights leaving Burlington, Vermont or Seattle, Washington.‚Äù For a given row in the data, dest can be BTV, SEA, or something else, but not BTV and SEA at the same time. Also note that we have used the relocate function to change the dest column position to just before the dep_time. See ?relocate for further details.\n\n\nAnother example uses ! to pick rows that do not match a condition. The ! can be read as not. Here, we are selecting rows corresponding to flights that did not go to Burlington, VT or Seattle, WA.\n\nCodenot_BTV_SEA &lt;- flights %&gt;%\n  filter(!(dest == \"BTV\" | dest == \"SEA\")) %&gt;%\n  relocate(dest,.before = dep_time )\nnot_BTV_SEA %&gt;%\n  slice(1:3)\n\n# A tibble: 3 √ó 19\n   year month   day dest  dep_time sched_dep_time dep_delay arr_time\n  &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;chr&gt;    &lt;int&gt;          &lt;int&gt;     &lt;dbl&gt;    &lt;int&gt;\n1  2013     1     1 IAH        517            515         2      830\n2  2013     1     1 IAH        533            529         4      850\n3  2013     1     1 MIA        542            540         2      923\n# ‚Ñπ 11 more variables: sched_arr_time &lt;int&gt;, arr_delay &lt;dbl&gt;, carrier &lt;chr&gt;,\n#   flight &lt;int&gt;, tailnum &lt;chr&gt;, origin &lt;chr&gt;, air_time &lt;dbl&gt;, distance &lt;dbl&gt;,\n#   hour &lt;dbl&gt;, minute &lt;dbl&gt;, time_hour &lt;dttm&gt;\n\n\nAs a final note we point out that filter should often be the first verb you‚Äôll apply to your data. This narrows down the data to just the observations your are interested in.\n\n\n\n\n\n\n Task\n\n\n\nWhat is another way of using the not operator ! to filter only the rows that are not going to Burlington, VT nor Seattle, WA in the flights data frame?\n\n\nTake a hint\n\nTry using the %in% operator\n\n\n\n\nClick here to see the solution\n\nCodeflights %&gt;%\n  filter( !dest %in% c(\"BTV\",\"SEA\")) %&gt;%\n  head()\n\n# A tibble: 6 √ó 19\n   year month   day dep_time sched_dep_time dep_delay arr_time sched_arr_time\n  &lt;int&gt; &lt;int&gt; &lt;int&gt;    &lt;int&gt;          &lt;int&gt;     &lt;dbl&gt;    &lt;int&gt;          &lt;int&gt;\n1  2013     1     1      517            515         2      830            819\n2  2013     1     1      533            529         4      850            830\n3  2013     1     1      542            540         2      923            850\n4  2013     1     1      544            545        -1     1004           1022\n5  2013     1     1      554            600        -6      812            837\n6  2013     1     1      554            558        -4      740            728\n# ‚Ñπ 11 more variables: arr_delay &lt;dbl&gt;, carrier &lt;chr&gt;, flight &lt;int&gt;,\n#   tailnum &lt;chr&gt;, origin &lt;chr&gt;, dest &lt;chr&gt;, air_time &lt;dbl&gt;, distance &lt;dbl&gt;,\n#   hour &lt;dbl&gt;, minute &lt;dbl&gt;, time_hour &lt;dttm&gt;"
  },
  {
    "objectID": "notes.html#mutate",
    "href": "notes.html#mutate",
    "title": "Week 1: Visualising and data tidying using R",
    "section": "\n6.5 Create new variables/change old variables using mutate",
    "text": "6.5 Create new variables/change old variables using mutate\n\n\n\n\n\n\n\n\nWhen looking at the flights data set, there are some clear additional variables that could be calculated based on the values of variables already in the data set. Passengers are often frustrated when their flights depart late, but change their mood a bit if pilots can make up some time during the flight to get them to their destination close to when they expected to land. This is commonly referred to as ‚Äúgain‚Äù and we will create this variable using the mutate function. Note that we will be overwriting the flights data frame with one including the additional variable gain here, or put differently, the mutate command outputs a new data frame which then gets saved over the original flights data frame.\n\nCodeflights &lt;- flights %&gt;%\n  mutate(gain = dep_delay - arr_delay)\n\n\nLet‚Äôs take a look at dep_delay, arr_delay, and the resulting gain variables in our new flights data frame:\n\n\n\n\ndep_delay\narr_delay\ngain\n\n\n\n2\n11\n-9\n\n\n4\n20\n-16\n\n\n2\n33\n-31\n\n\n-1\n-18\n17\n\n\n-6\n-25\n19\n\n\n\n\n\nThe flight in the first row departed 2 minutes late but arrived 11 minutes late, so its ‚Äúgained time in the air‚Äù is actually a loss of 9 minutes, hence its gain is -9. Contrast this to the flight in the fourth row which departed a minute early (dep_delay of -1) but arrived 18 minutes early (arr_delay of -18), so its ‚Äúgained time in the air‚Äù is 17 minutes, hence its gain is +17.\n\n\n\n\n\n\n Question\n\n\n\nWhy did we overwrite flights instead of assigning the resulting data frame to a new object, like flights_with_gain?\n\n\nAnswer\n\nAs a rough rule of thumb, as long as you are not losing information that you might need later, it‚Äôs acceptable practice to overwrite data frames. However, if you overwrite existing variables and/or change the observational units, recovering the original information might prove difficult. In this case, it might make sense to create a new data object.\n\n\n\nLet‚Äôs look at visualize this gain variable in the form of a histogram:\n\nCodeggplot(data = flights, mapping = aes(x = gain)) +\n  geom_histogram(color = \"white\", bins = 20)\n\n\n\n\n\n\n\nWe can also create multiple columns at once and even refer to columns that were just created in a new column.\n\n\n\n\ngain\nhours\ngain_per_hour\n\n\n\n-9\n3.783333\n-2.378855\n\n\n-16\n3.783333\n-4.229075\n\n\n-31\n2.666667\n-11.625000\n\n\n17\n3.050000\n5.573771\n\n\n19\n1.933333\n9.827586\n\n\n\n\n\n\n\n\n\n\n\n Question\n\n\n\nWhat do positive values of the gain variable in flights correspond to?\n\nDeparture delays are greater than arrivals delays\nDeparture delays are lower than arrivals delays\nDepartures and arrivals delays are the same\nWhat about negative values?\n\nDeparture delays are greater than arrivals delays\nDeparture delays are lower than arrivals delays\nDepartures and arrivals delays are the same\nAnd what about a zero value?\n\nDeparture delays are greater than arrivals delays\nDeparturedelays are lower than arrivals delays\nDepartures and arrivals delays are the same\n\n\n\n\n\n\n\n\n Question\n\n\n\nCould we create the dep_delay and arr_delay columns by simply subtracting dep_time from sched_dep_time and similarly for arrivals? Try the code out and explain any differences between the result and what actually appears in flights.\n\nflights %&gt;%\n  mutate(dep_delay  = sched_dep_time - dep_time ,\n         arr_delay  = sched_arr_time  - arr_time)\n\n\n\nTake a hint\n\nSee the description of the variables arr_time, dep_time, sched_dep_time and sched_arr_time in the flights data set ?flights\n\n\n\nAnswer\n\nThe differences are due to departure and arrival times have a HHMM or HMM format. E.g., if we compute the difference between a flight scheduled to arrive by 923 and its actual arrival time at 850, the result would be a difference of 73, while in reality there was only a 33 min difference if we consider the correct time format! We will see more detials on how to work with time-date variables later on in this session."
  },
  {
    "objectID": "notes.html#summarize",
    "href": "notes.html#summarize",
    "title": "Week 1: Visualising and data tidying using R",
    "section": "\n6.6 Summarise variables using summarize",
    "text": "6.6 Summarise variables using summarize\nThe next common task is to be able to summarise data: take a large number of values and summarise them with a single value. While this may seem like a very abstract idea, something as simple as the sum, the smallest value, and the largest values are all summaries of a large number of values.\n\n\n\n\n\n\n\n\nWe can calculate the standard deviation and mean of the temperature variable temp in the weather data frame of nycflights13 in one step using the summarize (or equivalently using the UK spelling summarise) function in dplyr. Before compute the mean it is important to notice that there are some missing values in the data. Thus, by default any time you try to summarise a number of values (using mean() and sd() for example) that has one or more missing values, an NA will be returned.\nYou can summarise all non-missing values by setting the na.rm argument to TRUE (rm is short for remove). This will remove any NA missing values and only return the summary value for all non-missing values. So the code below computes the mean and standard deviation of all non-missing values. Notice how the na.rm=TRUE are set as arguments to the mean and sd functions, and not to the summarize function.\n\nCodesummary_temp &lt;- weather %&gt;%\n  summarize(mean = mean(temp, na.rm = TRUE), std_dev = sd(temp, na.rm = TRUE))\nsummary_temp\n\n# A tibble: 1 √ó 2\n   mean std_dev\n  &lt;dbl&gt;   &lt;dbl&gt;\n1  55.3    17.8\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nImportant\n\n\n\nIt is not good practice to include na.rm = TRUE in your summary commands by default; you should attempt to run code first without this argument as this will alert you to the presence of missing data. Only after you have identified where missing values occur and have thought about the potential issues of these should you consider using na.rm = TRUE.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n Question\n\n\n\nSay a doctor is studying the effect of smoking on lung cancer for a large number of patients who have records measured at five year intervals. She notices that a large number of patients have missing data points because the patient has died, so she chooses to ignore these patients in her analysis. What is wrong with this doctor‚Äôs approach?\n\nIntroduces a selection bias since patient who died due to lung cancer are excluded from the analysis, leading to an underestimation of the true impact of smoking on lung cancer riskThere is no problem, smaller datasets with fewer missing values may require less computational resources, leading to faster processing times.Removing patients with missing data reduces the sample size. Hence, conclusions may not be as easily generalizable to the broader population, as the excluded patients may represent a different subset with unique characteristics.Removing missing values can result in a dataset with fewer errors and inconsistencies, which can lead to more accurate analyses."
  },
  {
    "objectID": "notes.html#groupby",
    "href": "notes.html#groupby",
    "title": "Week 1: Visualising and data tidying using R",
    "section": "\n6.7 Using grouping structures",
    "text": "6.7 Using grouping structures\n\n\n\n\n\n\n\n\nIt is often more useful to summarise a variable based on the groupings of another variable. Let‚Äôs say we are interested in the mean and standard deviation of temperatures but grouped by month. Run the following code:\n\nCodesummary_monthly_temp &lt;- weather %&gt;%\n  summarize(mean = mean(temp, na.rm = TRUE),\n            std_dev = sd(temp, na.rm = TRUE),\n            .by = month)\n\n\nThis code is identical to the previous code that created summary_temp, with an extra .by = month added. This kind per-operation grouping allow us to do the grouping within the operation where the summarisation takes place without changing the structure of the data .\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n Question\n\n\n\nThe drop_na() function can be used in the pipeline to remove missing observations from a data set. Try running the following code to compute the mean and standard deviation of the temperature in the weather data set and comment on the output. Why is this different from one one we had before?\n\nsummary_monthly_temp &lt;- weather %&gt;%\n  drop_na() %&gt;%\n  summarize(mean = mean(temp),\n            std_dev = sd(temp),\n            .by = month)\n\n\n\nAnswer\n\nThe drop_na() function remove all missing observation from the data set while specifying na.rm =T in each summarizing function only removes the missing values for the specific variable to which the function is applied.\n\n\n\nWe now revisit the n counting summary function (see the R programming course for more details). For example, suppose we would like to get a sense for how many flights departed from each of the three airports in New York City:\n\nCodeby_origin &lt;- flights %&gt;%\n  summarize(count = n(),\n            .by =origin)\nby_origin\n\n\n\n\n\n\n\norigin\ncount\n\n\n\nEWR\n120835\n\n\nJFK\n111279\n\n\nLGA\n104662\n\n\n\n\n\n\nWe see that Newark (EWR) had the most flights departing in 2013 followed by JFK and lastly by LaGuardia (LGA). Note, there is a subtle but important difference between sum and n. While sum simply adds up a large set of numbers, the latter counts the number of times each of many different values occur.\n\n\n\n\n\n\nTask\n\n\n\nWith the weather data set, write code to produce the mean and standard deviation temperature for each day in 2013 for NYC.\n\n\nTake a hint\n\nSee the documentation for summarize() (?summarize)\n\n\n\n\nClick here to see the solution\n\nCode weather %&gt;%\n  summarize(mean = mean(temp, na.rm = TRUE),\n            std_dev = sd(temp, na.rm = TRUE),\n            .by = day)\n\n# A tibble: 31 √ó 3\n     day  mean std_dev\n   &lt;int&gt; &lt;dbl&gt;   &lt;dbl&gt;\n 1     1  57.6    17.4\n 2     2  55.7    20.2\n 3     3  53.8    18.9\n 4     4  54.0    18.8\n 5     5  55.6    16.2\n 6     6  55.7    15.6\n 7     7  55.6    17.4\n 8     8  55.0    17.6\n 9     9  56.6    17.4\n10    10  56.9    17.8\n# ‚Ñπ 21 more rows"
  },
  {
    "objectID": "notes.html#grouping-by-more-than-one-variable",
    "href": "notes.html#grouping-by-more-than-one-variable",
    "title": "Week 1: Visualising and data tidying using R",
    "section": "\n6.8 Grouping by more than one variable",
    "text": "6.8 Grouping by more than one variable\nYou are not limited to grouping by one variable. Say you wanted to know the number of flights leaving each of the three New York City airports for each month, we can also group by a second variable month:\n\nCodeby_origin_monthly &lt;- flights %&gt;%\n  summarize(count = n(),\n            .by = c(origin, month))\nby_origin_monthly\n\n# A tibble: 36 √ó 3\n   origin month count\n   &lt;chr&gt;  &lt;int&gt; &lt;int&gt;\n 1 EWR        1  9893\n 2 LGA        1  7950\n 3 JFK        1  9161\n 4 EWR       10 10104\n 5 JFK       10  9143\n 6 LGA       10  9642\n 7 JFK       11  8710\n 8 EWR       11  9707\n 9 LGA       11  8851\n10 JFK       12  9146\n# ‚Ñπ 26 more rows\n\n\nWe see there are 36 rows for by_origin_monthly because there are 12 months times 3 airports (EWR, JFK, and LGA). How can we visualize this information? Lets look now into different techniques for manipulation and visualizing categorical data."
  },
  {
    "objectID": "notes.html#visualizing-categorical-data",
    "href": "notes.html#visualizing-categorical-data",
    "title": "Week 1: Visualising and data tidying using R",
    "section": "\n7.1 Visualizing categorical data",
    "text": "7.1 Visualizing categorical data\nRecall that barplots, or barcharts, are used to visualise the distributions of categorical variables. This essentially provides us with the frequencies of categories within a categorical variable. You can use either the raw data (e.g.¬†the original flights data set) or the summarised data set (e.g.¬†the by_origin_monthly data set we just created) to create barplots in ggplot.\n\n\nRaw data and geom_bar()\nSummarized data set and geom_col()\n\n\n\nHere we can use a data set with variable(s) representing the categories. We can add a geom_bar() layer to create a barplot layer by counting the number of cases for each level of a categorical variable and use the fill=origin option to assign a different color to the counts based on the origin.\n\nflights %&gt;%\n  ggplot(aes(x=factor(month),fill=origin))+\n  geom_bar()+\n  scale_x_discrete(labels = month.abb) +\n  labs(x= \"Months\",y=\"Number of flights\")\n\n\n\n\n\n\n\nNote that the month variable in our data set is an integer. Thus, we convert this into a factor using the factor() function directly in the aesthetic mapping. Then we provide appropriate labels for each month (labels = month.abb) by adding one more scale_x_discretelayer.\n\n\nHere we can use a data set with variables representing the categories and the counts of each category (e.g.¬†the by_origin_monthly data set we just created). To produce the bar plot we add a geom_col() layer which expects a data set that already contains the counts for each group. We use the fill=origin option to assign a different color to the counts based on the origin.\n\nby_origin_monthly %&gt;%\nggplot(aes(x = factor(month), y = count, fill= origin )) +\n  geom_col() +\n  scale_x_discrete(labels = month.abb)+\n    labs(x= \"Months\",y=\"Number of flights\")\n\n\n\n\n\n\n\nNote that the month variable in our data set is an integer. Thus, we convert this into a factor using the factor() function directly in the aesthetic mapping. Then we provide appropriate labels for each month (labels = month.abb) by adding one more scale_x_discretelayer.\n\n\n\nThis is what is referred to as a Stacked barplot since the bars for each origin are simply stacked on top of one another for each of the carriers. This provides us with a visually nice barplot to present the monthly number of flights by airport of origin. However, there are also alternative barplots to the stacked barplot.\n\nOne alternative to a stacked barplot is the side-by-side (or dodged) barplot, which, as suggested by its name, places the bars next to each other instead of on top of one another. This can be produced by including position = 'dodge' within the geom_col or geom_bar layer.\n\n\n\n\n\n\n\n Question\n\n\n\nHow would you modify the code above to produced a dodged barplot?\n\n\nAnswer\n\nDepending on the structure of your data you could change the column/bar layer to geom_col(position = \"dodge\") or geom_bar(position = \"dodge\") respectively.\n\n\n\n\nA second alternative is to use a faceted barplot. This can be produced by adding a facet_wrap() layer to ggplot. E.g. try adding facet_wrap(~ origin, ncol = 1) to any of the previous barplots you have produced. The facet_wrap function tells ggplot that we want to separate out barplots by origin, and hence we use ~ origin.\n\n\n\n\n\n\n\nTask\n\n\n\nBoxplots are useful visualisations when comparing the distribution of a numerical variable split across groups (or a categorical variable). Taking the weather data set, use ggplot to create a boxplot showing how the hourly temperature changes by month for each of the three different Weather stations (origin variable). Use a different color for each station.\n\n\nTake a hint\n\nTo create boxplots using ggplot you can use the geom_boxplot function. If we want to look at boxplots of a variable separately for a categorical variable then you need to declare that variable as a factor using the factor function.\n\n\n\n\nClick here to see the solution\n\nCodeggplot(data = weather, mapping = aes(x = factor(month), y = temp, fill = origin)) +\n  geom_boxplot() +\n  facet_wrap(~origin)+\n  labs(x = \"Month\", y = \"Temperature (Hourly)\",\n        title = \"Hourly temperatures from NYC in 2013 by month\")  +\n   scale_x_discrete(labels = month.abb)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nTask\n\n\n\nBy using the summarise() function, how could we identify how many flights left each of the three airports for each carrier? Can you create a barplot showing these results?\n\n\nTake a hint\n\nYou can count how many flights left each of the three airports by summarising the data using the n() function while grouping by the origin and carrier. Then, you can pass the resulting data frame to ggplot using the pipeline command %&gt;% and use a geom_col layer as in the previous example.\n\n\n\n\nClick here to see the solution\n\nCodeflights %&gt;%\n  summarise(count = n(),\n            .by = c(origin,carrier)) %&gt;%\n  ggplot(aes(x = carrier, y = count, fill = origin)) + geom_col()"
  },
  {
    "objectID": "notes.html#vectorised-if-else-thru-case_when",
    "href": "notes.html#vectorised-if-else-thru-case_when",
    "title": "Week 1: Visualising and data tidying using R",
    "section": "\n7.2 Vectorised if-else thru case_when\n",
    "text": "7.2 Vectorised if-else thru case_when\n\nIn many situations, we may want to represent continuous variables as discrete categories (e.g., grouping temperatures into ‚Äúcold,‚Äù ‚Äúwarm,‚Äù and ‚Äúhot‚Äù ranges). The case_when function provides an efficient way to handle multiple if-else statements by vectorizing them, allowing us to evaluate conditions and assign categories more cleanly and concisely. In this session, we will use case_when to categorize weather conditions based on meteorological data from the weather dataset. Let suppose that we want to categorize the temperature variable into three categories:\n\nlow for temperatures \\(&lt;39.9\\)\nmedium for temperature values \\(\\geq 39.9\\) and \\(\\leq 70\\)\nhigh for temperature values \\(&gt; 70\\)\n\nWe can achieve this with the following code:\n\nCodeweather %&gt;%\n  mutate(\n    temp_cat = case_when(\n      is.na(temp) ~ NA,\n      temp &lt; 39.9 ~ \"low\",\n      between(temp,39.9 ,70)~ \"medium\",\n      .default = \"large\"\n    )\n  ) %&gt;%\n  relocate(temp,temp_cat)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\ntemp\ntemp_cat\norigin\nyear\nmonth\nday\nhour\ndewp\nhumid\nwind_dir\nwind_speed\nwind_gust\nprecip\npressure\nvisib\ntime_hour\n\n\n\n39.02\nlow\nEWR\n2013\n1\n1\n1\n26.06\n59.37\n270\n10.35702\nNA\n0\n1012.0\n10\n2013-01-01 01:00:00\n\n\n39.02\nlow\nEWR\n2013\n1\n1\n2\n26.96\n61.63\n250\n8.05546\nNA\n0\n1012.3\n10\n2013-01-01 02:00:00\n\n\n39.02\nlow\nEWR\n2013\n1\n1\n3\n28.04\n64.43\n240\n11.50780\nNA\n0\n1012.5\n10\n2013-01-01 03:00:00\n\n\n39.92\nmedium\nEWR\n2013\n1\n1\n4\n28.04\n62.21\n250\n12.65858\nNA\n0\n1012.2\n10\n2013-01-01 04:00:00\n\n\n39.02\nlow\nEWR\n2013\n1\n1\n5\n28.04\n64.43\n260\n12.65858\nNA\n0\n1011.9\n10\n2013-01-01 05:00:00\n\n\n\n\n\nHere we use the mutate command to create new variable named temp_cat. The case_when will then set to NA those values in the original temp variable that are missing. Then if the values of temp are \\(&lt; 30.9\\) it will assign them the label of low. If they lie between \\(39.9\\) and \\(70\\) it will assign them the label of medium and finally set to large any of the values that do not meet any of the aforementioned conditions. We can also use the function relocate to change the columns position so that the temp and temp_cat appears first on the data frame.\n\n\n\n\n\n\nTask\n\n\n\nCreate a new variable called extreme_weather that takes the value of extreme if the wind speed exceeds 64 mph and the temperature is less than 40¬∞F and not extreme otherwise. Then, relocate this new variable along with the variables used to create it at the first columns of the data frame, and sort them out based on wind_speed.\n\n\nTake a hint\n\nUse the conditional operators | and & to add multiple conditions.\n\n\n\n\nClick here to see the solution\n\nCodeweather %&gt;%\n  mutate(\n    extreme_weather  = case_when(\n      is.na(temp)|is.na(wind_speed) ~ NA,\n      temp &lt; 40 & wind_speed  &gt; 64~ \"extreme\",\n      .default = \"not extreme\"\n    )\n  ) %&gt;%\n  relocate(extreme_weather,temp,wind_speed) |&gt;\n  arrange(desc(wind_speed))\n\n# A tibble: 26,115 √ó 16\n   extreme_weather  temp wind_speed origin  year month   day  hour  dewp humid\n   &lt;chr&gt;           &lt;dbl&gt;      &lt;dbl&gt; &lt;chr&gt;  &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;dbl&gt; &lt;dbl&gt;\n 1 extreme          39.0     1048.  EWR     2013     2    12     3 27.0   61.6\n 2 not extreme      57.2       42.6 EWR     2013     1    31     6 53.6   87.7\n 3 not extreme      53.6       42.6 JFK     2013     1    31     4 53.1  100  \n 4 not extreme      60.8       40.3 EWR     2013     1    31     4 59     93.8\n 5 not extreme      59         40.3 LGA     2013     1    31     4 55.4   93.7\n 6 not extreme      46.0       39.1 EWR     2013     1    31     8 30.0   53.3\n 7 not extreme      41         38.0 JFK     2013     3     6    14 28.9   61.9\n 8 not extreme      53.1       36.8 JFK     2013     1    31     3 52.0  100  \n 9 not extreme      51.8       36.8 JFK     2013     1    31     7 46.4   81.7\n10 not extreme      28.0       36.8 JFK     2013    11    24    10 -0.04  29.2\n# ‚Ñπ 26,105 more rows\n# ‚Ñπ 6 more variables: wind_dir &lt;dbl&gt;, wind_gust &lt;dbl&gt;, precip &lt;dbl&gt;,\n#   pressure &lt;dbl&gt;, visib &lt;dbl&gt;, time_hour &lt;dttm&gt;"
  },
  {
    "objectID": "notes.html#joining-by-key-variables",
    "href": "notes.html#joining-by-key-variables",
    "title": "Week 1: Visualising and data tidying using R",
    "section": "\n8.1 Joining by ‚Äúkey‚Äù variables",
    "text": "8.1 Joining by ‚Äúkey‚Äù variables\nIn both flights and airlines, the key variable we want to join/merge/match the two data frames with has the same name in both data sets: carriers. We make use of the inner_join function to join by the variable carrier.\n\nCodeflights_joined &lt;- flights %&gt;%\n  inner_join(airlines,\n             by = join_by(carrier))\n\n\nIf we compare the flights and the flights_joined we just created, we will observe that these are identical except that flights_joined has an additional variable name whose values were drawn from airlines.\nA visual representation of the inner_join is given below:\n\n\n\n\nDiagram of inner join from R for Data Science.\n\n\n\nThere are more complex joins available, but the inner_join will solve nearly all of the problems you will face here."
  },
  {
    "objectID": "notes.html#joining-by-key-variables-with-different-names",
    "href": "notes.html#joining-by-key-variables-with-different-names",
    "title": "Week 1: Visualising and data tidying using R",
    "section": "\n8.2 Joining by ‚Äúkey‚Äù variables with different names",
    "text": "8.2 Joining by ‚Äúkey‚Äù variables with different names\nSay instead, you are interested in all the destinations of flights from NYC in 2013 and ask yourself:\n\n‚ÄúWhat cities are these airports in?‚Äù\n‚ÄúIs ORD Orlando?‚Äù\n‚ÄúWhere is FLL?‚Äù\n\nThe airports data frame contains airport codes:\n\nairports\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nfaa\nname\nlat\nlon\nalt\ntz\ndst\ntzone\n\n\n\n04G\nLansdowne Airport\n41.13047\n-80.61958\n1044\n-5\nA\nAmerica/New_York\n\n\n06A\nMoton Field Municipal Airport\n32.46057\n-85.68003\n264\n-6\nA\nAmerica/Chicago\n\n\n06C\nSchaumburg Regional\n41.98934\n-88.10124\n801\n-6\nA\nAmerica/Chicago\n\n\n06N\nRandall Airport\n41.43191\n-74.39156\n523\n-5\nA\nAmerica/New_York\n\n\n09J\nJekyll Island Airport\n31.07447\n-81.42778\n11\n-5\nA\nAmerica/New_York\n\n\n\n\n\nHowever, looking at both the airports and flights and the visual representation of the relations between the data frames in the figure above, we see that in:\n\n\nairports the airport code is in the variable faa\n\n\nflights the airport code is in the variable origin\n\n\nSo to join these two data sets, our inner_join operation involves a logical operator == argument that accounts for the different names.\n\nCodeflights %&gt;%\n  inner_join(airports,\n             by = join_by(dest == faa))\n\n\nWe can read the code out loud as:\n‚ÄúTake the flights data frame and inner join it to the airports data frame by the entries where the variable dest is equal to faa‚Äù\nLet‚Äôs construct the sequence of commands that computes the number of flights from NYC to each destination, but also includes information about each destination airport:\n\nCodenamed_dests &lt;- flights %&gt;%\n  summarize(num_flights = n(),\n            .by = dest)  %&gt;%\n  arrange(desc(num_flights))  %&gt;%\n  inner_join(airports, by = join_by(dest == faa)) %&gt;%\n  rename(airport_name = name)\nnamed_dests\n\n\n\n\n# A tibble: 5 √ó 9\n  dest  num_flights airport_name              lat    lon   alt    tz dst   tzone\n  &lt;chr&gt;       &lt;int&gt; &lt;chr&gt;                   &lt;dbl&gt;  &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;chr&gt; &lt;chr&gt;\n1 ORD         17283 Chicago Ohare Intl       42.0  -87.9   668    -6 A     Amer‚Ä¶\n2 ATL         17215 Hartsfield Jackson Atl‚Ä¶  33.6  -84.4  1026    -5 A     Amer‚Ä¶\n3 LAX         16174 Los Angeles Intl         33.9 -118.    126    -8 A     Amer‚Ä¶\n4 BOS         15508 General Edward Lawrenc‚Ä¶  42.4  -71.0    19    -5 A     Amer‚Ä¶\n5 MCO         14082 Orlando Intl             28.4  -81.3    96    -5 A     Amer‚Ä¶\n\n\nIn case you didn‚Äôt know, ORD is the airport code of Chicago O‚ÄôHare airport and FLL is the main airport in Fort Lauderdale, Florida, which we can now see in our named_dests data frame."
  },
  {
    "objectID": "notes.html#joining-by-multiple-key-variables",
    "href": "notes.html#joining-by-multiple-key-variables",
    "title": "Week 1: Visualising and data tidying using R",
    "section": "\n8.3 Joining by multiple ‚Äúkey‚Äù variables",
    "text": "8.3 Joining by multiple ‚Äúkey‚Äù variables\nSay instead we are in a situation where we need to join by multiple variables. For example, in the first figure in this section we see that in order to join the flights and weather data frames, we need more than one key variable: year, month, day, hour, and origin. This is because the combination of these 5 variables act to uniquely identify each observational unit in the weather data frame: hourly weather recordings at each of the 3 NYC airports.\nWe achieve this by specifying a vector of key variables to join by.\n\nCodeflights_weather_joined &lt;- flights  %&gt;%\n  inner_join(weather,\n             by = join_by(year,month,day,hour,origin))\n\nflights_weather_joined\n\n# A tibble: 335,220 √ó 32\n    year month   day dep_time sched_dep_time dep_delay arr_time sched_arr_time\n   &lt;int&gt; &lt;int&gt; &lt;int&gt;    &lt;int&gt;          &lt;int&gt;     &lt;dbl&gt;    &lt;int&gt;          &lt;int&gt;\n 1  2013     1     1      517            515         2      830            819\n 2  2013     1     1      533            529         4      850            830\n 3  2013     1     1      542            540         2      923            850\n 4  2013     1     1      544            545        -1     1004           1022\n 5  2013     1     1      554            600        -6      812            837\n 6  2013     1     1      554            558        -4      740            728\n 7  2013     1     1      555            600        -5      913            854\n 8  2013     1     1      557            600        -3      709            723\n 9  2013     1     1      557            600        -3      838            846\n10  2013     1     1      558            600        -2      753            745\n# ‚Ñπ 335,210 more rows\n# ‚Ñπ 24 more variables: arr_delay &lt;dbl&gt;, carrier &lt;chr&gt;, flight &lt;int&gt;,\n#   tailnum &lt;chr&gt;, origin &lt;chr&gt;, dest &lt;chr&gt;, air_time &lt;dbl&gt;, distance &lt;dbl&gt;,\n#   hour &lt;dbl&gt;, minute &lt;dbl&gt;, time_hour.x &lt;dttm&gt;, gain &lt;dbl&gt;, hours &lt;dbl&gt;,\n#   gain_per_hour &lt;dbl&gt;, temp &lt;dbl&gt;, dewp &lt;dbl&gt;, humid &lt;dbl&gt;, wind_dir &lt;dbl&gt;,\n#   wind_speed &lt;dbl&gt;, wind_gust &lt;dbl&gt;, precip &lt;dbl&gt;, pressure &lt;dbl&gt;,\n#   visib &lt;dbl&gt;, time_hour.y &lt;dttm&gt;\n\n\n\n\n\n\n\n\n Question\n\n\n\nLooking at the first figure in this section, when joining flights and weather (or, in other words, matching the hourly weather values with each flight), why do we need to join by all of year, month, day, hour, and origin, and not just hour?\n\n\nAnswer\n\nyear,month,day,hour,origin are the key variables that allow us to uniquely identify the observational units.\n\n\n\n\n\n\n\n\n\nTask\n\n\n\nCreate a new data frame that shows the top 5 airports with the largest average arrival delays from NYC in 2013.\n\n\nTake a hint\n\nCompute the mean arrival delay from each destination. You can then join the resulting data set with the airports data which contains the airports names and search for the top 5 entries.\n\n\n\n\nClick here to see the solution\n\nCode  flights %&gt;%\n  summarize(mean_arr_delay = mean(arr_delay,na.rm=T),\n            .by = dest)  %&gt;%\n  inner_join(airports, by = join_by(dest == faa)) %&gt;%\n  rename(airport_name = name) |&gt;\n    slice_max(mean_arr_delay,n=5)"
  }
]