{
  "hash": "627ef7d26abb3ff683fa10d8519f2530",
  "result": {
    "markdown": "---\ntitle: \"Week 2: Tidying and Wrangling data using R\"\nformat:\n  pdf:\n    latex-auto-install: true\n  html:    \n    code-link: true\n    code-fold: true\n    code-tools:\n      source: false\n      toggle: true\n    toc: true\n    toc-location: left\n    toc-title: Contents\n    number-sections: true\neditor: visual\neditor_options: \n  chunk_output_type: console\n---\n\n# Getting started\n\nThis week we will demonstrate various techniques for **tidying** and **wrangling** data in R. From the 'Introduction to R Programming' course we are familiar with a data frame in R: a rectangular spreadsheet-like representation of data in R where the rows correspond to observations and the columns correspond to variables describing each observation. In Week 1 of Data Analysis, we started exploring the data frame `flights` included in the `nycflights13` package by creating visualisations of the data contained within said data frame.\n\nHere we will discover a type of data formatting called **tidy** data. You will see that having data stored in the **tidy** format is about more than what the colloquial definition of the term **tidy** might suggest of having your data \"neatly organised\" in a spreadsheet. Instead, we define the term **tidy** in a more rigorous fashion, outlining a set of rules by which data can be stored and the implications of these rules on analyses.\n\n::: callout-note\nThis session is based on Chapters 4 and 5 of the open-source book [An Introduction to Statistical and Data Science via R](https://moderndive.com/index.html) which can be consulted at any point.\n:::\n\nFirst, start by opening **RStudio** by going to `Desktop -> Maths-Stats -> RStudio`. Once RStudio has opened create a new R script by going to `File -> New File -> R Script`. Next go to `File -> Save As...` and save the script into your personal drive, either `M:` or `K:` (do not save it to the `H:` drive). We shall now load into R all of the libraries we will need for this session. This can be done by typing the following into your R script:\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(tidyverse)\nlibrary(nycflights13)\nlibrary(fivethirtyeight)\n```\n:::\n\n\nThe `tidyverse` library is actually a collection of different R packages for transforming and visualising data. The final two libraries (`nycflights13` and `fivethirtyeight`) contain interesting data sets that we shall examine in this session. Notice that when loading the `tidyverse` package you get a message that tells you about conflicting functions of certain packages. This means that there is at least one or more functions with the same name loaded from different packages (and thus one the function will mask the other). You can use the function `tidyverse_conflicts()` for getting a list of the conflicted packages:\n\n\n::: {.cell}\n\n```{.r .cell-code  code-fold=\"true\"}\ntidyverse_conflicts()\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n-- Conflicts ------------------------------------------ tidyverse_conflicts() --\nx dplyr::filter() masks stats::filter()\nx dplyr::lag()    masks stats::lag()\ni Use the conflicted package (<http://conflicted.r-lib.org/>) to force all conflicts to become errors\n```\n:::\n:::\n\n\nIn here, we can see for example that the `filter` function from the `dplyr` package has a conflict with the `filter` function in base R `stats` library. A way of sorting that out is to load the `dplyr` library after base R so that R will only consider the version of the function that was last loaded. We can be more rigorous about this and load the `conflicted` library. This will prohibit us to us any functions that have some conflict with previously defined functions.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(conflicted)\n```\n:::\n\n\nBy doing this, we would need to be more specific about the source package from which the desired function should be loaded. There are two ways of doing this:\n\n1.  Using `::` after calling the package name every time we use the function from that package. E.g., `dplyr::filter(â€¦)` will tell R to explicitly use the function `filter` from the `dplyr` library.\n\n2.  Using the `conflicts_prefer(\"function\",\"package\")` function to explicitly declare which version of the function you want to use in the remaining R session (i.e. after `conflicts_prefer()` is called, e.g., `conflict_prefer(\"filter\",\"dplyr\")` .\n\n::: {.callout-tip icon=\"false\"}\n## {{< bi question-octagon color=#6dc83c >}} Question\n\nWhat do you think is the advantage of using the `conflicts_prefer` as opposed to the first approach?\n:::\n\n# What is tidy data?\n\n\n::: {.cell}\n\n:::\n\n\nWhat does it mean for your data to be **tidy**? Beyond just being organised, having **tidy** data means that your data follows a standardised format. This makes it easier for you and others to visualise your data, to wrangle/transform your data, and to model your data. We will follow Hadley Wickham's definition of **tidy data** here:\n\n> A data set is a collection of values, usually either numbers (if quantitative) or strings AKA text data (if qualitative). Values are organised in two ways. Every value belongs to a variable and an observation. A variable contains all values that measure the same underlying attribute (like height, temperature, duration) across units. An observation contains all values measured on the same unit (like a person, or a day, or a city) across attributes.\n\n> Tidy data is a standard way of mapping the meaning of a data set to its structure. A data set is messy or tidy depending on how rows, columns and tables are matched up with observations, variables and types. In tidy data:\n\n> 1.  Each variable forms a column.\n> 2.  Each observation forms a row.\n> 3.  Each type of observational unit forms a table.\n\n\n::: {.cell}\n::: {.cell-output-display}\n![Tidy data graphic from http://r4ds.had.co.nz/tidy-data.html](tidy-1.png){width=6.4in}\n:::\n:::\n\n\nFor example, say the following table consists of stock prices:\n\n\n::: {.cell}\n::: {.cell-output-display}\n\\begin{table}[!h]\n\n\\caption{\\label{tab:unnamed-chunk-4}Stock Prices (Non-Tidy Format)}\n\\centering\n\\fontsize{9}{11}\\selectfont\n\\begin{tabular}[t]{llll}\n\\toprule\nDate & Boeing Stock Price & Amazon Stock Price & Google Stock Price\\\\\n\\midrule\n2009-01-01 & \\$173.55 & \\$174.90 & \\$174.34\\\\\n2009-01-02 & \\$172.61 & \\$171.42 & \\$170.04\\\\\n\\bottomrule\n\\end{tabular}\n\\end{table}\n:::\n:::\n\n\nAlthough the data are neatly organised in a spreadsheet-type format, they are not in tidy format since there are three variables corresponding to three unique pieces of information (Date, Stock Name, and Stock Price), but there are not three columns. In tidy data format each variable should be its own column, as shown below. Notice that both tables present the same information, but in different formats.\n\n\n::: {.cell}\n::: {.cell-output-display}\n\\begin{table}[!h]\n\n\\caption{\\label{tab:unnamed-chunk-5}Stock Prices (Tidy Format)}\n\\centering\n\\fontsize{9}{11}\\selectfont\n\\begin{tabular}[t]{lll}\n\\toprule\nDate & Stock Name & Stock Price\\\\\n\\midrule\n2009-01-01 & Boeing & \\$173.55\\\\\n2009-01-02 & Boeing & \\$172.61\\\\\n2009-01-01 & Amazon & \\$174.90\\\\\n2009-01-02 & Amazon & \\$171.42\\\\\n2009-01-01 & Google & \\$174.34\\\\\n\\addlinespace\n2009-01-02 & Google & \\$170.04\\\\\n\\bottomrule\n\\end{tabular}\n\\end{table}\n:::\n:::\n\n\nHowever, consider the following table:\n\n\n::: {.cell}\n::: {.cell-output-display}\n\\begin{table}[!h]\n\n\\caption{\\label{tab:unnamed-chunk-6}Date, Boeing Price, Weather Data}\n\\centering\n\\fontsize{9}{11}\\selectfont\n\\begin{tabular}[t]{lll}\n\\toprule\nDate & Boeing Price & Weather\\\\\n\\midrule\n2009-01-01 & \\$173.55 & Sunny\\\\\n2009-01-02 & \\$172.61 & Overcast\\\\\n\\bottomrule\n\\end{tabular}\n\\end{table}\n:::\n:::\n\n\nIn this case, even though the variable **Boeing Price** occurs again, the data *is* tidy since there are three variables corresponding to three unique pieces of information (Date, Boeing stock price, and the weather on that particular day).\n\nThe non-tidy data format in the original table is also known as [wide](https://en.wikipedia.org/wiki/Wide_and_narrow_data) format whereas the tidy data format in the second table is also known as [long/narrow](https://en.wikipedia.org/wiki/Wide_and_narrow_data#Narrow) data format. In this course, we will work mostly with data sets that are already in the tidy format.\n\n::: {.callout-tip icon=\"false\"}\n## {{< bi question-octagon color=#6dc83c >}} Question\n\nConsider the following data frame of average number of servings of beer, spirits, and wine consumption in three countries as reported in the FiveThirtyEight article [Dear Mona Followup: Where Do People Drink The Most Beer, Wine And Spirits?](https://fivethirtyeight.com/features/dear-mona-followup-where-do-people-drink-the-most-beer-wine-and-spirits/)\n\n\n::: {.cell}\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 3 x 4\n  country     beer_servings spirit_servings wine_servings\n  <chr>               <int>           <int>         <int>\n1 Canada                240             122           100\n2 South Korea           140              16             9\n3 USA                   249             158            84\n```\n:::\n:::\n\n\nThis data frame is not in tidy format. What would it look like if it were?\n:::\n\n\n<div class='webex-solution'><button>I need a hint</button>\n\n\nThink of these data as being in a wide format. What variables in this data set could be placed in different columns?\n\n\n</div>\n\n\n<!-- note: you could also just set webex.hide to TRUE -->\n\n\n::: {.cell webex.hide='See the solution'}\n\n<div class='webex-solution'><button>See the solution</button>\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 9 x 3\n  country     `beverages type` `number of servings`\n  <chr>       <chr>                           <int>\n1 Canada      beer_servings                     240\n2 South Korea beer_servings                     140\n3 USA         beer_servings                     249\n4 Canada      spirit_servings                   122\n5 South Korea spirit_servings                    16\n6 USA         spirit_servings                   158\n7 Canada      wine_servings                     100\n8 South Korea wine_servings                       9\n9 USA         wine_servings                      84\n```\n:::\n\n\n</div>\n:::\n\n\n# Observational units\n\nRecall the `nycflights13` package with data about all domestic flights departing from New York City in 2013 that we used in Week 1 to create visualisations. In particular, let's revisit the `flights` data frame:\n\n\n::: {.cell}\n\n```{.r .cell-code}\ndim(flights)  # Returns the dimensions of a data frame (number obs. and variables)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] 336776     19\n```\n:::\n\n```{.r .cell-code}\nhead(flights) # Returns the first 6 rows of the object\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 6 x 19\n   year month   day dep_time sched_dep_time dep_delay arr_time sched_arr_time\n  <int> <int> <int>    <int>          <int>     <dbl>    <int>          <int>\n1  2013     1     1      517            515         2      830            819\n2  2013     1     1      533            529         4      850            830\n3  2013     1     1      542            540         2      923            850\n4  2013     1     1      544            545        -1     1004           1022\n5  2013     1     1      554            600        -6      812            837\n6  2013     1     1      554            558        -4      740            728\n# i 11 more variables: arr_delay <dbl>, carrier <chr>, flight <int>,\n#   tailnum <chr>, origin <chr>, dest <chr>, air_time <dbl>, distance <dbl>,\n#   hour <dbl>, minute <dbl>, time_hour <dttm>\n```\n:::\n\n```{.r .cell-code}\nglimpse(flights) # Lists the variables in an object with their first few values \n```\n\n::: {.cell-output .cell-output-stdout}\n```\nRows: 336,776\nColumns: 19\n$ year           <int> 2013, 2013, 2013, 2013, 2013, 2013, 2013, 2013, 2013, 2~\n$ month          <int> 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1~\n$ day            <int> 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1~\n$ dep_time       <int> 517, 533, 542, 544, 554, 554, 555, 557, 557, 558, 558, ~\n$ sched_dep_time <int> 515, 529, 540, 545, 600, 558, 600, 600, 600, 600, 600, ~\n$ dep_delay      <dbl> 2, 4, 2, -1, -6, -4, -5, -3, -3, -2, -2, -2, -2, -2, -1~\n$ arr_time       <int> 830, 850, 923, 1004, 812, 740, 913, 709, 838, 753, 849,~\n$ sched_arr_time <int> 819, 830, 850, 1022, 837, 728, 854, 723, 846, 745, 851,~\n$ arr_delay      <dbl> 11, 20, 33, -18, -25, 12, 19, -14, -8, 8, -2, -3, 7, -1~\n$ carrier        <chr> \"UA\", \"UA\", \"AA\", \"B6\", \"DL\", \"UA\", \"B6\", \"EV\", \"B6\", \"~\n$ flight         <int> 1545, 1714, 1141, 725, 461, 1696, 507, 5708, 79, 301, 4~\n$ tailnum        <chr> \"N14228\", \"N24211\", \"N619AA\", \"N804JB\", \"N668DN\", \"N394~\n$ origin         <chr> \"EWR\", \"LGA\", \"JFK\", \"JFK\", \"LGA\", \"EWR\", \"EWR\", \"LGA\",~\n$ dest           <chr> \"IAH\", \"IAH\", \"MIA\", \"BQN\", \"ATL\", \"ORD\", \"FLL\", \"IAD\",~\n$ air_time       <dbl> 227, 227, 160, 183, 116, 150, 158, 53, 140, 138, 149, 1~\n$ distance       <dbl> 1400, 1416, 1089, 1576, 762, 719, 1065, 229, 944, 733, ~\n$ hour           <dbl> 5, 5, 5, 5, 6, 5, 6, 6, 6, 6, 6, 6, 6, 6, 6, 5, 6, 6, 6~\n$ minute         <dbl> 15, 29, 40, 45, 0, 58, 0, 0, 0, 0, 0, 0, 0, 0, 0, 59, 0~\n$ time_hour      <dttm> 2013-01-01 05:00:00, 2013-01-01 05:00:00, 2013-01-01 0~\n```\n:::\n:::\n\n\nWe see that `flights` has a rectangular shape with each row corresponding to a different flight and each column corresponding to a characteristic of that flight. This matches exactly with the first two properties of tidy data, namely:\n\n1.  Each variable forms a column.\n2.  Each observation forms a row.\n\nBut what about the third property?\n\n3.  Each type of observational unit forms a table.\n\nThe observational unit in the `flights` data set is an individual flight and we can see above that this data set consists of 336,776 flights with 19 variables. In other words, rows of this data set don't refer to a measurement on an airline or on an airport; they refer to characteristics/measurements on a given flight from New York City in 2013. This illustrates the third property of tidy data, i.e. each observational unit is fully described by a single data set.\n\nNote that there is only one observational unit of interest in any analysis. For example, also included in the `nycflights13` package are data sets with different observational units:\n\n-   `airlines` <!-- : translation between two letter IATA carrier codes and names (16 in total) -->\n-   `planes` <!-- : construction information about each of 3,322 planes used -->\n-   `weather` <!-- : hourly meteorological data (about 8705 observations) for each of the three NYC airports -->\n-   `airports` <!-- : 1458 airport names and locations -->\n\nThe organisation of this data follows the third **tidy** data property: observations corresponding to the same observational unit are saved in the same data frame.\n\n::: {.callout-warning icon=\"false\"}\n## Task\n\nFor each of the data sets listed above (other than `flights`), identify the observational unit and how many of these are described in each of the data sets.\n\n-   In the `airlines` data set the observational unit is\n\n* (A) Type of plane  \n* (B) Flight number  \n* (C) airport code  \n* (D) IATA carrier codes and names  \n\n and there are __ observational units.\n-   In the `planes` data set the observational unit is \n\n* (A) Flight  \n* (B) Manufacturer of the plane  \n* (C) Plane  \n* (D) Average cruising speed in mph  \n\n and there are _____ observational units.\n-   In the `weather` data set the observational unit is the \n\n* (A) Weather Station  \n* (B) Temperature  \n* (C) Relative humidity  \n* (D) Sea level pressure  \n\n and there are ____ observations on **average** across the three NYC airports.\n-   In the `airports` data set the observational unit is the \n\n* (A) Time zone  \n* (B) Airport  \n* (C) Altitude  \n* (D) Daylight savings time zone  \n\n and there are ____  observational units.\n:::\n\n# Identification vs measurement variables {#identification-vs-measurement}\n\nThere is a subtle difference between the kinds of variables that you will encounter in data frames: **measurement variables** and **identification variables**. The `airports` data frame contains both these types of variables. Recall that in `airports` the observational unit is an airport, and thus each row corresponds to one particular airport. Let's pull them apart using the `glimpse` function:\n\n\n::: {.cell}\n\n```{.r .cell-code}\nglimpse(airports)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nRows: 1,458\nColumns: 8\n$ faa   <chr> \"04G\", \"06A\", \"06C\", \"06N\", \"09J\", \"0A9\", \"0G6\", \"0G7\", \"0P2\", \"~\n$ name  <chr> \"Lansdowne Airport\", \"Moton Field Municipal Airport\", \"Schaumbur~\n$ lat   <dbl> 41.13047, 32.46057, 41.98934, 41.43191, 31.07447, 36.37122, 41.4~\n$ lon   <dbl> -80.61958, -85.68003, -88.10124, -74.39156, -81.42778, -82.17342~\n$ alt   <dbl> 1044, 264, 801, 523, 11, 1593, 730, 492, 1000, 108, 409, 875, 10~\n$ tz    <dbl> -5, -6, -6, -5, -5, -5, -5, -5, -5, -8, -5, -6, -5, -5, -5, -5, ~\n$ dst   <chr> \"A\", \"A\", \"A\", \"A\", \"A\", \"A\", \"A\", \"A\", \"U\", \"A\", \"A\", \"U\", \"A\",~\n$ tzone <chr> \"America/New_York\", \"America/Chicago\", \"America/Chicago\", \"Ameri~\n```\n:::\n:::\n\n\nThe variables `faa` and `name` are what we will call **identification variables**: variables that uniquely identify each observational unit. They are mainly used to provide a unique name to each observational unit, thereby allowing us to uniquely identify them. `faa` gives the unique code provided by the Federal Aviation Administration in the USA for that airport, while the `name` variable gives the longer more natural name of the airport. The remaining variables (`lat`, `lon`, `alt`, `tz`, `dst`, `tzone`) are often called **measurement** or **characteristic** variables: variables that describe properties of each observational unit, in other words each observation in each row. For example, `lat` and `long` describe the latitude and longitude of each airport.\n\nFurthermore, sometimes a single variable might not be enough to uniquely identify each observational unit: combinations of variables might be needed (see **Task** below). While it is not an absolute rule, for organisational purposes it is considered good practice to have your identification variables in the far left-most columns of your data frame.\n\n::: {.callout-tip icon=\"false\"}\n## {{< bi question-octagon color=#6dc83c >}} Question\n\nWhat properties of the observational unit do each of `lat`, `lon`, `alt`, `tz`, `dst`, and `tzone` describe for the `airports` data frame? \n\n* (A) Carriers in each airport  \n* (B) Airport Flights  \n* (C) Airport appliances  \n* (D) Spatial location of the airport  \n\n\n:::\n\n::: {.callout-warning icon=\"false\"}\n## Task\n\nFrom the data sets listed above, find an example where combinations of variables are needed to uniquely identify each observational unit.\n\n**Hint** think about the weather data set, can you identify each observational unit based on the station id only?\n:::\n\n# Importing spreadsheets into R {#csv}\n\nUp to this point, we have been using data stored inside of an R package. In the real world, your data will usually come from a spreadsheet file either on your computer or online. Spreadsheet data is often saved in one of two formats:\n\n-   A **Comma Separated Values** `.csv` file. You can think of a CSV file as a bare-bones spreadsheet where:\n    -   Each line in the file corresponds to one row of data/one observation.\n    -   Values for each line are separated with commas. In other words, the values of different variables are separated by commas.\n    -   The first line is often, but not always, a *header* row indicating the names of the columns/variables.\n-   An **Excel** `.xlsx` file. This format is based on Microsoft's proprietary Excel software. As opposed to bare-bones `.csv` files, `.xlsx` Excel files contain a lot of *metadata*, i.e. data about the data. Examples include the use of bold and italic fonts, colored cells, different column widths, and formula macros etc.\n\nWe'll cover two methods for importing data in R: one using the R console and the other using RStudio's graphical interface.\n\n## Method 1: From the console\n\nFirst, let's download a **Comma Separated Values** (CSV) file of ratings of the level of democracy in different countries spanning 1952 to 1992: <https://moderndive.com/data/dem_score.csv>. We use the `read_csv()` function from the `readr` package to read it off the web:\n\n\n::: {.cell}\n\n```{.r .cell-code}\ndem_score <- read_csv(\"https://moderndive.com/data/dem_score.csv\")\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 96 x 10\n   country    `1952` `1957` `1962` `1967` `1972` `1977` `1982` `1987` `1992`\n   <chr>       <dbl>  <dbl>  <dbl>  <dbl>  <dbl>  <dbl>  <dbl>  <dbl>  <dbl>\n 1 Albania        -9     -9     -9     -9     -9     -9     -9     -9      5\n 2 Argentina      -9     -1     -1     -9     -9     -9     -8      8      7\n 3 Armenia        -9     -7     -7     -7     -7     -7     -7     -7      7\n 4 Australia      10     10     10     10     10     10     10     10     10\n 5 Austria        10     10     10     10     10     10     10     10     10\n 6 Azerbaijan     -9     -7     -7     -7     -7     -7     -7     -7      1\n 7 Belarus        -9     -7     -7     -7     -7     -7     -7     -7      7\n 8 Belgium        10     10     10     10     10     10     10     10     10\n 9 Bhutan        -10    -10    -10    -10    -10    -10    -10    -10    -10\n10 Bolivia        -4     -3     -3     -4     -7     -7      8      9      9\n# i 86 more rows\n```\n:::\n:::\n\n\nIn this `dem_score` data frame, the minimum value of -10 corresponds to a highly autocratic nation whereas a value of 10 corresponds to a highly democratic nation.\n\n## Method 2: Using RStudio's interface\n\nLet's read in the same data saved in Excel format this time at <https://moderndive.com/data/dem_score.xlsx>, but using RStudio's graphical interface instead of via the R console. First download the Excel file, then go to the `Files -> Import Dataset -> From Excel...` and navigate to the directory where your downloaded `dem_score.xlsx` using `Browse...`. You should see something similar to the image below:\n\n\n::: {.cell}\n::: {.cell-output-display}\n![](read_excel.png){width=5.76in}\n:::\n:::\n\n\nAfter clicking on the **Import** button on the bottom-right save this spreadsheet's data in a data frame called `dem_score` and display its contents in the spreadsheet viewer (`View()`). Furthermore you'll see the code that read in your data in the console; you can copy and paste this code to reload your data again later instead of repeating the above manual process.\n\n::: callout-caution\nNote that if you use the `xlsx` package to import `.xlsx` files is important to have the latest version of java installed in your local PC. The `xlsx` package depends on the `rJava` package which requires the Java Runtime Environment 1.2 or above. Download and install the latest version of the Java Runtime Environment from [Oracle](https://www.java.com/en/download/).\n:::\n\n::: {.callout-warning icon=\"false\"}\n## Task\n\nRead in the life expectancy data stored at <https://moderndive.com/data/le_mess.csv>, either using the R console or RStudio's interface.\n:::\n\n# Converting to **tidy** data format {#tidying}\n\nIn this section, we will see how to convert a data set that is not in the **tidy** format i.e. [wide](https://en.wikipedia.org/wiki/Wide_and_narrow_data) format, to a data set that is in the **tidy** format i.e. [long/narrow](https://en.wikipedia.org/wiki/Wide_and_narrow_data#Narrow) format. Let's use the `dem_score` data frame we loaded from a spreadsheet in the previous section but focus on only data corresponding to the country of Guatemala.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nguat_dem <- dem_score  |>\n  dplyr::filter(country == \"Guatemala\")  \n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 1 x 10\n  country   `1952` `1957` `1962` `1967` `1972` `1977` `1982` `1987` `1992`\n  <chr>      <dbl>  <dbl>  <dbl>  <dbl>  <dbl>  <dbl>  <dbl>  <dbl>  <dbl>\n1 Guatemala      2     -6     -5      3      1     -3     -7      3      3\n```\n:::\n:::\n\n\n::: callout-note\nHere we have used the `filter` funtion from `dplyr` package to subset the data set. We will revisit this code for subsetting data later in the session.\n:::\n\nNow let's produce a plot showing how the democracy scores have changed over the 40 years from 1952 to 1992 for Guatemala. Let's start by laying out how we would map our aesthetics to variables in the data frame:\n\n-   The `data` frame is `guat_dem` so we use `data = guat_dem`.\n\nWe would like to see how the democracy score has changed over the years in Guatemala. But we have a problem. We see that we have a variable named `country` but its only value is `Guatemala`. We have other variables denoted by different year values. Unfortunately, we've run into a data set that is not in the appropriate format to apply the **Grammar of Graphics** in `ggplot2`. Remember that `ggplot2` is a package in the `tidyverse` and, thus, needs data to be in a tidy format. We'd like to finish off our mapping of aesthetics to variables by doing something like\n\n-   The `aes`thetic mapping is set by `aes(x = year, y = democracy_score)`,\n\nbut this is not possible with our wide-formatted data. We need to take the values of the current column names in `guat_dem` (aside from `country`) and convert them into a new variable that will act as a key called `year`. Then, we'd like to take the numbers on the inside of the table and turn them into a column that will act as values called `democracy_score`. Our resulting data frame will have three columns: `country`, `year`, and `democracy_score`.\n\nThe `gather` function in the `tidyr` package can complete this task for us. The first argument to `gather`, just as with `ggplot2`, is the `data` argument where we specify which data frame we would like to tidy. The next two arguments to `gather` are `key` and `value`, which specify what we would like to call the new columns that convert our wide data into tidy/long format. Lastly, we include a specification for variables we would like to NOT include in the tidying process using a `-`.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nguat_tidy <- gather(data = guat_dem, \n                    key = year,\n                    value = democracy_score,\n                    - country) \n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 9 x 3\n  country   year  democracy_score\n  <chr>     <chr>           <dbl>\n1 Guatemala 1952                2\n2 Guatemala 1957               -6\n3 Guatemala 1962               -5\n4 Guatemala 1967                3\n5 Guatemala 1972                1\n6 Guatemala 1977               -3\n7 Guatemala 1982               -7\n8 Guatemala 1987                3\n9 Guatemala 1992                3\n```\n:::\n:::\n\n\nWe can now create a plot showing how democracy score in Guatemala has changed from 1952 to 1992 using a linegraph and `ggplot2`.\n\n\n::: {.cell errors='true'}\n\n```{.r .cell-code}\nggplot(data = guat_tidy, mapping = aes(x = year, y = democracy_score)) +\n  geom_line() +\n  labs(x = \"year\")\n```\n\n::: {.cell-output-display}\n![](index_files/figure-pdf/unnamed-chunk-12-1.pdf){fig-pos='H'}\n:::\n:::\n\n\nObserve that the `year` variable in `guat_tidy` is stored as a character vector since we had to circumvent the naming rules in R by adding backticks around the different year columns in `guat_dem`. This is leading to `ggplot` not knowing exactly how to plot a line using a categorical variable. We can fix this by using the `parse_number` function in the `readr` package:\n\n\n::: {.cell}\n\n```{.r .cell-code}\nggplot(data = guat_tidy, mapping = aes(x = parse_number(year), y = democracy_score)) +\n  geom_line() +\n  labs(x = \"year\", y = \"Democracy score\",\n       title = \"Guatemala's democracy score ratings from 1952 to 1992\")\n```\n\n::: {.cell-output-display}\n![](index_files/figure-pdf/guatline-1.pdf){fig-pos='H'}\n:::\n:::\n\n\nWe'll see later how we could use the `mutate` function to change `year` to be a numeric variable during the tidying process (alternatively we could have added the argument `convert=T` in the `gather()` function to declare the `key` column values as an integers; see `?gather` for more details) . Notice now that the mappings of aesthetics to variables makes sense in the figure:\n\n-   The `data` frame is `guat_tidy` by setting `data = guat_tidy`;\n-   The `x` `aes`thetic is mapped to `year`;\n-   The `y` `aes`thetic is mapped to `democracy_score`; and\n-   The `geom_`etry chosen is `line`.\n\n::: {.callout-warning icon=\"false\"}\n## Task\n\nConvert the `dem_score` data frame into a tidy data frame and assign the name of `dem_score_tidy` to the resulting long-formatted data frame.\n\n\n<div class='webex-solution'><button>Take hint</button>\n\n\nSee the documentation for `gather()` (`?gather`). Try using the `convert= T` argument and comment on the output.\n\n\n</div>\n\n\n\n::: {.cell webex.hide='Click here to see the solution'}\n\n<div class='webex-solution'><button>Click here to see the solution</button>\n\n```{.r .cell-code  code-fold=\"show\"}\ndem_score_tidy <- gather(data = dem_score, \n                    key = year,\n                    convert= T,\n                    value = democracy_score,\n                    - country) \nhead(dem_score_tidy)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 6 x 3\n  country     year democracy_score\n  <chr>      <int>           <dbl>\n1 Albania     1952              -9\n2 Argentina   1952              -9\n3 Armenia     1952              -9\n4 Australia   1952              10\n5 Austria     1952              10\n6 Azerbaijan  1952              -9\n```\n:::\n\n\n</div>\n:::\n\n:::\n\n::: {.callout-warning icon=\"false\"}\n## Task\n\nNow try converting the life expectancy data set you created in a previous task into a tidy data frame.\n:::\n\n# Introduction to data wrangling {#wrangling}\n\nWe are now able to import data and perform basic operations on the data to get it into the **tidy** format. In this and subsequent sections we will use tools from the `dplyr` package to perform data **wrangling** which includes transforming, mapping and summarising variables.\n\n## The pipe \\|\\> {#piping}\n\nBefore we dig into data wrangling, let's first introduce the pipe operator (`|>`). Just as the `+` sign was used to add layers to a plot created using `ggplot`, the pipe operator allows us to chain together data wrangling functions. The pipe operator can be read as **then**. The `|>` operator allows us to go from one step in to the next easily so we can, for example:\n\n-   `filter` our data frame to only focus on a few rows **then**\n-   `group_by` another variable to create groups **then**\n-   `summarize` this grouped data to calculate the mean for each level of the group.\n\nThe piping syntax will be our major focus throughout the rest of this course and you'll find that you'll quickly be addicted to the chaining with some practice.\n\n## Data wrangling verbs {#verbs}\n\nThe `d` in `dplyr` stands for data frames, so the functions in `dplyr` are built for working with objects of the data frame type. For now, we focus on the most commonly used functions that help wrangle and summarise data. A description of these verbs follows, with each subsequent section devoted to an example of that verb, or a combination of a few verbs, in action.\n\n1.  `filter`: Pick rows based on conditions about their values\n2.  `summarize`: Compute summary measures known as \"summary statistics\" of variables\n3.  `group_by`: Group rows of observations together\n4.  `mutate`: Create a new variable in the data frame by mutating existing ones\n5.  `arrange`: Arrange/sort the rows based on one or more variables\n6.  `join`: Join/merge two data frames by matching along a \"key\" variable. There are many different `join`s available. Here, we will focus on the `inner_join` function.\n\nAll of the verbs are used similarly where you: take a data frame, pipe it using the `%>%` syntax into one of the verbs above followed by other arguments specifying which criteria you would like the verb to work with in parentheses.\n\n# Filter observations using filter {#filter}\n\n\n::: {.cell}\n::: {.cell-output-display}\n![](filter.png){width=4.09in}\n:::\n:::\n\n\nThe `filter` function allows you to specify criteria about values of a variable in your data set and then chooses only those rows that match that criteria.\n\n::: callout-important\nRecall that the base R has already a filter function defined. So make sure to avoid any conflicts either by calling `dplyr::filter()` every time you use the function (specially if you have loaded the `conflicts` library) or alternatively run the`conflict_prefer()` function to let R know that it should use `dplyr`'s `filter` function as default.\n\n\n::: {.cell}\n::: {.cell-output .cell-output-stderr}\n```\nWarning: package 'conflicted' was built under R version 4.2.3\n```\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code  code-fold=\"show\"}\nconflict_prefer(\"filter\", \"dplyr\")\n```\n\n::: {.cell-output .cell-output-stderr}\n```\n[conflicted] Will prefer dplyr::filter over any other package.\n```\n:::\n:::\n\n:::\n\nWe begin by focusing only on flights from New York City to Portland, Oregon. The `dest` code (or airport code) for Portland, Oregon is `PDX`. Run the following code and look at the resulting spreadsheet to ensure that only flights heading to Portland are chosen:\n\n\n::: {.cell exercise='true'}\n\n```{.r .cell-code}\nportland_flights <- flights |> \n  filter(dest == \"PDX\")\n# We do not display columns 6-11 so we can see the destination (dest) variable.\nportland_flights[,-(6:12)] \n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 1,354 x 12\n    year month   day dep_time sched_dep_time origin dest  air_time distance\n   <int> <int> <int>    <int>          <int> <chr>  <chr>    <dbl>    <dbl>\n 1  2013     1     1     1739           1740 JFK    PDX        341     2454\n 2  2013     1     1     1805           1757 EWR    PDX        336     2434\n 3  2013     1     1     2052           2029 JFK    PDX        331     2454\n 4  2013     1     2      804            805 EWR    PDX        310     2434\n 5  2013     1     2     1552           1550 JFK    PDX        305     2454\n 6  2013     1     2     1727           1720 EWR    PDX        351     2434\n 7  2013     1     2     1738           1740 JFK    PDX        322     2454\n 8  2013     1     2     2024           2029 JFK    PDX        325     2454\n 9  2013     1     3     1755           1745 JFK    PDX        325     2454\n10  2013     1     3     1814           1727 EWR    PDX        320     2434\n# i 1,344 more rows\n# i 3 more variables: hour <dbl>, minute <dbl>, time_hour <dttm>\n```\n:::\n:::\n\n\nNote the following:\n\n-   The ordering of the commands:\n    -   Take the data frame `flights` **then**\n    -   `filter` the data frame so that only those where the `dest` equals `PDX` are included.\n-   The double equals sign `==` tests equality, and not a single equals sign `=`.\n\nYou can combine multiple criteria together using operators that make comparisons:\n\n-   `|` corresponds to **or**\n-   `&` corresponds to **and**\n\nWe can often skip the use of `&` and just separate our conditions with a comma. You'll see this in the example below.\n\nIn addition, you can use other mathematical checks (similar to `==`):\n\n-   `>` corresponds to **greater than**\n-   `<` corresponds to **less than**\n-   `>=` corresponds to **greater than or equal to**\n-   `<=` corresponds to **less than or equal to**\n-   `!=` corresponds to **not equal to**\n\nTo see many of these in action, let's select all flights that left JFK airport heading to Burlington, Vermont (`BTV`) or Seattle, Washington (`SEA`) in the months of October, November, or December. Run the following\n\n\n::: {.cell exercise='true'}\n\n```{.r .cell-code}\nbtv_sea_flights_fall <- flights |> \n  filter(origin == \"JFK\", (dest == \"BTV\" | dest == \"SEA\"), month >= 10)\nbtv_sea_flights_fall[,-(6:12)]\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 815 x 12\n    year month   day dep_time sched_dep_time origin dest  air_time distance\n   <int> <int> <int>    <int>          <int> <chr>  <chr>    <dbl>    <dbl>\n 1  2013    10     1      729            735 JFK    SEA        352     2422\n 2  2013    10     1      853            900 JFK    SEA        362     2422\n 3  2013    10     1      916            925 JFK    BTV         48      266\n 4  2013    10     1     1216           1221 JFK    BTV         49      266\n 5  2013    10     1     1452           1459 JFK    BTV         46      266\n 6  2013    10     1     1459           1500 JFK    SEA        348     2422\n 7  2013    10     1     1754           1800 JFK    SEA        338     2422\n 8  2013    10     1     1825           1830 JFK    SEA        366     2422\n 9  2013    10     1     1925           1930 JFK    SEA        332     2422\n10  2013    10     1     2238           2245 JFK    BTV         48      266\n# i 805 more rows\n# i 3 more variables: hour <dbl>, minute <dbl>, time_hour <dttm>\n```\n:::\n:::\n\n\n::: callout-note\nEven though colloquially speaking one might say \"all flights leaving Burlington, Vermont *and* Seattle, Washington,\" in terms of computer logical operations, we really mean \"all flights leaving Burlington, Vermont *or* Seattle, Washington.\" For a given row in the data, `dest` can be `BTV`, `SEA`, or something else, but not `BTV` **and** `SEA` at the same time.\n:::\n\nAnother example uses `!` to pick rows that *do not* match a condition. The `!` can be read as **not**. Here, we are selecting rows corresponding to flights that **did not** go to Burlington, VT or Seattle, WA.\n\n\n::: {.cell exercise='true'}\n\n```{.r .cell-code}\nnot_BTV_SEA <- flights |> \n  filter(!(dest == \"BTV\" | dest == \"SEA\"))\nnot_BTV_SEA[,-(6:12)]\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 330,264 x 12\n    year month   day dep_time sched_dep_time origin dest  air_time distance\n   <int> <int> <int>    <int>          <int> <chr>  <chr>    <dbl>    <dbl>\n 1  2013     1     1      517            515 EWR    IAH        227     1400\n 2  2013     1     1      533            529 LGA    IAH        227     1416\n 3  2013     1     1      542            540 JFK    MIA        160     1089\n 4  2013     1     1      544            545 JFK    BQN        183     1576\n 5  2013     1     1      554            600 LGA    ATL        116      762\n 6  2013     1     1      554            558 EWR    ORD        150      719\n 7  2013     1     1      555            600 EWR    FLL        158     1065\n 8  2013     1     1      557            600 LGA    IAD         53      229\n 9  2013     1     1      557            600 JFK    MCO        140      944\n10  2013     1     1      558            600 LGA    ORD        138      733\n# i 330,254 more rows\n# i 3 more variables: hour <dbl>, minute <dbl>, time_hour <dttm>\n```\n:::\n\n```{.r .cell-code}\n# We do not display columns 6-11 so we can see the \"origin\" and \"dest\" variables.\n```\n:::\n\n\nAs a final note we point out that `filter` should often be the first verb you'll apply to your data. This narrows down the data to just the observations your are interested in.\n\n::: {.callout-warning icon=\"false\"}\n## Task\n\nWhat is another way of using the **not** operator `!` to filter only the rows that are not going to Burlington, VT nor Seattle, WA in the `flights` data frame?\n\n\n<div class='webex-solution'><button>Take a hint</button>\n\n\nTry using the `%in%` operator\n\n\n</div>\n\n\n\n::: {.cell webex.hide='Click here to see the solution'}\n\n<div class='webex-solution'><button>Click here to see the solution</button>\n\n```{.r .cell-code  code-fold=\"show\"}\nflights |> \n  filter( !dest %in% c(\"BTV\",\"SEA\")) |>\n  head()\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 6 x 19\n   year month   day dep_time sched_dep_time dep_delay arr_time sched_arr_time\n  <int> <int> <int>    <int>          <int>     <dbl>    <int>          <int>\n1  2013     1     1      517            515         2      830            819\n2  2013     1     1      533            529         4      850            830\n3  2013     1     1      542            540         2      923            850\n4  2013     1     1      544            545        -1     1004           1022\n5  2013     1     1      554            600        -6      812            837\n6  2013     1     1      554            558        -4      740            728\n# i 11 more variables: arr_delay <dbl>, carrier <chr>, flight <int>,\n#   tailnum <chr>, origin <chr>, dest <chr>, air_time <dbl>, distance <dbl>,\n#   hour <dbl>, minute <dbl>, time_hour <dttm>\n```\n:::\n\n\n</div>\n:::\n\n:::\n\n# Summarise variables using summarize {#summarize}\n\nThe next common task is to be able to summarise data: take a large number of values and summarise them with a single value. While this may seem like a very abstract idea, something as simple as the sum, the smallest value, and the largest values are all summaries of a large number of values.\n\n\n::: {.cell}\n::: {.cell-output-display}\n![](summary.png){width=2.29in}\n:::\n:::\n\n\nWe can calculate the standard deviation and mean of the temperature variable `temp` in the `weather` data frame of `nycflights13` in one step using the `summarize` (or equivalently using the UK spelling `summarise`) function in `dplyr`\n\n\n::: {.cell}\n\n```{.r .cell-code}\nsummary_temp <- weather |> \n  summarize(mean = mean(temp), std_dev = sd(temp))\n```\n:::\n\n::: {.cell}\n::: {.cell-output-display}\n\\begin{table}[!h]\n\\centering\\begingroup\\fontsize{9}{11}\\selectfont\n\n\\begin{tabular}{rr}\n\\toprule\nmean & std\\_dev\\\\\n\\midrule\nNA & NA\\\\\n\\bottomrule\n\\end{tabular}\n\\endgroup{}\n\\end{table}\n:::\n:::\n\n\nWe have created a small data frame here called `summary_temp` that includes both the mean (`mean`) and standard deviation (`std_dev`) of the `temp` variable in `weather`. Notice, the data frame `weather` went from many rows to a single row of just the summary values in the data frame `summary_temp`.\n\nBut why are the values returned `NA`? This stands for **not available or not applicable** and is how R encodes **missing values**; if in a data frame for a particular row and column no value exists, `NA` is stored instead. Furthermore, by default any time you try to summarise a number of values (using `mean()` and `sd()` for example) that has one or more missing values, then `NA` is returned.\n\nValues can be missing for many reasons. Perhaps the data was collected but someone forgot to enter it? Perhaps the data was not collected at all because it was too difficult? Perhaps there was an erroneous value that someone entered that was changed to read as missing? You'll often encounter issues with missing values.\n\nYou can summarise all non-missing values by setting the `na.rm` argument to TRUE (`rm` is short for remove). This will remove any `NA` missing values and only return the summary value for all non-missing values. So the code below computes the mean and standard deviation of all non-missing values. Notice how the `na.rm=TRUE` are set as arguments to the `mean` and `sd` functions, and not to the `summarize` function.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nsummary_temp <- weather |> \n  summarize(mean = mean(temp, na.rm = TRUE), std_dev = sd(temp, na.rm = TRUE))\n```\n:::\n\n::: {.cell}\n::: {.cell-output-display}\n\\begin{table}[!h]\n\\centering\\begingroup\\fontsize{9}{11}\\selectfont\n\n\\begin{tabular}{rr}\n\\toprule\nmean & std\\_dev\\\\\n\\midrule\n55.26039 & 17.78785\\\\\n\\bottomrule\n\\end{tabular}\n\\endgroup{}\n\\end{table}\n:::\n:::\n\n\nAnother very useful function that allows you to summarise multiple columns is the `summarise_at()` function. Here, we can supply a vector of variables we want to summarise and a list of functions that we want to apply to each of the variables. See the following example where we compute the minimum and maximum values of temperature and relative humidity (notice that we also specified the argument `na.rm=T` to remove missing values - this arguments gets passed on to all the functions in the list):\n\n\n::: {.cell}\n\n```{.r .cell-code}\nweather |>\n  summarise_at(.vars = c(\"temp\",\"humid\"),\n               .funs = list(min = min, max = max),\n               na.rm = TRUE)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 1 x 4\n  temp_min humid_min temp_max humid_max\n     <dbl>     <dbl>    <dbl>     <dbl>\n1     10.9      12.7     100.       100\n```\n:::\n:::\n\n\nIt is **not** good practice to include `na.rm = TRUE` in your summary commands by default; you should attempt to run code first without this argument as this will alert you to the presence of missing data. Only after you have identified where missing values occur and have thought about the potential issues of these should you consider using `na.rm = TRUE`. In the upcoming Tasks we will consider the possible ramifications of blindly sweeping rows with missing values under the rug.\n\nWhat other summary functions can we use inside the `summarize` verb? Any function in R that takes a vector of values and returns just one. Here are just a few:\n\n-   `mean`: the mean (or average)\n-   `sd`: the standard deviation, which is a measure of spread\n-   `min` and `max`: the minimum and maximum values, respectively\n-   `IQR`: the interquartile range\n-   `sum`: the sum\n-   `n`: a count of the number of rows/observations in each group. This particular summary function will make more sense when `group_by` is used in the next section.\n\n::: {.callout-tip icon=\"false\"}\n## {{< bi question-octagon color=#6dc83c >}} Question\n\nSay a doctor is studying the effect of smoking on lung cancer for a large number of patients who have records measured at five year intervals. She notices that a large number of patients have missing data points because the patient has died, so she chooses to ignore these patients in her analysis. What is wrong with this doctor's approach?\n\n\n::: {.cell}\n\n:::\n\n\n\n\n* (A) Introduces a selection bias since patient who died due to lung cancer are excluded from the analysis, leading to an underestimation of the true impact of smoking on lung cancer risk  \n* (B) There is no problem, smaller datasets with fewer missing values may require less computational resources, leading to faster processing times.  \n* (C) Removing patients with missing data reduces the sample size. Hence, conclusions may not be as easily generalizable to the broader population, as the excluded patients may represent a different subset with unique characteristics.  \n* (D) Removing missing values can result in a dataset with fewer errors and inconsistencies, which can lead to more accurate analyses.  \n\n\n:::\n\n::: {.callout-tip icon=\"false\"}\n## {{< bi question-octagon color=#6dc83c >}} Question\n\nModify `summary_temp` from above to also use the `n` summary function: `summarize(count = n())`. What does the returned value correspond to?\n\n\n\n* (A) Number of weather stations  \n* (B) Number of columns in the data  \n* (C) Sample size  \n\n\n:::\n\n::: {.callout-tip icon=\"false\"}\n## {{< bi question-octagon color=#6dc83c >}} Question\n\nWhy does the code below not work?\n\n\n::: {.cell}\n\n```{.r .cell-code  code-fold=\"show\"}\nsummary_temp <- weather |>   \n  summarize(mean = mean(temp, na.rm = TRUE)) |> \n  summarize(std_dev = sd(temp, na.rm = TRUE))\n```\n\n::: {.cell-output .cell-output-error}\n```\nError in `summarize()`:\ni In argument: `std_dev = sd(temp, na.rm = TRUE)`.\nCaused by error in `is.data.frame()`:\n! object 'temp' not found\n```\n:::\n:::\n\n\n\n<div class='webex-solution'><button>Take hint</button>\n\n\nRun the code line by line instead of all at once, and then look at the data. In other words, run `summary_temp <- weather |> summarize(mean = mean(temp, na.rm = TRUE))` first.\n\n\n</div>\n\n\n\n<div class='webex-solution'><button>Answer</button>\n\n\nThe first line of code computes the temperature mean for the weather data set. Then, the output gets passed on to `weather |> summarize(std_dev= sd(temp, na.rm = TRUE))`. However, the temperature value is no longer present in the first result, hence the error: `! object 'temp' not found`\n\n\n</div>\n\n:::\n\n# Group rows using grouping structures {#groupby}\n\n\n::: {.cell}\n::: {.cell-output-display}\n![](group_summary.png){width=3.15in}\n:::\n:::\n\n\nIt is often more useful to summarise a variable based on the groupings of another variable. Let's say we are interested in the mean and standard deviation of temperatures but *grouped by month*. To be more specific: we want the mean and standard deviation of temperatures\n\n1.  split by month.\n2.  sliced by month.\n3.  aggregated by month.\n4.  collapsed over month.\n\nRun the following code:\n\n\n::: {.cell}\n\n```{.r .cell-code}\nsummary_monthly_temp <- weather |> \n  summarize(mean = mean(temp, na.rm = TRUE), \n            std_dev = sd(temp, na.rm = TRUE),\n            .by = month)\n```\n:::\n\n\nThis code is identical to the previous code that created `summary_temp`, with an extra `.by = month` added. This kind per-operation grouping allow us to do the grouping within the operation where the summarisation takes place without changing the structure of the data .\n\n::: {#note_grouping .callout-note}\nPrevious versions of `dplyr` relied on the specification of a `group_by` function within the pipeline to do the grouping. For example, in the next line of code the `weather` data set is initially grouped by `month`and then passed as a new grouped data frame into `summarize`. Yielding to the same data frame that shows the mean and standard deviation of temperature for each month in New York City:\n\n\n::: {.cell}\n\n```{.r .cell-code  code-fold=\"true\"}\nsummary_monthly_temp <- weather |> \n  group_by(month) |> \n  summarize(mean = mean(temp, na.rm = TRUE), \n            std_dev = sd(temp, na.rm = TRUE))\n```\n:::\n\n\nWhile`group_by` doesn't change the data frame, it sets *meta-data* (data about the data), specifically the group structure of the data. If we wanted to remove this group structure meta-data, we could add the `.groups = \"drop\"` option.\n\n\n::: {.cell}\n\n```{.r .cell-code  code-fold=\"show\"}\nsummary_monthly_temp <- weather |> \n  group_by(month) |> \n  summarize(mean = mean(temp, na.rm = TRUE), \n            std_dev = sd(temp, na.rm = TRUE),\n            .groups = \"drop\")\n```\n:::\n\n\nThe advantage of using the `.by` argument is that the grouping occurs within the `summarise` function and thus the resulting data frame is no longer grouped.\n:::\n\n::: {.callout-tip icon=\"false\"}\n## {{< bi question-octagon color=#6dc83c >}} Question\n\nThe `drop_na()` function can be used in the pipeline to remove missing observations from a data set. Try running the following code to compute the mean and standard deviation of the temperature in the `weather` data set and comment on the output. Why is this different from one one we had before?\n\n\n::: {.cell}\n\n```{.r .cell-code}\nsummary_monthly_temp <- weather |> \n  drop_na() |>\n  summarize(mean = mean(temp), \n            std_dev = sd(temp),\n            .by = month)\n```\n:::\n\n\n\n<div class='webex-solution'><button>Answer</button>\n\n\nThe `drop_na()` function remove all missing observation from the data set while specifying `na.rm =T` in each summarizing function only removes the missing values for the specific variable to which the function is applied.\n\n\n</div>\n\n:::\n\nWe now revisit the `n` counting summary function we introduced in the previous section. For example, suppose we would like to get a sense for how many flights departed each of the three airports in New York City:\n\n\n::: {.cell}\n\n```{.r .cell-code}\nby_origin <- flights |>\n  summarize(count = n(),\n            .by =origin)\n```\n:::\n\n::: {.cell}\n::: {.cell-output-display}\n\\begin{table}[!h]\n\\centering\\begingroup\\fontsize{9}{11}\\selectfont\n\n\\begin{tabular}{lr}\n\\toprule\norigin & count\\\\\n\\midrule\nEWR & 120835\\\\\nJFK & 111279\\\\\nLGA & 104662\\\\\n\\bottomrule\n\\end{tabular}\n\\endgroup{}\n\\end{table}\n:::\n:::\n\n\nWe see that Newark (`EWR`) had the most flights departing in 2013 followed by `JFK` and lastly by LaGuardia (`LGA`). Note, there is a subtle but important difference between `sum` and `n`. While `sum` simply adds up a large set of numbers, the latter counts the number of times each of many different values occur.\n\n## Grouping by more than one variable\n\nYou are not limited to grouping by one variable. Say you wanted to know the number of flights leaving each of the three New York City airports *for each month*, we can also group by a second variable `month`:\n\n\n::: {.cell}\n\n```{.r .cell-code  code-fold=\"show\"}\nby_origin_monthly <- flights |> \n  summarize(count = n(), \n            .by = c(origin, month))\nby_origin_monthly\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 36 x 3\n   origin month count\n   <chr>  <int> <int>\n 1 EWR        1  9893\n 2 LGA        1  7950\n 3 JFK        1  9161\n 4 EWR       10 10104\n 5 JFK       10  9143\n 6 LGA       10  9642\n 7 JFK       11  8710\n 8 EWR       11  9707\n 9 LGA       11  8851\n10 JFK       12  9146\n# i 26 more rows\n```\n:::\n:::\n\n\nWe see there are 36 rows for `by_origin_monthly` because there are 12 months times 3 airports (`EWR`, `JFK`, and `LGA`). Let's now pose a question.\n\n1.  First, what if we reverse the order of the grouping, i.e. `.by = c(month, origin)`?\n\n\n::: {.cell}\n\n```{.r .cell-code}\nby_monthly_origin <- flights |> \n  summarize(count = n(), \n            .by = c(month,origin))\nby_monthly_origin\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 36 x 3\n   month origin count\n   <int> <chr>  <int>\n 1     1 EWR     9893\n 2     1 LGA     7950\n 3     1 JFK     9161\n 4    10 EWR    10104\n 5    10 JFK     9143\n 6    10 LGA     9642\n 7    11 JFK     8710\n 8    11 EWR     9707\n 9    11 LGA     8851\n10    12 JFK     9146\n# i 26 more rows\n```\n:::\n:::\n\n\nIn `by_monthly_origin` the `month` column is now first and the rows are sorted by `month` instead of origin. If you compare the values of `count` in `by_origin_monthly` and `by_monthly_origin` using the `View` function, you'll see that the values are actually the same, just presented in a different order.\n\n::: {.callout-tip icon=\"false\"}\n## {{< bi question-octagon color=#6dc83c >}} Question\n\nRecall from Week 1 when we looked at plots of temperatures by months in NYC. What does the standard deviation column in the `summary_monthly_temp` data frame tell us about temperatures in New York City throughout the year?\n\n\n::: {.cell}\n\n:::\n\n\n\n\n* (A) Temperature are lower in the winter   \n* (B) Temperature variability increases during winter  \n* (C) Spring is the season with more outliers   \n\n\n:::\n\n::: {.callout-warning icon=\"false\"}\n## Task\n\nWrite code to produce the mean and standard deviation temperature for each day in 2013 for NYC\n\n\n<div class='webex-solution'><button>Take a hint</button>\n\n\nSee the documentation for `plot()` (`?plot`)\n\n\n</div>\n\n\n\n::: {.cell webex.hide='Click here to see the solution'}\n\n<div class='webex-solution'><button>Click here to see the solution</button>\n\n```{.r .cell-code  code-fold=\"show\"}\n weather |> \n  summarize(mean = mean(temp, na.rm = TRUE), \n            std_dev = sd(temp, na.rm = TRUE),\n            .by = day)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 31 x 3\n     day  mean std_dev\n   <int> <dbl>   <dbl>\n 1     1  57.6    17.4\n 2     2  55.7    20.2\n 3     3  53.8    18.9\n 4     4  54.0    18.8\n 5     5  55.6    16.2\n 6     6  55.7    15.6\n 7     7  55.6    17.4\n 8     8  55.0    17.6\n 9     9  56.6    17.4\n10    10  56.9    17.8\n# i 21 more rows\n```\n:::\n\n\n</div>\n:::\n\n:::\n\n::: {.callout-warning icon=\"false\"}\n## Task\n\nHow could we identify how many flights left each of the three airports for each `carrier`? Can you create a bar plot showing these results?\n\n\n<div class='webex-solution'><button>Take a hint</button>\n\n\nYou can count how many flights left each of the three airports by summarising the data using the `n()` function while grouping by the origin and carrier. Then, you can pass the resulting data frame to `ggplot` using the pipeline command `|>` and use a `geom_col` layer as we saw in the previous week.\n\n\n</div>\n\n\n\n::: {.cell webex.hide='Click here to see the solution'}\n\n<div class='webex-solution'><button>Click here to see the solution</button>\n\n```{.r .cell-code  code-fold=\"show\"}\nflights |> \n  summarise(count = n(), \n            .by = c(origin,carrier)) |>\n  ggplot(aes(x = carrier, y = count, fill = origin)) + geom_col()\n```\n\n::: {.cell-output-display}\n![](index_files/figure-pdf/unnamed-chunk-34-1.pdf){fig-pos='H'}\n:::\n\n\n</div>\n:::\n\n:::\n\n# Create new variables/change old variables using mutate {#mutate}\n\n\n::: {.cell}\n::: {.cell-output-display}\n![](mutate.png){width=4.08in}\n:::\n:::\n\n\nWhen looking at the `flights` data set, there are some clear additional variables that could be calculated based on the values of variables already in the data set. Passengers are often frustrated when their flights depart late, but change their mood a bit if pilots can make up some time during the flight to get them to their destination close to when they expected to land. This is commonly referred to as \"gain\" and we will create this variable using the `mutate` function. Note that we will be overwriting the `flights` data frame with one including the additional variable `gain` here, or put differently, the `mutate` command outputs a new data frame which then gets saved over the original `flights` data frame.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nflights <- flights |> \n  mutate(gain = dep_delay - arr_delay)\n```\n:::\n\n\nLet's take a look at `dep_delay`, `arr_delay`, and the resulting `gain` variables in our new `flights` data frame:\n\n\n::: {.cell}\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 336,776 x 3\n   dep_delay arr_delay  gain\n       <dbl>     <dbl> <dbl>\n 1         2        11    -9\n 2         4        20   -16\n 3         2        33   -31\n 4        -1       -18    17\n 5        -6       -25    19\n 6        -4        12   -16\n 7        -5        19   -24\n 8        -3       -14    11\n 9        -3        -8     5\n10        -2         8   -10\n# i 336,766 more rows\n```\n:::\n:::\n\n\nThe flight in the first row departed 2 minutes late but arrived 11 minutes late, so its \"gained time in the air\" is actually a loss of 9 minutes, hence its `gain` is `-9`. Contrast this to the flight in the fourth row which departed a minute early (`dep_delay` of `-1`) but arrived 18 minutes early (`arr_delay` of `-18`), so its \"gained time in the air\" is 17 minutes, hence its `gain` is `+17`.\n\nWhy did we overwrite `flights` instead of assigning the resulting data frame to a new object, like `flights_with_gain`? As a rough rule of thumb, as long as you are not losing information that you might need later, it's acceptable practice to overwrite data frames. However, if you overwrite existing variables and/or change the observational units, recovering the original information might prove difficult. In this case, it might make sense to create a new data object.\n\nLet's look at summary measures of this `gain` variable and plot it in the form of a histogram:\n\n\n::: {.cell}\n\n```{.r .cell-code}\ngain_summary <- flights |> \n  summarize(\n    min = min(gain, na.rm = TRUE),\n    q1 = quantile(gain, 0.25, na.rm = TRUE),\n    median = quantile(gain, 0.5, na.rm = TRUE),\n    q3 = quantile(gain, 0.75, na.rm = TRUE),\n    max = max(gain, na.rm = TRUE),\n    mean = mean(gain, na.rm = TRUE),\n    sd = sd(gain, na.rm = TRUE),\n    missing = sum(is.na(gain))\n```\n:::\n\n::: {.cell}\n::: {.cell-output-display}\n\\begin{table}[!h]\n\\centering\\begingroup\\fontsize{9}{11}\\selectfont\n\n\\begin{tabular}{rrrrrrrr}\n\\toprule\nmin & q1 & median & q3 & max & mean & sd & missing\\\\\n\\midrule\n-196 & -3 & 7 & 17 & 109 & 5.659779 & 18.04365 & 9430\\\\\n\\bottomrule\n\\end{tabular}\n\\endgroup{}\n\\end{table}\n:::\n:::\n\n\nWe have recreated the `summary` function we saw in Week 1 here using the `summarize` function in `dplyr`. Lets make a histogram for the new created `gain` variable.\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nggplot(data = flights, mapping = aes(x = gain)) +\n  geom_histogram(color = \"white\", bins = 20)\n```\n\n::: {.cell-output-display}\n![Histogram of gain variable.](index_files/figure-pdf/unnamed-chunk-39-1.pdf){fig-align='center' fig-pos='H'}\n:::\n:::\n\n\nWe can also create multiple columns at once and even refer to columns that were just created in a new column.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nflights <- flights |>\n  mutate(\n    gain = dep_delay - arr_delay,\n    hours = air_time / 60,\n    gain_per_hour = gain / hours\n  )\n```\n:::\n\n\n::: {.callout-tip icon=\"false\"}\n## {{< bi question-octagon color=#6dc83c >}} Question\n\nWhat do positive values of the `gain` variable in `flights` correspond to?\n\n\n\n* (A) Departure delays are greater than arrivals delays  \n* (B) Departure delays are lower than arrivals delays  \n* (C) Departures and arrivals delays are the same  \n\n\n\nWhat about negative values?\n\n\n\n* (A) Departure delays are greater than arrivals delays  \n* (B) Departure delays are lower than arrivals delays  \n* (C) Departures and arrivals delays are the same  \n\n\n\nAnd what about a zero value?\n\n\n\n* (A) Departure delays are greater than arrivals delays  \n* (B) Departuredelays are lower than arrivals delays  \n* (C) Departures and arrivals delays are the same  \n\n\n:::\n\n::: {.callout-tip icon=\"false\"}\n## {{< bi question-octagon color=#6dc83c >}} Question\n\nCould we create the `dep_delay` and `arr_delay` columns by simply subtracting `dep_time` from `sched_dep_time` and similarly for arrivals? Try the code out and explain any differences between the result and what actually appears in `flights`.\n\n\n::: {.cell}\n\n```{.r .cell-code  code-fold=\"show\"}\nflights |>\n  mutate(dep_delay  = sched_dep_time - dep_time ,\n         arr_delay  = sched_arr_time  - arr_time)  \n```\n:::\n\n\n\n<div class='webex-solution'><button>Take a hint</button>\n\n\nSee the description of the variables `arr_time`, `dep_time`, `sched_dep_time` and `sched_arr_time` in the flights data set `?flights`\n\n\n</div>\n\n\n\n<div class='webex-solution'><button>Answer</button>\n\n\nThe differences are due to departure and arrival times have a HHMM or HMM format. E.g., if we compute the difference between a flight scheduled to arrive by 923 and its actual arrival time at 850, the result would be a difference of 73, while in reality there was only a 33 min difference if we consider the correct time format!\n\n\n</div>\n\n:::\n\n# Reorder the data frame using arrange {#arrange}\n\nOne of the most common things people working with data would like to do is sort the data frames by a specific variable in a column. Have you ever been asked to calculate a median by hand? This requires you to put the data in order from smallest to highest in value. The `dplyr` package has a function called `arrange` that we will use to sort/reorder our data according to the values of the specified variable. This is often used after we have grouped and summarized the data as we will see.\n\nLet's suppose we were interested in determining the most frequent destination airports from New York City in 2013:\n\n\n::: {.cell}\n\n```{.r .cell-code}\nfreq_dest <- flights |> \n  summarize(num_flights = n(),\n            .by = dest)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 105 x 2\n   dest  num_flights\n   <chr>       <int>\n 1 IAH          7198\n 2 MIA         11728\n 3 BQN           896\n 4 ATL         17215\n 5 ORD         17283\n 6 FLL         12055\n 7 IAD          5700\n 8 MCO         14082\n 9 PBI          6554\n10 TPA          7466\n# i 95 more rows\n```\n:::\n:::\n\n\nYou'll see that by default the values of `dest` are displayed in alphabetical order here. We are interested in finding those airports that appear most:\n\n\n::: {.cell}\n\n```{.r .cell-code}\nfreq_dest |>\n  arrange(num_flights)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 105 x 2\n   dest  num_flights\n   <chr>       <int>\n 1 LEX             1\n 2 LGA             1\n 3 ANC             8\n 4 SBN            10\n 5 HDN            15\n 6 MTJ            15\n 7 EYW            17\n 8 PSP            19\n 9 JAC            25\n10 BZN            36\n# i 95 more rows\n```\n:::\n:::\n\n\nThis is actually giving us the opposite of what we are looking for. It tells us the least frequent destination airports first. To switch the ordering to be descending instead of ascending we use the `desc` (`desc`ending) function:\n\n\n::: {.cell}\n\n```{.r .cell-code}\nfreq_dest |> \n  arrange(desc(num_flights))\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 105 x 2\n   dest  num_flights\n   <chr>       <int>\n 1 ORD         17283\n 2 ATL         17215\n 3 LAX         16174\n 4 BOS         15508\n 5 MCO         14082\n 6 CLT         14064\n 7 SFO         13331\n 8 FLL         12055\n 9 MIA         11728\n10 DCA          9705\n# i 95 more rows\n```\n:::\n:::\n\n\n# Joining data frames {#joins}\n\nAnother common task is joining (merging) two different data sets. For example, in the `flights` data, the variable `carrier` lists the carrier code for the different flights. While `UA` and `AA` might be somewhat easy to guess for some (United and American Airlines), what are VX, HA, and B6? This information is provided in a separate data frame `airlines`.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nairlines\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 16 x 2\n   carrier name                       \n   <chr>   <chr>                      \n 1 9E      Endeavor Air Inc.          \n 2 AA      American Airlines Inc.     \n 3 AS      Alaska Airlines Inc.       \n 4 B6      JetBlue Airways            \n 5 DL      Delta Air Lines Inc.       \n 6 EV      ExpressJet Airlines Inc.   \n 7 F9      Frontier Airlines Inc.     \n 8 FL      AirTran Airways Corporation\n 9 HA      Hawaiian Airlines Inc.     \n10 MQ      Envoy Air                  \n11 OO      SkyWest Airlines Inc.      \n12 UA      United Air Lines Inc.      \n13 US      US Airways Inc.            \n14 VX      Virgin America             \n15 WN      Southwest Airlines Co.     \n16 YV      Mesa Airlines Inc.         \n```\n:::\n:::\n\n\nWe see that in `airports`, `carrier` is the carrier code while `name` is the full name of the airline. Using this table, we can see that VX, HA, and B6 correspond to Virgin America, Hawaiian Airlines Inc., and JetBlue Airways, respectively. However, will we have to continually look up the carrier's name for each flight in the `airlines` data set? No! Instead of having to do this manually, we can have R automatically do the \"looking up\" for us.\n\nNote that the values in the variable `carrier` in `flights` match the values in the variable `carrier` in `airlines`. In this case, we can use the variable `carrier` as a *key variable* to join/merge/match the two data frames by. Key variables are almost always identification variables that uniquely identify the observational units as we saw back in the **Identification vs Measurement Variable** section. This ensures that rows in both data frames are appropriately matched during the join. This diagram helps us understand how the different data sets are linked by various key variables:\n\n\n::: {.cell}\n::: {.cell-output-display}\n![Data relationships in nycflights13 from R for Data Science, Hadley and Garrett (2016).](relational-nycflights.png){width=2.64in}\n:::\n:::\n\n\n## Joining by \"key\" variables\n\nIn both `flights` and `airlines`, the key variable we want to join/merge/match the two data frames with has the same name in both data sets: `carriers`. We make use of the `inner_join` function to join by the variable `carrier`.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nflights_joined <- flights |> \n  inner_join(airlines, \n             by = join_by(carrier))\n             \nflights\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 336,776 x 22\n    year month   day dep_time sched_dep_time dep_delay arr_time sched_arr_time\n   <int> <int> <int>    <int>          <int>     <dbl>    <int>          <int>\n 1  2013     1     1      517            515         2      830            819\n 2  2013     1     1      533            529         4      850            830\n 3  2013     1     1      542            540         2      923            850\n 4  2013     1     1      544            545        -1     1004           1022\n 5  2013     1     1      554            600        -6      812            837\n 6  2013     1     1      554            558        -4      740            728\n 7  2013     1     1      555            600        -5      913            854\n 8  2013     1     1      557            600        -3      709            723\n 9  2013     1     1      557            600        -3      838            846\n10  2013     1     1      558            600        -2      753            745\n# i 336,766 more rows\n# i 14 more variables: arr_delay <dbl>, carrier <chr>, flight <int>,\n#   tailnum <chr>, origin <chr>, dest <chr>, air_time <dbl>, distance <dbl>,\n#   hour <dbl>, minute <dbl>, time_hour <dttm>, gain <dbl>, hours <dbl>,\n#   gain_per_hour <dbl>\n```\n:::\n\n```{.r .cell-code}\nflights_joined\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 336,776 x 23\n    year month   day dep_time sched_dep_time dep_delay arr_time sched_arr_time\n   <int> <int> <int>    <int>          <int>     <dbl>    <int>          <int>\n 1  2013     1     1      517            515         2      830            819\n 2  2013     1     1      533            529         4      850            830\n 3  2013     1     1      542            540         2      923            850\n 4  2013     1     1      544            545        -1     1004           1022\n 5  2013     1     1      554            600        -6      812            837\n 6  2013     1     1      554            558        -4      740            728\n 7  2013     1     1      555            600        -5      913            854\n 8  2013     1     1      557            600        -3      709            723\n 9  2013     1     1      557            600        -3      838            846\n10  2013     1     1      558            600        -2      753            745\n# i 336,766 more rows\n# i 15 more variables: arr_delay <dbl>, carrier <chr>, flight <int>,\n#   tailnum <chr>, origin <chr>, dest <chr>, air_time <dbl>, distance <dbl>,\n#   hour <dbl>, minute <dbl>, time_hour <dttm>, gain <dbl>, hours <dbl>,\n#   gain_per_hour <dbl>, name <chr>\n```\n:::\n:::\n\n\nWe observe that the `flights` and `flights_joined` are identical except that `flights_joined` has an additional variable `name` whose values were drawn from `airlines`.\n\nA visual representation of the `inner_join` is given below:\n\n\n::: {.cell}\n::: {.cell-output-display}\n![Diagram of inner join from R for Data Science.](join-inner.png){width=2.25in}\n:::\n:::\n\n\nThere are more complex joins available, but the `inner_join` will solve nearly all of the problems you will face here.\n\n## Joining by \"key\" variables with different names\n\nSay instead, you are interested in all the destinations of flights from NYC in 2013 and ask yourself:\n\n-   \"What cities are these airports in?\"\n-   \"Is `ORD` Orlando?\"\n-   \"Where is `FLL`?\"\n\nThe `airports` data frame contains airport codes:\n\n\n::: {.cell}\n\n```{.r .cell-code}\nairports\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 1,458 x 8\n   faa   name                             lat    lon   alt    tz dst   tzone    \n   <chr> <chr>                          <dbl>  <dbl> <dbl> <dbl> <chr> <chr>    \n 1 04G   Lansdowne Airport               41.1  -80.6  1044    -5 A     America/~\n 2 06A   Moton Field Municipal Airport   32.5  -85.7   264    -6 A     America/~\n 3 06C   Schaumburg Regional             42.0  -88.1   801    -6 A     America/~\n 4 06N   Randall Airport                 41.4  -74.4   523    -5 A     America/~\n 5 09J   Jekyll Island Airport           31.1  -81.4    11    -5 A     America/~\n 6 0A9   Elizabethton Municipal Airport  36.4  -82.2  1593    -5 A     America/~\n 7 0G6   Williams County Airport         41.5  -84.5   730    -5 A     America/~\n 8 0G7   Finger Lakes Regional Airport   42.9  -76.8   492    -5 A     America/~\n 9 0P2   Shoestring Aviation Airfield    39.8  -76.6  1000    -5 U     America/~\n10 0S9   Jefferson County Intl           48.1 -123.    108    -8 A     America/~\n# i 1,448 more rows\n```\n:::\n:::\n\n\nHowever, looking at both the `airports` and `flights` and the visual representation of the relations between the data frames in the figure above, we see that in:\n\n-   `airports` the airport code is in the variable `faa`\n-   `flights` the airport code is in the variable `origin`\n\nSo to join these two data sets, our `inner_join` operation involves a logical operator `==` argument that accounts for the different names.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nflights |> \n  inner_join(airports,\n             by = join_by(dest == faa))\n```\n:::\n\n\nWe can read the code out loud as:\n\n\n```{=tex}\n\\begin{center}\n\"*Take the flights data frame and inner join it to the airports data frame by the entries where the variable* `dest` *is equal to* `faa`\"\n\\end{center}\n```\n\nLet's construct the sequence of commands that computes the number of flights from NYC to each destination, but also includes information about each destination airport:\n\n\n::: {.cell}\n\n```{.r .cell-code}\nnamed_dests <- flights|>\n  summarize(num_flights = n(),\n            .by = dest) |>\n  arrange(desc(num_flights)) |>\n  inner_join(airports, by = join_by(dest == faa)) %>%\n  rename(airport_name = name)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 101 x 9\n   dest  num_flights airport_name             lat    lon   alt    tz dst   tzone\n   <chr>       <int> <chr>                  <dbl>  <dbl> <dbl> <dbl> <chr> <chr>\n 1 ORD         17283 Chicago Ohare Intl      42.0  -87.9   668    -6 A     Amer~\n 2 ATL         17215 Hartsfield Jackson At~  33.6  -84.4  1026    -5 A     Amer~\n 3 LAX         16174 Los Angeles Intl        33.9 -118.    126    -8 A     Amer~\n 4 BOS         15508 General Edward Lawren~  42.4  -71.0    19    -5 A     Amer~\n 5 MCO         14082 Orlando Intl            28.4  -81.3    96    -5 A     Amer~\n 6 CLT         14064 Charlotte Douglas Intl  35.2  -80.9   748    -5 A     Amer~\n 7 SFO         13331 San Francisco Intl      37.6 -122.     13    -8 A     Amer~\n 8 FLL         12055 Fort Lauderdale Holly~  26.1  -80.2     9    -5 A     Amer~\n 9 MIA         11728 Miami Intl              25.8  -80.3     8    -5 A     Amer~\n10 DCA          9705 Ronald Reagan Washing~  38.9  -77.0    15    -5 A     Amer~\n# i 91 more rows\n```\n:::\n:::\n\n\nIn case you didn't know, `ORD` is the airport code of Chicago O'Hare airport and `FLL` is the main airport in Fort Lauderdale, Florida, which we can now see in our `named_dests` data frame.\n\n## Joining by multiple \"key\" variables\n\nSay instead we are in a situation where we need to join by multiple variables. For example, in the first figure in this section we see that in order to join the `flights` and `weather` data frames, we need more than one key variable: `year`, `month`, `day`, `hour`, and `origin`. This is because the combination of these 5 variables act to uniquely identify each observational unit in the `weather` data frame: hourly weather recordings at each of the 3 NYC airports.\n\nWe achieve this by specifying a vector of key variables to join by.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nflights_weather_joined <- flights |>\n  inner_join(weather, \n             by = join_by(year,month,day,hour,origin))\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 335,220 x 32\n    year month   day dep_time sched_dep_time dep_delay arr_time sched_arr_time\n   <int> <int> <int>    <int>          <int>     <dbl>    <int>          <int>\n 1  2013     1     1      517            515         2      830            819\n 2  2013     1     1      533            529         4      850            830\n 3  2013     1     1      542            540         2      923            850\n 4  2013     1     1      544            545        -1     1004           1022\n 5  2013     1     1      554            600        -6      812            837\n 6  2013     1     1      554            558        -4      740            728\n 7  2013     1     1      555            600        -5      913            854\n 8  2013     1     1      557            600        -3      709            723\n 9  2013     1     1      557            600        -3      838            846\n10  2013     1     1      558            600        -2      753            745\n# i 335,210 more rows\n# i 24 more variables: arr_delay <dbl>, carrier <chr>, flight <int>,\n#   tailnum <chr>, origin <chr>, dest <chr>, air_time <dbl>, distance <dbl>,\n#   hour <dbl>, minute <dbl>, time_hour.x <dttm>, gain <dbl>, hours <dbl>,\n#   gain_per_hour <dbl>, temp <dbl>, dewp <dbl>, humid <dbl>, wind_dir <dbl>,\n#   wind_speed <dbl>, wind_gust <dbl>, precip <dbl>, pressure <dbl>,\n#   visib <dbl>, time_hour.y <dttm>\n```\n:::\n:::\n\n\n::: {.callout-tip icon=\"false\"}\n## {{< bi question-octagon color=#6dc83c >}} Question\n\nLooking at the first figure in this section, when joining `flights` and `weather` (or, in other words, matching the hourly weather values with each flight), why do we need to join by all of `year`, `month`, `day`, `hour`, and `origin`, and not just `hour`?\n\n\n<div class='webex-solution'><button>Answer</button>\n\n\n`year`,`month`,`day`,`hour`,`origin` are the key variables that allow us to uniquely identify the observational units.\n\n\n</div>\n\n:::\n\n# Other verbs {#other-verbs}\n\n## Select variables using select {#select}\n\n\n::: {.cell}\n::: {.cell-output-display}\n![Select diagram from Data Wrangling with dplyr and tidyr cheatsheet.](select.png){width=3.85in}\n:::\n:::\n\n\nWe've seen that the `flights` data frame in the `nycflights13` package contains many different variables. The `names` function gives a listing of all the columns in a data frame; in our case you would run `names(flights)`. You can also identify these variables by running the `glimpse` function in the `dplyr` package:\n\n\n::: {.cell}\n\n```{.r .cell-code}\nglimpse(flights)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nRows: 336,776\nColumns: 22\n$ year           <int> 2013, 2013, 2013, 2013, 2013, 2013, 2013, 2013, 2013, 2~\n$ month          <int> 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1~\n$ day            <int> 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1~\n$ dep_time       <int> 517, 533, 542, 544, 554, 554, 555, 557, 557, 558, 558, ~\n$ sched_dep_time <int> 515, 529, 540, 545, 600, 558, 600, 600, 600, 600, 600, ~\n$ dep_delay      <dbl> 2, 4, 2, -1, -6, -4, -5, -3, -3, -2, -2, -2, -2, -2, -1~\n$ arr_time       <int> 830, 850, 923, 1004, 812, 740, 913, 709, 838, 753, 849,~\n$ sched_arr_time <int> 819, 830, 850, 1022, 837, 728, 854, 723, 846, 745, 851,~\n$ arr_delay      <dbl> 11, 20, 33, -18, -25, 12, 19, -14, -8, 8, -2, -3, 7, -1~\n$ carrier        <chr> \"UA\", \"UA\", \"AA\", \"B6\", \"DL\", \"UA\", \"B6\", \"EV\", \"B6\", \"~\n$ flight         <int> 1545, 1714, 1141, 725, 461, 1696, 507, 5708, 79, 301, 4~\n$ tailnum        <chr> \"N14228\", \"N24211\", \"N619AA\", \"N804JB\", \"N668DN\", \"N394~\n$ origin         <chr> \"EWR\", \"LGA\", \"JFK\", \"JFK\", \"LGA\", \"EWR\", \"EWR\", \"LGA\",~\n$ dest           <chr> \"IAH\", \"IAH\", \"MIA\", \"BQN\", \"ATL\", \"ORD\", \"FLL\", \"IAD\",~\n$ air_time       <dbl> 227, 227, 160, 183, 116, 150, 158, 53, 140, 138, 149, 1~\n$ distance       <dbl> 1400, 1416, 1089, 1576, 762, 719, 1065, 229, 944, 733, ~\n$ hour           <dbl> 5, 5, 5, 5, 6, 5, 6, 6, 6, 6, 6, 6, 6, 6, 6, 5, 6, 6, 6~\n$ minute         <dbl> 15, 29, 40, 45, 0, 58, 0, 0, 0, 0, 0, 0, 0, 0, 0, 59, 0~\n$ time_hour      <dttm> 2013-01-01 05:00:00, 2013-01-01 05:00:00, 2013-01-01 0~\n$ gain           <dbl> -9, -16, -31, 17, 19, -16, -24, 11, 5, -10, 0, 1, -9, 1~\n$ hours          <dbl> 3.7833333, 3.7833333, 2.6666667, 3.0500000, 1.9333333, ~\n$ gain_per_hour  <dbl> -2.3788546, -4.2290749, -11.6250000, 5.5737705, 9.82758~\n```\n:::\n:::\n\n\nHowever, say you only want to consider two of these variables, say `carrier` and `flight`. You can `select` these:\n\n\n::: {.cell}\n\n```{.r .cell-code}\nflights |> \n  select(carrier, flight)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 336,776 x 2\n   carrier flight\n   <chr>    <int>\n 1 UA        1545\n 2 UA        1714\n 3 AA        1141\n 4 B6         725\n 5 DL         461\n 6 UA        1696\n 7 B6         507\n 8 EV        5708\n 9 B6          79\n10 AA         301\n# i 336,766 more rows\n```\n:::\n:::\n\n\nThis function makes navigating data sets with a very large number of variables easier for humans by restricting consideration to only those of interest, like `carrier` and `flight` above. So for example, this might make viewing the data set using the `View` spreadsheet viewer more digestible. However, as far as the computer is concerned it does not care how many additional variables are in the data set in question, so long as `carrier` and `flight` are included.\n\nAnother example involves the variable `year`. If you remember the original description of the `flights` data frame (or by running `?flights`), you will remember that this data corresponds to flights in 2013 departing New York City. The `year` variable isn't really a variable here in that it doesn't vary, the `flights` data set actually comes from a larger data set that covers many years. We may want to remove the `year` variable from our data set since it won't be helpful for analysis in this case. We can deselect `year` by using the `-` sign:\n\n\n::: {.cell}\n\n```{.r .cell-code}\nflights_no_year <- flights |> \n  select(-year)\n```\n:::\n\n\nOr we could specify a ranges of columns:\n\n\n::: {.cell}\n\n```{.r .cell-code}\nflight_arr_times <- flights |> \n  select(month:dep_time, arr_time:sched_arr_time)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 336,776 x 5\n   month   day dep_time arr_time sched_arr_time\n   <int> <int>    <int>    <int>          <int>\n 1     1     1      517      830            819\n 2     1     1      533      850            830\n 3     1     1      542      923            850\n 4     1     1      544     1004           1022\n 5     1     1      554      812            837\n 6     1     1      554      740            728\n 7     1     1      555      913            854\n 8     1     1      557      709            723\n 9     1     1      557      838            846\n10     1     1      558      753            745\n# i 336,766 more rows\n```\n:::\n:::\n\n\nThe `select` function can also be used to reorder columns in combination with the `everything` helper function. Let's suppose we would like the `hour`, `minute`, and `time_hour` variables, which appear at the end of the `flights` data set, to actually appear immediately after the `day` variable:\n\n\n::: {.cell}\n\n```{.r .cell-code}\nflights_reorder <- flights |> \n  select(month:day, hour:time_hour, everything())\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n [1] \"month\"          \"day\"            \"hour\"           \"minute\"        \n [5] \"time_hour\"      \"year\"           \"dep_time\"       \"sched_dep_time\"\n [9] \"dep_delay\"      \"arr_time\"       \"sched_arr_time\" \"arr_delay\"     \n[13] \"carrier\"        \"flight\"         \"tailnum\"        \"origin\"        \n[17] \"dest\"           \"air_time\"       \"distance\"       \"gain\"          \n[21] \"hours\"          \"gain_per_hour\" \n```\n:::\n:::\n\n\nin this case `everything()` picks up all remaining variables. Lastly, the helper functions `starts_with`, `ends_with`, and `contains` can be used to choose **variables / column names** that match those conditions:\n\n\n::: {.cell}\n\n```{.r .cell-code}\nflights_begin_a <- flights |> \n  select(starts_with(\"a\"))\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 336,776 x 3\n   arr_time arr_delay air_time\n      <int>     <dbl>    <dbl>\n 1      830        11      227\n 2      850        20      227\n 3      923        33      160\n 4     1004       -18      183\n 5      812       -25      116\n 6      740        12      150\n 7      913        19      158\n 8      709       -14       53\n 9      838        -8      140\n10      753         8      138\n# i 336,766 more rows\n```\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nflights_delays <- flights |> \n  select(ends_with(\"delay\"))\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 336,776 x 2\n   dep_delay arr_delay\n       <dbl>     <dbl>\n 1         2        11\n 2         4        20\n 3         2        33\n 4        -1       -18\n 5        -6       -25\n 6        -4        12\n 7        -5        19\n 8        -3       -14\n 9        -3        -8\n10        -2         8\n# i 336,766 more rows\n```\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nflights_time <- flights |> \n  select(contains(\"time\"))\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 336,776 x 6\n   dep_time sched_dep_time arr_time sched_arr_time air_time time_hour          \n      <int>          <int>    <int>          <int>    <dbl> <dttm>             \n 1      517            515      830            819      227 2013-01-01 05:00:00\n 2      533            529      850            830      227 2013-01-01 05:00:00\n 3      542            540      923            850      160 2013-01-01 05:00:00\n 4      544            545     1004           1022      183 2013-01-01 05:00:00\n 5      554            600      812            837      116 2013-01-01 06:00:00\n 6      554            558      740            728      150 2013-01-01 05:00:00\n 7      555            600      913            854      158 2013-01-01 06:00:00\n 8      557            600      709            723       53 2013-01-01 06:00:00\n 9      557            600      838            846      140 2013-01-01 06:00:00\n10      558            600      753            745      138 2013-01-01 06:00:00\n# i 336,766 more rows\n```\n:::\n:::\n\n\n## Rename variables using rename {#rename}\n\nAnother useful function is `rename`, which as you may suspect renames one column to another name. Suppose we wanted `dep_time` and `arr_time` to be `departure_time` and `arrival_time` instead in the `flights_time` data frame:\n\n\n::: {.cell}\n\n```{.r .cell-code}\nflights_time <- flights |> \n  select(contains(\"time\")) |> \n  rename(departure_time = dep_time,\n         arrival_time = arr_time)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] \"departure_time\" \"sched_dep_time\" \"arrival_time\"   \"sched_arr_time\"\n[5] \"air_time\"       \"time_hour\"     \n```\n:::\n:::\n\n\nNote that in this case we used a single `=` sign with `rename`. eg. `departure_time = dep_time`. This is because we are not testing for equality like we would using `==`, but instead we want to assign a new variable `departure_time` to have the same values as `dep_time` and then delete the variable `dep_time`.\n\n## Find the top number of values using slice\n\nWe can also use the `slice_max()` function which automatically tells us the most frequent `num_flights`. We specify the top 10 airports here:\n\n\n::: {.cell}\n\n```{.r .cell-code}\nnamed_dests |> \n  slice_max(num_flights, n = 10)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 10 x 9\n   dest  num_flights airport_name             lat    lon   alt    tz dst   tzone\n   <chr>       <int> <chr>                  <dbl>  <dbl> <dbl> <dbl> <chr> <chr>\n 1 ORD         17283 Chicago Ohare Intl      42.0  -87.9   668    -6 A     Amer~\n 2 ATL         17215 Hartsfield Jackson At~  33.6  -84.4  1026    -5 A     Amer~\n 3 LAX         16174 Los Angeles Intl        33.9 -118.    126    -8 A     Amer~\n 4 BOS         15508 General Edward Lawren~  42.4  -71.0    19    -5 A     Amer~\n 5 MCO         14082 Orlando Intl            28.4  -81.3    96    -5 A     Amer~\n 6 CLT         14064 Charlotte Douglas Intl  35.2  -80.9   748    -5 A     Amer~\n 7 SFO         13331 San Francisco Intl      37.6 -122.     13    -8 A     Amer~\n 8 FLL         12055 Fort Lauderdale Holly~  26.1  -80.2     9    -5 A     Amer~\n 9 MIA         11728 Miami Intl              25.8  -80.3     8    -5 A     Amer~\n10 DCA          9705 Ronald Reagan Washing~  38.9  -77.0    15    -5 A     Amer~\n```\n:::\n:::\n\n\nWe can find the most frequent flights in a single pipeline as follows:\n\n\n::: {.cell}\n\n```{.r .cell-code}\nten_freq_dests <- flights |>\n  summarize(num_flights = n(),\n            .by = dest) |>\n  slice_max(num_flights, n = 10) \n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 10 x 2\n   dest  num_flights\n   <chr>       <int>\n 1 ORD         17283\n 2 ATL         17215\n 3 LAX         16174\n 4 BOS         15508\n 5 MCO         14082\n 6 CLT         14064\n 7 SFO         13331\n 8 FLL         12055\n 9 MIA         11728\n10 DCA          9705\n```\n:::\n:::\n\n\n::: {.callout-warning icon=\"false\"}\n## Task\n\nHow could one use `starts_with`, `ends_with`, and `contains` to select columns from the `flights` data frame? Provide three different examples in total: one for `starts_with`, one for `ends_with`, and one for `contains`.\n\n\n::: {.cell webex.hide='Click here to see the solution'}\n\n<div class='webex-solution'><button>Click here to see the solution</button>\n\n```{.r .cell-code  code-fold=\"show\"}\n# Select arrival time and arrival delay columns\nflights |>\n  select(starts_with(\"arr\"))\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 336,776 x 2\n   arr_time arr_delay\n      <int>     <dbl>\n 1      830        11\n 2      850        20\n 3      923        33\n 4     1004       -18\n 5      812       -25\n 6      740        12\n 7      913        19\n 8      709       -14\n 9      838        -8\n10      753         8\n# i 336,766 more rows\n```\n:::\n\n```{.r .cell-code  code-fold=\"show\"}\n# Select departure and arrival delay columns\nflights |>\n  select(ends_with(\"delay\"))\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 336,776 x 2\n   dep_delay arr_delay\n       <dbl>     <dbl>\n 1         2        11\n 2         4        20\n 3         2        33\n 4        -1       -18\n 5        -6       -25\n 6        -4        12\n 7        -5        19\n 8        -3       -14\n 9        -3        -8\n10        -2         8\n# i 336,766 more rows\n```\n:::\n\n```{.r .cell-code  code-fold=\"show\"}\n# Select departure times, schedule  departure and departure delay columns\nflights |>\n  select(contains(\"dep\"))\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 336,776 x 3\n   dep_time sched_dep_time dep_delay\n      <int>          <int>     <dbl>\n 1      517            515         2\n 2      533            529         4\n 3      542            540         2\n 4      544            545        -1\n 5      554            600        -6\n 6      554            558        -4\n 7      555            600        -5\n 8      557            600        -3\n 9      557            600        -3\n10      558            600        -2\n# i 336,766 more rows\n```\n:::\n\n\n</div>\n:::\n\n:::\n\n::: {.callout-warning icon=\"false\"}\n## Task\n\nCreate a new data frame that shows the top 5 airports with the largest average arrival delays from NYC in 2013.\n\n\n<div class='webex-solution'><button>Take a hint</button>\n\n\nCompute the mean arrival delay from each destination. You can then join the resulting data set with the `airports` data which contains the airports names and search for the top 5 entries.\n\n\n</div>\n\n\n\n::: {.cell webex.hide='Click here to see the solution'}\n\n<div class='webex-solution'><button>Click here to see the solution</button>\n\n```{.r .cell-code  code-fold=\"show\"}\n  flights|>\n  summarize(mean_arr_delay = mean(arr_delay,na.rm=T),\n            .by = dest) |>\n  inner_join(airports, by = join_by(dest == faa)) |>\n  rename(airport_name = name) |>\n    slice_max(mean_arr_delay,n=5)\n```\n\n\n</div>\n:::\n\n:::\n\n## Vectorised if-else thru `case_when`\n\n`case_when` serves as a method to streamline multiple if-else statements by vectorizing them. It allows us to assess a condition expression and make decisions accordingly. For instance, consider a scenario where we need to categorize weather conditions according to the meteorological data contained in the `weather` data set.\n\nLet suppose that we want to categorize the temperature variable into three categories:\n\n-   **low** for temperatures $<39.9$\n\n-   **medium** for temperature values $\\geq 39.9$ and $\\leq 70$\n\n-   **high** for temperature values $> 70$\n\nWe can achieve this with the following code:\n\n\n::: {.cell}\n\n```{.r .cell-code  code-fold=\"show\"}\nweather |>\n  mutate(\n    temp_cat = case_when(\n      is.na(temp) ~ NA,\n      temp < 39.9 ~ \"low\",\n      between(temp,39.9 ,70)~ \"medium\",\n      .default = \"large\"\n    )\n  ) |>\n  relocate(temp,temp_cat)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 26,115 x 16\n    temp temp_cat origin  year month   day  hour  dewp humid wind_dir wind_speed\n   <dbl> <chr>    <chr>  <int> <int> <int> <int> <dbl> <dbl>    <dbl>      <dbl>\n 1  39.0 low      EWR     2013     1     1     1  26.1  59.4      270      10.4 \n 2  39.0 low      EWR     2013     1     1     2  27.0  61.6      250       8.06\n 3  39.0 low      EWR     2013     1     1     3  28.0  64.4      240      11.5 \n 4  39.9 medium   EWR     2013     1     1     4  28.0  62.2      250      12.7 \n 5  39.0 low      EWR     2013     1     1     5  28.0  64.4      260      12.7 \n 6  37.9 low      EWR     2013     1     1     6  28.0  67.2      240      11.5 \n 7  39.0 low      EWR     2013     1     1     7  28.0  64.4      240      15.0 \n 8  39.9 medium   EWR     2013     1     1     8  28.0  62.2      250      10.4 \n 9  39.9 medium   EWR     2013     1     1     9  28.0  62.2      260      15.0 \n10  41   medium   EWR     2013     1     1    10  28.0  59.6      260      13.8 \n# i 26,105 more rows\n# i 5 more variables: wind_gust <dbl>, precip <dbl>, pressure <dbl>,\n#   visib <dbl>, time_hour <dttm>\n```\n:::\n:::\n\n\nHere we use the `mutate` command to create new variable named `temp_cat`. The `case_when` will then set to `NA` those values in the original `temp` variable that are missing. Then if the values of `temp` are $< 30.9$ it will assign them the label of `low`. If they lie between $39.9$ and $70$ it will assign them the label of `medium` and finally set to `large` any of the values that do not meet any of the aforementioned conditions. We can also use the function `relocate` to change the columns position so that the `temp` and `temp_cat` appears first on the data frame.\n\n::: {.callout-warning icon=\"false\"}\n## Task\n\nCreate a new variable called `extreme_weather` that takes the value of `extreme` if the wind speed exceeds 64 mph and the temperature is less than 40 Â°F and `not extreme` otherwise. Then, relocate this new variable along with the variables used to create it at the first columns of the data frame, and sort them out based on `wind_speed`.\n\n\n<div class='webex-solution'><button>Take a hint</button>\n\n\nUse the conditional operators `|` and `&` to add multiple conditions.\n\n\n</div>\n\n\n\n::: {.cell webex.hide='Click here to see the solution'}\n\n<div class='webex-solution'><button>Click here to see the solution</button>\n\n```{.r .cell-code  code-fold=\"show\"}\nweather |>\n  mutate(\n    extreme_weather  = case_when(\n      is.na(temp)|is.na(wind_speed) ~ NA,\n      temp < 40 & wind_speed  > 64~ \"extreme\",\n      .default = \"not extreme\"\n    )\n  ) |>\n  relocate(extreme_weather,temp,wind_speed) |>\n  arrange(desc(wind_speed))\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 26,115 x 16\n   extreme_weather  temp wind_speed origin  year month   day  hour  dewp humid\n   <chr>           <dbl>      <dbl> <chr>  <int> <int> <int> <int> <dbl> <dbl>\n 1 extreme          39.0     1048.  EWR     2013     2    12     3 27.0   61.6\n 2 not extreme      57.2       42.6 EWR     2013     1    31     6 53.6   87.7\n 3 not extreme      53.6       42.6 JFK     2013     1    31     4 53.1  100  \n 4 not extreme      60.8       40.3 EWR     2013     1    31     4 59     93.8\n 5 not extreme      59         40.3 LGA     2013     1    31     4 55.4   93.7\n 6 not extreme      46.0       39.1 EWR     2013     1    31     8 30.0   53.3\n 7 not extreme      41         38.0 JFK     2013     3     6    14 28.9   61.9\n 8 not extreme      53.1       36.8 JFK     2013     1    31     3 52.0  100  \n 9 not extreme      51.8       36.8 JFK     2013     1    31     7 46.4   81.7\n10 not extreme      28.0       36.8 JFK     2013    11    24    10 -0.04  29.2\n# i 26,105 more rows\n# i 6 more variables: wind_dir <dbl>, wind_gust <dbl>, precip <dbl>,\n#   pressure <dbl>, visib <dbl>, time_hour <dttm>\n```\n:::\n\n\n</div>\n:::\n\n:::\n\n# Summary\n\nThe table below lists a selection of the data wrangling verbs and summarises what they do. Using these verbs and the pipe `|>` operator, you'll be able to write easily legible code to perform almost all the data wrangling necessary for the rest of this course.\n\n\n::: {.cell-output-display}\n\\begin{table}[!h]\n\n\\caption{\\label{tab:wrangle-summary-table}Summary of data wrangling verbs}\n\\centering\n\\fontsize{9}{11}\\selectfont\n\\begin{tabular}[t]{ll}\n\\toprule\nVerb & Operation\\\\\n\\midrule\nfilter() & Pick out a subset of rows\\\\\nsummarize() & Summarise many values to one using a summary statistic function like mean(), median(), etc.\\\\\nmutate() & Create new variables by mutating existing ones\\\\\narrange() & Arrange rows of a data variable in ascending (default) or descending order\\\\\ninner\\_join() & Join/merge two data frames, matching rows by a key variable\\\\\n\\addlinespace\nselect() & Pick out a subset of columns to make data frames easier to view\\\\\n\\bottomrule\n\\end{tabular}\n\\end{table}\n:::\n",
    "supporting": [
      "index_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {
      "include-in-header": [
        "\\usepackage{booktabs}\r\n\\usepackage{longtable}\r\n\\usepackage{array}\r\n\\usepackage{multirow}\r\n\\usepackage{wrapfig}\r\n\\usepackage{float}\r\n\\usepackage{colortbl}\r\n\\usepackage{pdflscape}\r\n\\usepackage{tabu}\r\n\\usepackage{threeparttable}\r\n\\usepackage{threeparttablex}\r\n\\usepackage[normalem]{ulem}\r\n\\usepackage{makecell}\r\n\\usepackage{xcolor}\r\n"
      ]
    },
    "engineDependencies": {},
    "preserve": null,
    "postProcess": false
  }
}